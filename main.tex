\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2019

% ready for submission
% \usepackage{neurips_2019}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2019}

% to compile a camera-ready version, add the [final] option, e.g.:
     \usepackage[final]{neurips_2019}

% to avoid loading the natbib package, add option nonatbib:
%     \usepackage[nonatbib]{neurips_2019}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

% My packages

\usepackage[mathscr]{euscript}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage {tikz}
\usetikzlibrary {positioning}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{hyperref}
\usepackage{stmaryrd }
\usepackage{csquotes}
\usepackage{wasysym}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]

\newcommand{\CI}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp$}}}}
\newcommand{\CII}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp\mkern-10mu\perp$}}}}
\newcommand{\RV}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\PA}[2]{\ensuremath{\text{Pa}_{#1}(#2)}}
\newcommand{\ND}[2]{\ensuremath{\text{ND}_{#1}(#2)}}
\newcommand{\CH}[2]{\ensuremath{\text{Ch}_{#1}(#2)}}
\newcommand{\DE}[2]{\ensuremath{\text{De}_{#1}(#2)}}
\makeatletter
\newcommand*\bigcdot{\mathpalette\bigcdot@{.5}}
\newcommand*\bigcdot@[2]{\mathbin{\vcenter{\hbox{\scalebox{#2}{$\m@th#1\bullet$}}}}}
\makeatother

\newcommand\splitter[1]{%
\begin{tikzpicture}[scale=#1]
\draw (0,-1) -- (0,0);
\draw (0,0) to [bend right] (1,1);
\draw (0,0) to [bend left] (-1,1);
\end{tikzpicture}
}

\newcommand\stopper[1]{%
\begin{tikzpicture}[scale=#1]
\draw (0,-1) -- (0,0);
\node (E) at (0,0) {$\bigcdot$};
\end{tikzpicture}
}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\arginf}{arg\,inf}
\DeclareMathOperator*{\argsup}{arg\,sup}

\newcommand{\cheng}[1]{ {\color{purple}[{\bf Cheng:~{#1}}]} }


\title{How to ask a causal question}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  David Johnston\thanks{Use footnote for providing further information
    about author (webpage, alternative address)---\emph{not} for acknowledging
    funding agencies.} \\
  College of Engineering and Computer Science\\
  Australian National University and DATA61\\
  ACT, Australia 0200 \\
  \texttt{david.johnston1@anu.edu.au} \\
  % examples of more authors
   \And
  Cheng Soon Ong\\
  DATA61 and Australian National University\\
  % Address \\
  % \texttt{email} \\
   \And
   Robert Williamson \\
   Australian National University and DATA61\\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}


\begin{document}

\maketitle

\begin{abstract}
There are multiple competing approaches to the handling of causality in statistical inference, including Causal Bayesian Networks and Potential Outcomes which differ in part in their underlying conceptions of causality. In an approach similar to Dawid, we develop the notion of a causal statistical decision problem patterned after the statistical decision theory of Wald. Our approach is motivated by a simple consideration: suppose we have a dataset, some set of available decisions and we know what state we would like the world to occupy, but we are uncertain about how our decisions affect the state of the world. We introduce the notion of \emph{consequence } that relate decisions to states of the world, and \emph{causal theories} that relate observations to consequences. These definitions are not motivated by any ``causal'' considerations, but by the need to connect observations, decisions and consequences. We connect causal statistical decision problems to statistical decision problems via a reduction that allows results from the latter to sometimes be imported to the former. We show that Causal Bayesian Networks and Potential Outcomes both have a natural mapping to causal theories, and demonstrate a straightforward example of a causal theory that cannot be unambiguously represented by either. We argue by example that, given this more general perspective, the standard understanding of a Causal Bayesian Network is only justified under additional nontrivial assumptions. Finally, we conclude with a long list of open questions raised by this new perspective.
\end{abstract}

\section{Notation}

\begin{itemize}
    \item A subscript on a random variable $\RV{X}_i$ refers to its position in a sequence of (usually IID) random variables taking values in the same space
    \item A superscript on a random variable $\RV{X}^i$ marks it out as an element of a set of random variables that do not necessarily take values in the same space
    \item The notation $[N]$ refers to the set of natural numbers $\{0,...,N\}$
\end{itemize}

\include{story}
\include{markov_kernels}
\include{causal_decision_problems}
\include{causal_bayesian_networks}
\include{counterfactuals}

\section{Discussion}

One of the possibly controversial choices in this scheme is the separation of the decision set $D$ from the sample space $E$ of the observed data. Almost universally, the causal inference literature identifies actions with some known impact on some observed variable (for example, deterministically setting some variable to a given value). If a problem is to be non-trivial we must accept some means of relating observed data to consequences.

This choice was made because there are many ways to specify prior knowledge about the relationship between decisions and outcomes, and different options are frequently chosen in practice. Within the graphical models literature one can find a wide variety of intervention types such as hard interventions, soft interventions, activity interventions and policy interventions. Given this, the requirement to specify prior knowledge about the outcomes of decisions \emph{somehow} is at least not an extra requirement.

Avoiding prescription here is also consistent with the project of describing the minimal set of elements necessary to describe a statistical causal decision problem. While we do not have a clean set of axioms that compel the construction given in this work, an informal case can be made for the necessity of the choices here. Taking the starting point that we are given some preferences over outcomes described by a utility function, a set of available decisions and a dataset and we want to determine preferences over possible decision functions, it appears necessary that we have some means of relating decisions to outcomes (given here by \emph{consequence mappings}) and some means of relating the given data to such consequence mappings (given here by \emph{causal theories}). It is not necessary, however, to suppose any particular canonical relationship between decisions, the given data and the outcomes. No preferences among possible decisions may be a trivial result, but it is not invalid.



\section{Conclusion}



\bibliographystyle{plainnat}
\bibliography{references}


\include{appendix}

\end{document}
