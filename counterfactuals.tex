
\section{Potential Outcomes}

\textbf{Todo: } This story could be made stronger starting from the proposition that using PO or anything else, you still need to rate the desirability of available decisisons somehow.

Potential Outcomes is a major rival to the approach typified by Causal Bayesian Networks for formulating causal questions and hypotheses. Causal queries in the Potential Outcomes framework concern the distribution of random variables $\RV{X}_0, \RV{X}_1$ representing potential outcomes, or ``the value $\RV{X}$ would take if action 0 or 1 were taken respectively''. Because they are built on a probability distribution, queries in the Potential Outcomes framework resemble ordinary statistical decision problems, and indeed it is possible to formulate an ordinary statistical decision problem featuring potential outcomes. This has an important implication for the present discussion: suppose we approach a causal query as a statistical decision problem $\langle (\mathscr{H}, E),D,\RV{X},\ell\rangle$ where $\ell$ depends on the distribution in $\mathscr{H}$ via some random variables $\RV{X}_0,\RV{X}_1$ representing potential outcomes. Then, by the reduction given in Theorem \ref{th:sdp_to_cdp} we can construct a Causal Decision Problem that makes the same risk assignments \emph{by assuming decisions have no effect on outcomes}. 

We proposed Causal Decision Problems to model situations where the loss is underwritten by a known utility over outcomes, but where the outcomes themselves were uncertain. If we suppose that the loss $\ell$ above is indeed underwritten by a utility over outcomes, then the relationship between decisions and outcomes must already be ``baked in'' to the definition of $\ell$. The CDP one obtains via Theorem \ref{th:sdp_to_cdp} is therefore uninteresting.

If we are to find an interesting representation of a problem posed via Potential Outcomes as a Causal Decision Problem, we must therefore do some reverse engineering to determine the consequence map represented by a distribution over potential outcomes and the utility underwriting the loss function. It seems clear from the interpretation of potential outcomes above that the consequence map $\kappa:D\to\Delta(\mathcal{E})$ should have the outcome consistency property:
\begin{align}
    \kappa(i;(\RV{X}_i-\RV{X})^{-1}(A))=\delta_0(A) \label{eq:oc_consist}
\end{align} 
where we understand $\RV{X}$ to represent any quantities that are actually observed. This is similar to the common consistency condition (e.g., see \cite{richardson2013single}) but it is not equivalent. Note that this condition precludes an ordinary CBN from modelling the consequences for a problem posed via potential outcomes as we cannot assert independent control of $\RV{X}_i$ and $\RV{X}$. It may also be desirable to assume $\kappa(i;\RV{X}_i^{-1}(A))=\mu(\RV{X}_i^{-1}(A))$ - that is, the distribution of potential outcomes in the given data is the same as the distribution of potential outcomes in consequence of any decision $i$.

Potential outcomes is usually associated with a much more complicated hypothesis class than any approach that associates a distributions over observable variables with consequences. We can analogise the notion of a reduction introduced in Definition \ref{def:red_sdp_cdp} to introduce a weak notion of equivalence between ``simple'' SCDPs and counterfactual SCDPs.

\begin{definition}[Reduction]\label{def:red_scdp}
Given a statistical causal decision problem $\alpha$ with an induced game $\langle \mathscr{T}^\alpha, \mathscr{D}, R^\alpha \rangle$ and a second statistical causal decision problem $\beta$ with induced game $\langle \mathscr{T}^\beta, \mathscr{D}, R^\beta\rangle$ where the set of decision functions $\mathscr{D}$ is shared, $\alpha$ is reducible to $\beta$ if there is a surjective function $g:\mathscr{T}^\alpha\to \mathscr{T}^\beta$ such that for all $(\kappa,\mu)\in \mathscr{H}$ and $J\in \mathscr{D}$ we have $R^\alpha(J,\kappa,\mu)=R^\beta(J,g(\kappa,\mu))$.
\end{definition}

\begin{theorem}[Reduction of problems with observable utility]\label{th:scdp_obu_red}
A statistical causal decision problem $\alpha=\langle (\mathscr{T}^\alpha,(E,\mathcal{E})),D,\RV{X},U\rangle$ where, for $\zeta\in \Delta(\mathcal{E}\otimes\mathcal{D})$, $U(\zeta)=U'(\zeta (\stopper{0.15} \otimes F_{\RV{Y}}))$ for some $\RV{Y}:E\to Y$ and $U':\Delta(\mathcal{Y})\to \mathbb{R}$ has $\RV{Y}$-\emph{observable utility}. Such a problem can be reduced to a problem $\beta=\langle (\mathscr{T}^\beta,(E,\sigma(\RV{X}\otimes\RV{Y}))),D,\RV{X},U\rangle$.
\end{theorem}

\begin{proof}
Consider the mapping $g:\mathscr{T}^\alpha\to\mathscr{T}^\beta$ given by $(\kappa,\mu)\mapsto (\kappa F_{\underline{(\RV{X}\otimes\RV{Y})}},\mu F_{\underline{(\RV{X}\otimes\RV{Y})}})$. Note that $\kappa F_{\underline{(\RV{X}\otimes\RV{Y})}}$ and $\mu F_{\underline{(\RV{X}\otimes\RV{Y})}}$ are in $\Delta(\sigma(\RV{X}\otimes\RV{Y}))$ and $\Delta(\sigma(\RV{X}\otimes\RV{Y}))^D$.

We have for $J\in \mathscr{D}$, $(\kappa,\mu)\in\mathscr{T}^\alpha$
\begin{align}
    R^\alpha(J,\kappa,\mu) &= \sup_{\gamma'\in\Delta(\mathcal{D})} U(\gamma'\underline{(I_D\otimes\kappa)}) - U(\mu F_{\RV{X}} J\underline{(I_D\otimes\kappa)})\\
                           &= \sup_{\gamma'\in\Delta(\mathcal{D})} U'(\gamma'\splitter{0.15}(I_D\otimes\kappa)(\stopper{0.15}\otimes F_{\RV{Y}}) - U(\mu F_{\RV{X}} J\splitter{0.15} (I_D\otimes\kappa))(\stopper{0.15}\otimes F_{\RV{Y}}))\\
                           &= \sup_{\gamma'\in\Delta(\mathcal{D})} U'(\gamma'\kappa F_{\RV{Y}}) - U'(\mu F_{\RV{X}} J\kappa F_{\RV{Y}})\\
                           &= \sup_{\gamma'\in\Delta(\mathcal{D})} U'(\gamma'\kappa F_{\underline{(\RV{X}\otimes\RV{Y})}} F_{\RV{Y}}) - U'(\mu F_{\underline{(\RV{X}\otimes\RV{Y})}} F_{\RV{X}} J\kappa F_{\underline{(\RV{X}\otimes\RV{Y})}} F_{\RV{Y}})\\
                           &= \sup_{\gamma'\in\Delta(\mathcal{D})} U(\gamma'\kappa F_{\underline{(\RV{X}\otimes\RV{Y})}}) - U(\mu F_{\underline{(\RV{X}\otimes\RV{Y})}} F_{\RV{X}} J\kappa F_{\underline{(\RV{X}\otimes\RV{Y})}})\\
                           &= R^\beta (J,g(\kappa,\mu))
\end{align}
\end{proof}

Theorem \ref{th:scdp_obu_red} tells us that any statistical causal decision problem that represents uncertainty over unobservable counterfactual quantities can be reduced to a problem that represents uncertainty over only observed quantities provided the utility only depends on observed quantities. Note that there are some quantities considered in the counterfactual literature such as ``the effect of treatment on the treated'' (ETT) that depends on counterfactual quantities and has some relevance to decision preferences \cite{rubin_estimating_1974}, though it has been suggested that where this quantity can be determined it does not actually depend on anything counterfactual \cite{geneletti2007defining}. Furthermore, we are not aware of any discussion of whether ETT (or variants) is ultimately underwritten by purely counterfactual preferences, or is simply a proxy for ordinary preferences. The legal standard of no harm ``but for'' the defendant's negligence, on the other hand, does seem to invoke fundamentally counterfactual considerations \cite{pearl_causality:_2009}.

An alternative way to connect SCDPs to the counterfactual framework is to suppose that counterfactual variables are random variables on some distribution defined by some canonical construction similar to Theorem \ref{th:red_cdp}. The precise nature of this canonical construction is not at all obvious, nor is the general nature of (pseudo) utilities that demand such a construction. Nonparametric Structural Equation Models (NPSEMs) are nonetheless considered by many to be appropriate tools for the construction of counterfactual distributions. Theorem \ref{th:npsem_ct} shows that these models can be represented by causal theories.

\begin{definition}[NPSEM]\label{def:NPSEM}
A non-parametric structural equation model (NPSEM) is a tuple $\langle \{\RV{X}_i, \RV{U}_i, f_i\}_{i\in[N]}, (D,\mathcal{D}), (E,\mathcal{E})\rangle$ where, for all $i\in N$, $\RV{X}_i:E\times D \to X_i$, $\RV{U}_i:E\to U_i$, $\mathscr{H}\subset\Delta(\mathcal{E}$ and $D=\times_{i\in[N]} X_i\cup\{*\}$. The $\RV{X}_i$ are given by

\begin{align}
    \RV{X}_i(e,d) = \begin{cases} f_i(\RV{X}_{<i}(e,d),\RV{U}_i(e)) &\RV{D}_i(d)=*\\ 
    \RV{D}_i(d)  &\RV{D}_i(d)\neq * \end{cases}
\end{align}

Where $\RV{X}_{<i}(e,d)=[\RV{X}_0(e,d),...\RV{X}_{i-1}(e,d)]$ and the $f_i$ are all measurable with respect to the relevant product $\sigma$-algebras. Note that we can let $\RV{X}$ be the joint space of all the $\RV{X}_i$ and an NPSEM induces a measurable function $F:D\times E\to X$.
\end{definition}

\begin{theorem}[Representation of NPSEM]\label{th:npsem_ct}
For $X=\times_{i\in[N]}X_i$ let $\{\mathscr{T}\}$ be the set of causal theories on the measurable space $(E\times X,\mathcal{E}\otimes\mathcal{F})$ and decision space $D$ and $\mathscr{M}$ be the set of NPSEMs on the same spaces with hypothesis class $\mathscr{H}$. There is a surjective map $h:\{\mathscr{T}\}\to \mathscr{M}$.
\end{theorem}

\begin{proof}
Let $\RV{X}=\splitter{0.15}(\RV{X}_0\otimes\splitter{0.15}(...\RV{X}_{N-1}\otimes\RV{X}_N)_N$ and $\RV{X}_*$ be the same composition for $\RV{X}_0(\cdot,*)$ etc.

Consider the theory $\{(d\mapsto $
\end{proof}