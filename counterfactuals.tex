%!TEX root = main.tex

\section{Potential outcomes models}\label{sec:counterfactuals}

We present one formalisation of potential outcomes (we do not claim it is authoritative) based on \cite{rubin_causal_2005}, and note any points of divergence. 

We will eschew any discussion of sequences. Following the convention set out in the introduction, we will interchangeably use sans serif letters to refer to ``random variables'' and ``particular strings in the string diagram''. $\RV{W}$ is the treatment assignment taking values in $\{0,1\}$, $\RV{Y}(0)$ $\RV{Y}(1)$ are the potential outcomes taking values in $Y$, $\RV{Y}$ is the observed outcome also taking values in $Y$ and $\RV{X}$ is a ``vector of background facts'' taking values in $X$.

Given an underlying state space $\Theta$, a potential outcomes model $\mathscr{O}$ consists of a set of Markov kernels $\langle \mathbf{P}, \mathbf{W}, \mathbf{Y} \rangle$ and a canonical composition that yields a statistical experiment $\mathbf{H}:\Theta\to \Delta(\mathcal{X}\otimes\mathcal{Y}\otimes \mathcal{W})$. 

The kernels are:
\begin{itemize}
\item A ``model of the science'', $\mathbf{P}:\Theta \to \Delta(\mathcal{X}\otimes\mathcal{Y}\otimes\mathcal{Y})$ (In Rubin's notation, $\mathbf{P}$ is $\prod_i f(\RV{X}_i,\RV{Y}_i(0),\RV{Y}_i(1)|\theta)$, though as noted we do not consider sequences here)
\item An ``assignment mechanism'', $\mathbf{W}:\Theta\times X\times Y^2 \to \Delta(\{0,1\})$ (in Rubin's notation, $\mathbf{W}$ is $Pr(\RV{W}|X,Y(1),Y(0))$)
\item An ``observation model'', $\mathbf{Y}:\{0,1\}\times Y^2\to \Delta(\mathcal{Y})$, defined explicitly as $\mathbf{Y}:(\mathbf{y}^0,\mathbf{y}^1,\mathbf{w})\mapsto (1-\mathbf{w}) \odot \delta_{\mathbf{y}^0} + \mathbf{w} \odot \delta_{\mathbf{y}^0}$ where $\odot$ is the elementwise product
\end{itemize}

We differ from Rubin by defining $\mathbf{Y}$ as a Markov kernel rather than a function. This approach means that we can at best assert $W=w\implies \RV{Y}=\RV{Y}(w)$ \emph{almost surely} with respect to some probability measure, as a Markov kernel cannot guarantee exact equality. We also differ from Rubin by including $\Theta$ in the domain of $\mathbf{W}$ as in our framework leaving this dependence out is equivalent to assuming that the treatment assignment mechanism is known \emph{a priori} (as a result, our state $\Theta$ is larger than Rubin's).

We then define the \emph{canonical experiment} $\mathbf{H}^{\mathscr{O}}$ by

\begin{align}
\mathbf{H}^{\mathscr{O}}:=
\begin{tikzpicture}
	\path (0,0) coordinate (A)
	++ (0.5,0) coordinate (copy0)
	++ (1,0) coordinate (cent0)
	+(0,0.5) node[kernel] (HPO) {$\mathbf{P}$}
	+(0.5,0.4) coordinate (copy1)
	++ (1.3,0) coordinate (cent1)
	+(0,-0.5) node[kernel] (HW) {$\mathbf{W}$}
	+(0.5,-0.5) coordinate (copy2)
	++(1,0) coordinate (cent2)
	+ (0,0) node[kernel] (HY) {$\mathbf{Y}$}
	++(1,0) coordinate (cent3)
	+(0,0.65) node (X) {$\RV{X}$}
	+(0,0) node (Y) {$\RV{Y}$}
	+(0,-0.5) node (W) {$\RV{W}$};
	\draw (A) -- (copy0);
	\draw (copy0) to [bend left=20] (HPO);
	\draw (copy0) to [bend right=20] ($(HW.west)+(0,-0.1)$);
	\draw ($(HPO.east)+(0,-0.1)$) -- (copy1);
	\draw (copy1) edge[out=0,in=180] (HW);
	\draw ($(HPO.east)+(0,0.15)$) -- (X) (HY) -- (Y) (HW) -- (W);
	\draw (copy1) edge[out=0,in=180] ($(HY.west)+(0,0.1)$);
	\draw (copy2) to [bend left = 20] ($(HY.west)+(0,-0.1)$);
\end{tikzpicture}
\end{align}

We have labeled the wires carrying the three observed random variables $\RV{X}, \RV{Y}$ and $\RV{W}$. The potential outcomes $[\RV{Y}(0),\RV{Y}(1)]$ are jointly carried by the lower wire exiting from $\mathbf{P}$  -- drawing separate wires would make the diagram quite crowded.  Apart from the connection between $\Theta$ and $\mathbf{W}$, this composition is consistent with Rubin, though the notation is substantially different.

% Where we have labeled the wires ``carrying'' $\RV{Y}(0)$ and $\RV{Y}(1)$ for clarity. Addtionally, we could draw an alternative diagram where each wire was copied $n$ times to reflect the unit level variables. We can define an extended probability space $H^*$ on which potential outcomes are also random variables:

% \begin{align}
% H^*:=\begin{tikzpicture}
% \path (0,0) coordinate (A)
% ++ (0.8,0) node[kernel] (HPO) {$H_{PO}$}
% ++ (0.8,0) coordinate (copy00)
% + (0,0.15) coordinate (copy01)
% + (0,-0.15) coordinate (copy02)
% ++(0.8,0) node[kernel] (HW) {$H_W$}
% +(0.2,-0.6) node (Y0) {}
% +(0.2,-1.2) node (Y1) {}
% ++(0.8,0) coordinate (copy1)
% ++(0.8,0) node[kernel] (HY) {$H_Y$}
% ++(0.8,0) node (Y) {$\RV{Y}$}
% +(0,0.5) node (W) {$\RV{W}$}
% +(0,1) node (X) {$\RV{X}$}
% +(0,-0.6) node (Y0l) {$\RV{Y}(0)$}
% +(0,-1.2) node (Y1l) {$\RV{Y}(1)$};
% \draw (A) -- (HPO) -- (HW) -- (HY) -- (Y);
% \draw ($(HPO.east)+(0,0.15)$) -- ($(HW.west)+(0,0.15)$);
% \draw ($(HPO.east)+(0,-0.15)$) -- ($(HW.west)+(0,-0.15)$);
% \draw (copy01) to [bend left] (X);
% \draw (copy00) to [bend right] (Y0) to [bend right] ($(HY.west)+(0,-0.1)$);
% \draw (copy02) to [bend right] (Y1.west) -- (Y1.east) to [bend right] ($(HY.west)+(0,-0.15)$);
% \draw (copy1) to [bend left] (W);
% \draw (Y0) -- (Y0l);
% \draw (Y1) -- (Y1l);
% \end{tikzpicture}
% \end{align}

% Following this example, we will define a potential outcomes model with $m$ potential outcomes as three Markov kernels $\langle \mathbf{P}, \mathbf{W}, \mathbf{Y} \rangle$ where $\mathbf{P}:\Theta\to \Delta(\mathcal{X}\otimes\mathcal{Y}^m)$, $\mathbf{W}:\Theta\times X\times Y^m\to \Delta([m]^n)$ and $\mathbf{Y}:[m]^n\times Y^m\to \Delta(\mathcal{Y})$ which is always a ``selection kernel'' as defined above. We adopt the alternative signature for $\mathbf{W}$ as the treatment assignment isn't always known \emph{a priori}; it may itself depend on some unknown state. Furthermore, a potential outcomes model induces a statistical experiment $\mathbf{H}$ under the canonical composition shown above. Note that in general multiple potential outcomes models will yield the same statistical experiment $\mathbf{H}$.

\subsection{Are potential outcomes models causal theories?}

By assumption, a potential outcomes model induces a canonical statistical experiment. Given that potential outcomes models are a type of causal model, we can ask whether we can induce a canonical \emph{causal theory}. It is not possible to do this as naturally as with causal Bayesian networks because potential outcomes models do not feature consequence maps. Nevertheless, a causal theory can be induced by considering the science $\mathbf{P}$ to be fixed and the assignment function $\mathbf{W}$ to be variable, which seems to us to be in line with the ideas underpinning the potential outcomes approach. In addition, the rule we obtain distinguishes every potential outcomes model with different science $\mathbf{P}$, which we consider a minimal requirement for any rule claiming to represent potential outcomes models as causal theories.

Suppose a potential outcomes model $\mathscr{O}$ is equipped with discrete spaces $\Theta,X,Y,\{0,1\}$ and define $D:=[0,1]^{|\Theta|+2|Y|+|X|}$. There is a kernel $\mathbf{B}:D\times\Theta\times X \times Y^2\to \Delta(\mathcal{W})$ such that for every Markov kernel $\mathbf{W}':\Theta\times X\times Y^m\to \Delta(\{0,1\})$ there exists $d\in D$ with $\mathbf{W}'=\mathbf{B}_d$; that is, $D$ indexes the set possible treatment assignment maps. The assumption of discrete spaces is to guarantee the existence of such a $\mathbf{B}$.

From $\mathscr{O}$ and $\mathbf{B}$ we define the \emph{canonical theory} $\mathbf{T}^{\mathscr{O}}$:

\begin{align}
	\mathbf{T}^{\mathscr{O}}:= \begin{tikzpicture}
	\path (0,0) coordinate (A)
	+ (0,-1.65) coordinate (D)
	++ (1,0) coordinate (copy0)
	++ (1,0) coordinate (cent0)
	+(0,1.5) node[kernel] (HPO) {$\mathbf{P}$}
	+(0.5,1.5) coordinate(copy1)
	+(0,-0.5) node[kernel] (HPOC) {$\mathbf{P}$}
	+(0.5,-0.5) coordinate (copy1C)
	++ (1.3,0) coordinate (cent1)
	+(0,0.5) node[kernel] (HW) {$\mathbf{W}$}
	+(0.5,0.5) coordinate (copy2)
	+(0,-1.5) node[kernel] (CW) {$\mathbf{B}$}
	+(0.5,-1.5) coordinate (copy2C)
	++(1,0) coordinate (cent2)
	+ (0,1) node[kernel] (HY) {$\mathbf{Y}$}
	+ (0,-1) node[kernel] (HYC) {$\mathbf{Y}$}
	++(1,0) coordinate (cent3)
	+(0,1.65) node (X) {$X$}
	+(0,1) node (Y) {$Y$}
	+(0,0.5) node (W) {$W$}
	+(0,-0.35) node (XC) {$X_C$}
	+(0,-1) node (YC) {$Y_C$}
	+(0,-1.5) node (WC) {$W_C$};
	\draw (A) -- (copy0);
	\draw (HPO) -- (copy1);
	\draw (HPOC) -- (copy1C);
	\draw (copy0) to [bend left=20] (HPO);
	\draw (copy0) to [bend left=20] ($(HW.west)+(0,-0.1)$);
	\draw (copy0) to [bend right=20] (HPOC);
	\draw (copy0) to [bend right=40] ($(CW.west)+(0,0)$);
	\draw (copy1) edge[out=0,in=180] (HW);
	\draw (copy1C) edge[out=0,in=180] ($(CW.west)+(0,0.15)$);
	\draw (D) -- ($(CW.west)+(0,-0.15)$);
	\draw ($(HPO.east)+(0,0.15)$) -- (X) ($(HPOC.east)+(0,0.15)$) -- (XC) (HY) -- (Y) (HYC) -- (YC) (HW) -- (W) (CW) -- (WC);
	\draw (copy1) edge[out=0,in=180] ($(HY.west)+(0,0.1)$) (copy1C) edge[out=0,in=180] ($(HYC.west)+(0,0.1)$);
	\draw (copy2) to [bend left = 20] ($(HY.west)+(0,-0.1)$) (copy2C) to [bend left = 20] ($(HYC.west)+(0,-0.1)$);
\end{tikzpicture}\label{eq:po_causal_theory}
\end{align}

$\mathbf{T}^{\mathscr{O}}$ is two parallel copies of $\mathscr{H}^{\mathscr{O}}$ where $\mathbf{W}$ is replaced by $\mathbf{B}$ in the lower version.
\begin{theorem}
Given potential outcomes models $\mathscr{O}=\langle \mathbf{P}, \mathbf{W}, \mathbf{Y} \rangle$, $\mathscr{O}'=\langle \mathbf{P}', \mathbf{W}', \mathbf{Y} \rangle$ sharing spaces $\Theta,X,Y,[m]$, then $\mathbf{T}^{\mathscr{O}}=\mathbf{T}^{\mathscr{O}'}$ if and only if $\mathbf{P}=\mathbf{P'}$ and $\mathbf{H}=\mathbf{H}'$.
\end{theorem}

\begin{proof}

Let $\mathbf{T}:=\mathbf{T}^{\mathscr{O}}$ and $\mathbf{T}':=\mathbf{T}^{\mathscr{O}'}$.

If $\mathbf{P}=\mathbf{P}'$ and $\mathbf{H}=\mathbf{H}'$ we clearly have $\mathbf{T}(*\otimes \mathrm{Id}) = \mathbf{T}'(*\otimes \mathrm{Id}):=\mathbf{C}$ as all kernels in the bottom half of \ref{eq:po_causal_theory} ($\mathbf{P},\mathbf{B}$ and $\mathbf{Y}$) are the same by definition. But then $\mathbf{T} = \splitter{0.1}(\mathbf{H}\otimes\mathbf{C}) = \mathbf{T}'$.

Suppose $\mathbf{T}=\mathbf{T}'$ and $\mathbf{P}\neq \mathbf{P}'$. Then there exists some $A\in \mathcal{X}\otimes\mathcal{Y}^2$, $\theta\in \Theta$ such that $\mathbf{P}_\theta (A) \neq \mathbf{P}'_\theta(A)$. Choose $d\in D$ such that $\mathbf{B}_{d,\theta,x,y_0,y_1} = \delta_0$ if $(x,y_0,y_1)\in A$ and $\mathbf{B}_{d,\theta,x,y_0,y_1} = \delta_1$ otherwise. Then $\mathbf{T}^\mathscr{O}_{\theta,d} \Pi_{\RV{W}} (\{0\})  =\mathbf{P}_\theta (A) \neq \mathbf{P}'_\theta(A) = \mathbf{T}^{\mathscr{O}\prime}_{\theta,d} \Pi_{\RV{W}} (\{0\})$, a contradiction. Thus $\mathbf{P}=\mathbf{P}'$. In addition, $\mathbf{H} = \mathbf{T}(\mathrm{Id}\otimes *) = \mathbf{T}'(\mathrm{Id}\otimes *) =\mathbf{H}'$.
\end{proof}

Note that the assignment $\mathbf{W}$ may differ between $\mathscr{O}$ and $\mathscr{O}'$. Suppose $X=\emptyset$, $Y=\{0,1\}$ and for some $\theta$, $\mathbf{P}_\theta = \frac{1}{4}(\delta_{0,0}+\delta_{0,1}+\delta_{1,0}+\delta_{1,1})$. Then $\mathbf{W}_\theta:(y_0,y_1)\mapsto \llbracket y_0=y_1\rrbracket\delta_0 + \llbracket y_0\neq y_1\rrbracket \delta_1$ and $\mathbf{W}'_\theta := 1-\mathbf{W}_\theta$ both yield the same observations $\mathbf{H}_\theta$. It may be desirable that a mapping from PO models to causal theories also distinguishes PO models that differ only on $\mathbf{W}$ - for example, we might want some decision $d\in D$ to always be interpretable as ``in the state $\theta$, raise the probability of treatment above the observed level iff $y_0\neq y_1$'', a decision which would yield different consequences given a theory based on $\mathbf{W}_\theta$ or $\mathbf{W}'_\theta$. 

\section{Potential Outcomes Models Induce Rich Causal Theories}

Though the theory $\mathbf{T}^{\mathscr{O}}$ appears to be quite different in a number of ways from theories induced by a causal graph $\mathbf{T}^\mathcal{G}$, it also features a rich set of decisions. If it is possible to choose any assignment function from $\Theta\times X\times Y^2\to\Delta(\{0,1\})$, then it is (for example) possible to choose a functon that assigns treatment if and only if $y_1 > y_0$ independent of state $\theta$.

As with causal Bayesian networks, for a real decision problem we would like to work with a realistic theory $\mathbf{T}^r$ on a set of decisions $D^r$ that correspond to actions we believe we can actually take. However, we may be willing to accept that the realistic theory $\mathbf{T}^r$ corresponds closely to the rich theory $\mathbf{T}^\mathscr{O}$ with, for example, a limited set of decisions. To illustrate this, consider the problem of evaluating the ``effect of assigning treatment'' vs ``the effect of receiving treatment''. From \citet{shrier_intention--treat_2017}:

\begin{quote}
In public health, we are normally concerned with the effect of assigning a treatment. If we implement a prevention or treatment program that is efficacious only under strict research conditions but people in the real world would not receive it for any possible reason, the program will not be effective. This real-world context is best estimated by the intention-to-treat (ITT) analysis [...]

There are 2 reasons why the average causal effect of receiving a treatment may be more important than the ITT for some people. First, investigators may want to know what the average causal effect of a treatment program would be if they could improve participation in the program. [...] Also, the average causal effect of receiving a treatment is of primary interest to a patient deciding whether or not to take the treatment as recommended.
\end{quote}

Concretely, suppose we have two rich theories $\mathbf{T}^{\mathrm{ITT}}$ and $\mathbf{T}^{\mathrm{RT}}$ modelling effects of intention-to-treat and receiving treatment respectively, and we want realistic theories $\mathbf{T}^p,\mathbf{T}^t$ describing the effects of prescribing treatment and taking treatment respectively. Consider the first decision problem: we have two decisions $D^p=\{d_0,d_1\}$ where $d_1$ corresponds to ``implement a treatment program'' and $d_0$ corresponds to ``do nothing''. Under the intention to treat model $\mathbf{T}^{\mathrm{ITT}}$ it is plausible that these decisions correspond to determinisically setting $\RV{W}=1$ and $\RV{W}=0$ respectively. In detail, we suppose that the consequence of choosing $d_1$ in the pragmatic theory $\mathbf{T}^p$ is the same as the consequence of choosing the decision $e_1\in D^{\mathrm{ITT}}$ such that for all $\theta,x,y_0,y_1$, $\mathbf{B}^{\mathrm{ITT}}_{\theta,d,x,y_0,y_1} = \delta_1$ and analogously $d_0$ corresponds to the element $e_0\in D^{\mathrm{ITT}}$ that sets $\RV{W}$ to 0.

Consider the same problem -- that of implementing a treatment program -- for the rich theory of receiving treatment $\mathbf{T}^{\mathrm{RT}}$. Here, a correspondence between $D^p$ and $D^{\mathrm{RT}}$ is less clear. We may accept that implementing a treatment program corresponds to \emph{some} choice of treatment taking function $\mathbf{B}^{\mathrm{RT}}$, one that is perhaps more likely to result in treatment than that for doing nothing. However, without more information we have only that there is a correspondence between $D^{\mathrm{RT}}$ and $D^p$ and not what this correspondence is. We could, for example, express our uncertainty with a set of possible correspondences or a probability measure over over this set and proceed from there.

Consider the third decision problem, where decisions correspond to taking the treatment, and in particular consider using the rich theory $\mathbf{T}^{\mathrm{ITT}}$. It is very likely that \emph{no} choice of prescription function $\RV{W}^{\mathrm{ITT}}$ is consistent with the test subjects always taking the treatment. In this case we're not just uncertain about the correspondence between rich decisions $D^{\mathrm{ITT}}$ and realistic decisions $D^t$ -- we are are actually confident that there is no such correspondence.

\section{Comparing Induced Causal Theories}

Causal theories induced by CBN and PO models are directly comparable, and the induces theories are typically rather different. For example, a CBN $\mathcal{G}$ defines an intervention operation for every random variable that has been represented as a node of $\mathcal{G}$, which is reflected in $\mathbf{T}^\mathcal{G}$, while an induced PO theory $\mathbf{T}^\mathscr{O}$ will typically not allow any decisions that deterministically set $\RV{Y}$ in all states, and no decisions may affect $\RV{X}$ at all. On the other hand, decisions in a theory $\mathbf{T}^{\mathscr{O}}$ allow $\RV{W}$ to depend arbitrarily on $\RV{X}$ and $\theta$ together, which is not possible for a theory induced by a CBN. Despite these differences, when we move from rich theories to realistic theories we may end up with the same result using either method.

Suppose we have a CBN $\mathcal{G}:=W\rightarrowtriangle Y$, where $\RV{W}$ and $\RV{Y}$ are random variables taking values in some arbitrary spaces $W$ and $Y$. Suppose also that we require a realistic theory $\mathbf{T}^\mathcal{G}:\Theta\times W\to \Delta([\mathcal{W}\otimes\mathcal{Y}]^2)$ where our decisions correspond only to ``hard do interventions'' $do(W=w)$ on $\RV{W}$ under the full CBN theory -- that is, we have no decisions corresponding to do-interventions on $\RV{Y}$ or do-nothing. Then there exist Markov kernels $\mathbf{W}:\Theta\to \Delta(\mathcal{W})$, $\mathbf{Y}:\Theta\times W\to \Delta(\mathcal{Y})$  such that $\mathbf{T}^\mathcal{G}$ can be represented as in the diagram \ref{eq:twovar_ecbn}. Conversely, any causal theory that can be represented in this manner is a candidate for $\mathbf{T}^\mathcal{G}$ (see \ref{sec:cbn_as_ct})
\begin{align}
\begin{tikzpicture}[yscale=0.7]
 \path (0,0) coordinate (T)
  + (0,-1.15) coordinate (D)
  ++(0.5,0) coordinate (copy0)
  ++(1,0) coordinate (n0)
  +(-0.5,0.8) coordinate (copy1)
  +(0,1) node[kernel] (X) {$\mathbf{W}$}
  +(0,-1) node[kernel] (Id) {$\mathbf{Id}_W$}
  +(0.6,-1.15) coordinate (copy2)
  ++(1.2,0) coordinate (n1)
  +(-0.6,1) coordinate (copy3)
  +(0,1) node[kernel] (Y) {$\mathbf{Y}$}
  +(0,-1) node[kernel] (Y1) {$\mathbf{Y}$}
  ++(1,0) coordinate (n2)
  +(0,1.5) node (Xout) {$\RV{W}$}
  +(0,1) node (Yout) {$\RV{Y}$}
  +(0,-0.5) node (Xout1) {$\RV{W}_C$}
  +(0,-1) node (Yout1) {$\RV{Y}_C$};
  \draw (T) -- (copy0);
  \draw (D) -- ($(Id.west)+(0,-0.15)$);
  \draw (copy0) to [bend left] (copy1) to [bend left] (X);
  \draw (copy1) to [bend right] ($(Y.west)+(0,-0.15)$);
  \draw (copy0) to [bend right = 10] ($(Y1.west)+(0,0.15)$);
  \draw ($(Id.east)+(0,-0.15)$) -- ($(Y1.west)+(0,-0.15)$);
  \draw (copy2) to [bend left] (Xout1);
  \draw (copy3) to [bend left] (Xout);
  \draw (X) -- (Y) -- (Yout);
  \draw (Y1) -- (Yout1);
 \end{tikzpicture} \label{eq:twovar_ecbn}
 \end{align}

 Suppose we have a PO model $\mathscr{O}=\langle \mathbf{P}, \mathbf{W}, \mathbf{Y} \rangle$ on $\Theta$, $W$ and $Y$ such that $\mathbf{W}$ depends only on $\Theta$. Suppose also that we require a realistic theory where, similarly to the case above, decisions correspond only to ``setting'' $\RV{W}$ in the standard theory associated with $\mathscr{O}$. Then the resulting theory can be represented by the diagram \ref{eq:twovar_epo}. Conversely, there is a PO model for every causal theory with this representation.

\begin{align}
\begin{tikzpicture}[yscale=0.8]
	\path (0,0) coordinate (A)
	+ (0,-1.65) coordinate (D)
	++ (1,0) coordinate (copy0)
	++ (1,0) coordinate (cent0)
	+(0,1) node[kernel] (HPO) {$\mathbf{P}$}
	+(0,-1) node[kernel] (HPOC) {$\mathbf{P}$}
	++ (1.3,0) coordinate (cent1)
	+(0,0.5) node[kernel] (HW) {$\mathbf{W}$}
	+(0,-1.5) node[kernel] (CW) {$\mathbf{Id}_W$}
	++(1,0) coordinate (cent2)
	+ (0,1) node[kernel] (HY) {$\mathbf{Y}'$}
	+ (0,-1) node[kernel] (HYC) {$\mathbf{Y}'$}
	++(1,0) coordinate (cent3)
	+(0,1) node (Y) {$\RV{Y}$}
	+(0,0.5) node (W) {$\RV{W}$}
	+(0,-1) node (YC) {$\RV{Y}_C$}
	+(0,-1.5) node (WC) {$\RV{W}_C$};
	\draw (A) -- (copy0);
	\draw (copy0) to [bend left=20] (HPO);
	\draw (copy0) to [bend left=20] ($(HW.west)+(0,-0.1)$);
	\draw (copy0) to [bend right=20] (HPOC);
	\draw (D) -- ($(CW.west)+(0,-0.15)$);
	\draw (HY) -- (Y) (HYC) -- (YC) (HW) -- (W) (CW) -- (WC);
	\draw (HPO) -- (HY) (HPOC) -- (HYC);
	\draw ($(HW.east)+(0,0.1)$) to [bend left = 20] ($(HY.west)+(0,-0.1)$) ($(CW.east) + (0,0.1)$) to [bend left = 20] ($(HYC.west)+(0,-0.1)$);
\end{tikzpicture} \label{eq:twovar_epo}
\end{align}

In the lower diagram we can define $\mathbf{Y}^*:= (\mathbf{P}\otimes\mathbf{Id})\mathbf{Y}'$ to produce a diagram that is equivalent to \ref{eq:twovar_ecbn}. While $\mathbf{P}$ and $\mathbf{W}$ are arbitrary, $\mathbf{Y}'$ has a particular form. It is still possible to express a general kernel $\mathbf{Y}:\Theta\times W\to \Delta(\mathcal{Y})$ in the form of $\mathbf{Y}^*$; let $\mathbf{P}:\theta\mapsto \mathbf{Y}_{\theta,0}\otimes\mathbf{Y}_{\theta,1}$. Then $\mathbf{Y}^*=\mathbf{Y}$. Thus under the restrictions given, the sets of viable realistic theories derived from the CBN and the PO models are exactly the same.

% We will propose, somewhat weakly, that given a well-specified potential outcomes model, decisions correspond to modifications of $H_W$. This supposition generalises the approach to policy modelling found in \cite{heckman_policy-relevant_2001.} As there is no general way to identify an arbitrary set of decisions $D$ with different assignment functions $H_W$, we offer (weakly) that the answer to the question in the paragraph above is ``no''. However, given knowledge of the ``decision-influenced treatment assignment'' $C_W:\Theta\times D\to \{0,1\}^n$, we \emph{can} define a causal theory via the four elements $\langle H_{PO}, H_W, H_Y, C_W\rangle$. We've supposed here there are $n$ ``observational'' units and $n$ ``consequence'' units, a restriction that simplifies the notation and is fairly easy to lift. Concretely, the causal theory is:

% First, suppose a potential outcomes model $\langle H_{PO}, H_W, H_Y \rangle$ is used in the evaluation of a public program, and it is intended to inform a choice between decisions $d=0$: cut funding or $d=1$: maintain funding. Suppose we also have $C_W$ such that
% \begin{itemize}
% \item $d=1$ leaves the assignment function unchanged; $C_W(\theta,1;A) = H_W(\theta;A)$ for all $\theta, A$
% \item $d_0$ means no-one receives treatment; $C_W(\theta,0;A) = \delta_0(A)$ for all $\theta, A$.
% \end{itemize}

% Supposing $Y=[0,1]$ and positing a utility function $u:=\pi_{Y}$, we can compare the utilities of decisions $0$ and $1$ for state $\theta$ by $Tu(\theta,1)-Tu(\theta,0)$ (in more familiar notation, $\mathbb{E}_{T(\theta,1;\cdot)}[u] - \mathbb{E}_{T(\theta,0;\cdot)}[u]$). By construction, if we let $H^*$ be the ``expanded'' version of $H$ above, $Tu(\theta,1)-Tu(\theta,0)=H^*_{\theta|\RV{W}}\pi_{\RV{Y}(1)}(1) - H^*_{\theta|\RV{W}}\pi_{\RV{Y}(0)}(1)$; this is because only the units for which $\RV{W}=1$ have different outcomes under the different decisions. This quantity is known as the \emph{effect of treatment on the treated} (ETT) \citep{heckman_randomization_1991}. 

% \todo[inline]{ETT is common in the causal literature, but this is as far as I know the first example where it is formally derived as the difference between outcomes under different decisions, so I should probably do it properly}



% We recall the abstract state space $\Theta$ and define a sequence of measurable ``potential outcomes'' $\RV{Y}_i^0,\RV{Y}_i^1:\Theta\to Y$ and measurable ``background facts'' $\RV{X}^*_i:\Theta\to X$ for all $i\in[n]$. As $\Theta$ is \emph{not} the sample space of a statistical experiment we will not call potential outcomes or background facts random variables. In addition, we have a Markov kernel $H:\Theta\to \Delta(E)$ for some measurable space $E$ and random variables $\RV{Y}_i:E\to Y$ and $\RV{W}_i:E\to \{0,1\}$, $\RV{X}_i:E\to X$. Let $\RV{X}$ stand for the composite variable made from the entire sequence of $\RV{X}_i$ and similar for other RVs. This is consistent with Rubin's approach:
% \begin{quote}
% [out of $\{\RV{X},\RV{Y}^0,\RV{Y}^1,\RV{X}^*\}$] the vector $\RV{W}$ is the only random variable; the science is regarded as fixed and waiting to be partially revealed by the assignment mechanism.
% \end{quote}

% Potential outcomes poses restrictions on $\Theta$ as well as $H$. A very common assumption is the \emph{stable unit treatment value assumption} (SUTVA). This consists of two parts:
% \begin{align}
% \forall e\in E, \theta\in \Theta, \RV{W}_i(e) = w \implies H_\theta F_{\RV{Y}_i} = \delta_{\RV{Y}^w_i(\theta)}\\
% \forall \mathbf{w}:=(w_0,...,w_i,...,w_n)\in \{0,1\}^n, \RV{Y}^{\mathbf{w}}_i = \RV{Y}^{w_i}_i
% \end{align}

% We are not aware of a similarly formal statement of SUTVA anywhere.


% The second an assumption on $\Theta$ while the first is an assumption on $H_\theta$.

% A key point here is \emph{a potential outcomes model is a statistical experiment}. In fact, we can give a concrete representation of the model Rubin discusses. Let $W:=\{0,1\}$, $H_W:\Theta\to \Delta(W^n)$ be a Markov kernel representing the treatment assignment and let $H_Y:\Theta\times W^n\to \Delta(Y^n)$ be the deterministic Markov kernel $H_Y:(\theta,\mathbf{w})\mapsto (1-\mathbf{w}) \odot \delta_{\RV{Y}^0(\theta)} + \mathbf{w} \odot \delta_{\RV{Y}^1(\theta)} $ where $\odot$ refers to the elementwise product. Then, letting $E:=X^n\otimes Y^n\otimes W^n $, the statistical experiment $H$ is the Markov kernel

% \begin{align}
% H:=\begin{tikzpicture}
% \path (0,0) coordinate (A)
% ++ (0.5,0) coordinate (copy0)
% ++ (1,0) node[kernel] (HW) {$H_W$}
% +  (0,0.5) node[kernel] (FYY) {$F_{\RV{Y}^0 \RV{Y}^1}$}
% +  (0,1) node[kernel] (FX) {$F_{\RV{X}^*}$}
% ++ (0.5,0) coordinate (copy1)
% ++ (1.3,0) node[kernel] (HY) {$H_Y$}
% ++ (0.5,0) coordinate (Y)
% + (0,-0.5) coordinate (W)
% + (0,1) coordinate (X);
% \draw (A) -- (HW) -- (HY) -- (Y);
% \draw (copy0) to [bend left] (FYY);
% \draw (copy0) to [bend left] (FX);
% \draw (FX) -- (X);
% \draw (FYY) to [bend left] ($(HY.west)+(0,0.1)$);
% \draw (copy1) to [bend right] (W);
% \end{tikzpicture}
% \end{align}

% An common assumption that permits inference is \emph{ignorability}. A treatment of this assumption in the present work would require a deeper dive into the graphical notation introduced here. For now it is sufficient that a potential outcomes model is a statistical experiment. For details on ignorability, we refer readers to \cite{rubin_causal_2005}.

% \todo[inline]{I actually think the graphical notation is a superior means of dealing with ignorability; it is essentially a ``partial string lifting'' condition akin to my ``universal optimisability''. Perhaps as a result of \emph{not} using this notation, I think Rubin gets a bit confused: he assumes $H_W$ depends only on $\RV{X}^*,\RV{Y}^0,\RV{Y}^1$, introduces a limited prior, makes a mistake, and then doesn't clearly show how ignorability helps (not surprising, as we can always do fine if we know $H_W$). The real point is, however, that $H_W$ might have further dependence on the state, but if we know ignorability holds then we need no further information about this dependence.}




% \begin{align}
% H=\begin{tikzpicture}
% \path (0,0) coordinate (A)
% ++ (0.5,0) coordinate (copy0)
% ++ (1,0) node[kernel] (HW) {$H_W$}
% +  (0,0.5) node[kernel] (FYY) {$F_{\RV{Y}^0 \RV{Y}^1}$}
% +  (0,1) node[kernel] (FX) {$F_{\RV{X}^*}$}
% +(0.5,1) coordinate (copy1)
% ++ (1.5,0) node[kernel] (HY) {$H_Y$}
% ++(0.5,0) coordinate (copy2)
% +(0.5,0.5) node[kernel] (HWP) {$H_W'$}
% ++ (1,0) coordinate (Y)
% + (0,0.5) coordinate (W)
% + (0,1) coordinate (X);
% \draw (A) -- (HW) -- (HY) -- (Y);
% \draw (copy0) to [bend left] (FYY);
% \draw (copy0) to [bend left] (FX);
% \draw (FX) -- (X);
% \draw (FYY) to [bend left] ($(HY.west)+(0,0.1)$);
% \draw (copy1) to [bend right = 20] ($(HWP.west)+(0,0.1)$);
% \draw (copy2) to [bend left] ($(HWP.west)+(0,-0.1)$) (HWP) -- (W);
% \end{tikzpicture}
% \end{align}

% \subsection{potential outcomes models via Structural Equation Models}


