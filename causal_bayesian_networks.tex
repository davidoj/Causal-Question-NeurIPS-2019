\section{Causal Bayesian Networks}

A causal Bayesian network is an example of an identifiable causal theory. Given a measurable space $(X,\mathcal{X})$ where $X=\times_{i\in [N]} X^i$, a decision space $D = \times_{i\in [N]} X^i\cup\{*\}$ and a causal graph $\mathcal{G}$ over nodes $\mathbf{V}=\{V^i|i\in [N]\}$, the graph $\mathcal{G}$ maps each probability distribution $\mu\in \Delta(\mathcal{X})$ to a unique consequence $D\to \Delta(\mathcal{X})$.

The CBN convention is to call the elements of the decision space $D$ ``interventions'' and denote then with $P(\cdot|do(\cdot\cdot))$ notation. In the first definition below, we instead denote interventions with indices on the probability distribution, and introduce the special $*$ object to denote a passive intervention.

\begin{definition}[Causal Bayesian Network]\label{def:CBN}
The definition here follows \cite{pearl_causality:_2009}.

Consider a directed acyclic graph $\mathcal{G}$ with nodes $\mathbf{X}=\{\RV{X}^i|i\in [N]\}$, a measurable space $(E,\mathcal{E})$ and a set of random variables $\RV{X}^i:E\to X^i$ and let $X=\times_{i\in[N]} X^i$. For each $x\in \times_{i\in [N]} X^i\cup \{*\}$ suppose we have an \emph{interventional distribution} $P^{x}\in \Delta(\mathcal{E})$, and let the set of all such distributions be denoted $\mathbf{P}^{X\cup\{*\}}$. Let $P^*$ be the passive distribution given by the intervention $x = (*,...,*)$.

Given any $x\in X\cup\{*\}$ let $S(x)\subset[N]$ be the set of all indices $i$ such that $x^i\neq *$. The graph $\mathcal{G}$ is a causal Bayesian network compatible with $\mathbf{P}^{X\cup\{*\}}$ iff for all $x\in X$ and $S(x)\subset [N]$:
\begin{enumerate}
    \item $P^{x}_{\RV{X}}$ is compatible with $\mathcal{G}$ for all $x\in \cup_{i\in [N]} X^i\cup \{*\}$
    \item $P^x_{\RV{X}}(\RV{X}^{S(x)})=\delta_{x^{S(x)}}(\RV{X}^{S(x)})$
    \item For $i\in S^C$, $P^x_{\RV{X}}(\RV{X}^i|\PA{\mathcal{G}}{\RV{X}^i})=P^*_\RV{X}(\RV{X}^i|\PA{\mathcal{G}}{\RV{X}^i})$, $P^x$-almost surely
\end{enumerate}
\end{definition}

The above three conditions are sufficient that, given some graph $\mathcal{G}$ and $P^*_{\RV{X}}\in \Delta(\mathcal{X})$, one obtains a unique set of interventional distributions $\mathbf{P}_{\mathcal{G}}^{X\cup\{*\}}$ (this follows from the truncated factorisation property given by \cite{pearl_causality:_2009}). Identifying the decision set $D$ with $\times_{i\in [N]} X^i\cup\{*\}$, note that the map $\kappa^P_\mathcal{G}:D\to \Delta(\mathcal{X})$ given by $d\mapsto P^d_{\mathcal{G}}$ looks like a consequence map, which in fact it is (as established by Theorem \ref{th:cbn_MK}). The set of pairs $\{(P^*_{\RV{X}}, \kappa^P_\mathcal{G})|P^*_{\RV{X}}\in \Delta(\mathcal{X})\}$ is then a causal theory $\mathscr{T}_\mathcal{G}$.

\begin{theorem}\label{th:cbn_MK}
Given a graph $\mathcal{G}$, a measurable set $(E,\mathcal{E})$ and a decision set $D=\times_{i\in [N]} X^i\cup\{*\}$, let $P^x\in \Delta(\mathcal{E})$ be an interventional distribution compatible with $\mathcal{G}$ as defined in Definition \ref{def:CBN}. 

Then the map $\kappa_{\mathcal{G}}:D\to \Delta(\mathcal{X})$ given by $x\mapsto P^x$ is a Markov kernel.
\end{theorem}

The proof is given in Appendix \ref{app:cbn_ct}.

\subsection{Extending the theory induced by a CBN}

The causal theory associated with a given graph $\mathcal{G}$ is in general incomplete in that it does not associate a consequence with some distributions on $\Delta(\mathcal{X})$. In particular, if certain conditional independences are implied by $\mathcal{G}$, then probability distributions for which these conditional independences do not hold do not appear in the associated causal theory - only \emph{compatible} distributions are represented. This follows from condition 1 of Definition \ref{def:CBN}. While a theory doesn't have to feature a causal state for every possible distribution, it usually isn't reasonable to assume \emph{a priori} that certain conditional independences hold. In this case, it is necessary to extend the causal theory associated with $\mathcal{G}$ to cover distributions that are incompatible with $\mathcal{G}$.

The choice of how to extend the theory can be important. For discrete and jointly Gaussian distributions, conditional independences are associated with lower dimensional subspaces of the set of distributions\cite{meek_strong_1995}. Given causal theory $\mathscr{T}\subset$ and a $\sigma$-algebra $\mathcal{T}$, if we have a prior $\xi\in \Delta(\mathscr{H}\times \mathscr{K})$ such that the marginal $P^\xi(A)$ for $A\in \Delta(\mathscr{H})$ admits a density $P^\xi(A) = \int_A p^\xi(x)dx$ then this prior will assign 0 weight to any subset of $\mathscr{T}$ for which some conditional independence holds, and so for any $\mathcal{G}$ which is not fully connected the Bayes risk of any decision function $J$ is determined entirely by the extension of $\mathscr{T}$ to the set of distributions incompatible with $\mathcal{G}$.

An example follows. Suppose we have the following graph $\mathcal{G}$:

\begin{figure}
    \centering
     \begin{tikzpicture}[-latex,auto ,node distance =1 cm and 2cm ,on grid ,
    semithick ,
    vb/.style ={ circle ,top color =white , 
    draw , text=blue , minimum width =0.6 cm},
    kernel/.style={rectangle,draw}
    ]

    \node[vb] (A) {$A$};
    \node[vb] (B) [right = of A] {$B$};
    \node[vb] (C) [right = of B] {$C$};
    \draw (A) -- (B);
    \draw (B) -- (C);
    \end{tikzpicture}
    \caption{Simple causal Bayesian network $\mathcal{G}$}
    \label{fig:simple_cbn}
\end{figure}

Associated with this graph is the sample space $(E,\mathcal{E})=(\{0,1\}^3,\mathscr{P}(\{0,1\}^3)$ where $\mathscr{P}$ denotes the power set, and random variables $\RV{A},\RV{B}$ and $\RV{C}$ taking values in $\{0,1\}$. The set of possible distributions $\Delta(\mathcal{E})$ can be identified with the probability simplex in $\mathbb{R}^8$. For simplicity, suppose that only $A$ can be intervened on; that is, the decision space $D=A\cup\{*\}$ with the decision $\RV{D}_A=x$ for $x\in A$ having the usual interpretation as a hard intervention on $A$. We could alternatively assign infinite costs to interventions on $B$ and $C$, but this adds unnecessary complexity.

$\mathcal{G}$ implies $\RV{A}\CI \RV{C} | \RV{B}$. We have a theory $\mathscr{T}_{\mathcal{G}}$ associated with the graph $\mathcal{G}$ containing the state
\begin{align}
    (\nu,x\mapsto P^\nu(\RV{B}|\RV{A}=x) ) \label{eq:ocbn}
\end{align}
for every compatible $\nu$ . 

Consider two options for extending this to distributions $\nu$ incompatible with $\mathcal{G}$:
\begin{itemize}
    \item $\mathscr{T}_{\mathcal{G}}'$ assigns the causal states given by the union over all DAGs on the set of nodes $\{A, B, C\}$
    \item $\mathscr{T}_{\mathcal{G}}^\square$ assigns the causal states given by the union over all supergraphs of $\mathcal{G}$ on $\{A, B, C\}$
    \item $\mathscr{T}_{\mathcal{G}}^\circ$ assigns the causal states given by $\mathcal{G}$ and ignores the inconsistency of $\nu$
\end{itemize}

In the first theory, for every DAG featuring $A\to B$ there is a DAG featuring $B\to A$; in addition, there are a number of DAGs with no arrow between $A$ and $B$. Therefore any prior $\xi$ that admits a density over $\Delta(\mathcal{E})$ and assigns equal weight to each causal state in $\mathcal{T}$ featuring the same distribution will generate a posterior that assigns a weight of more than 0.5 to the possibility that the marginal distribution of $\RV{B}$ is independent of whatever decision $\RV{D}_A$ is chosen. This remains true even if the observed data consist of a very large number of IID observations distributed according to some $\pi$ for which it is indeed holds that $\RV{A} \CI_\pi \RV{C} | \RV{B}$.

The second theory, on the other hand, yields a set consequences that are ``close'' to the consequence given by the original graph $\mathcal{G}$ provided the distribution $\mu$ is sufficiently ``close'' to a distribution $\nu$ for which $\RV{A} \CI_\nu \RV{C} | \RV{B}$. Note that, marginalising over $\RV{A}$ and $\RV{C}$ and ignoring the passive action, the theory $\mathscr{T}^\square_{\mathcal{G}}$ associates two consequences with every incompatible $\mu$:
\begin{align}
    &(\mu,x\mapsto P^\mu(\RV{B}|\RV{A}=x) )\label{eq:cbn_s1}\\
    &(\mu,x \mapsto \sum_c P^\mu(\RV{B}|\RV{A}=x,\RV{C}=c)P^\mu(\RV{C}=c)) \label{eq:cbn_s2}
\end{align}

Note that \ref{eq:cbn_s1} matches the pattern for states in the original graph \ref{eq:ocbn}. Define the consequences $\kappa^\circ := x\mapsto P^\mu(\RV{B}|\RV{A}=x)$ and $\kappa^\square:= x \mapsto \sum_c P^\mu(\RV{B}|\RV{A}=x,\RV{C}=c)P^\mu(\RV{C}=c))$, leaving the $\mu$-dependence implicit.

Consider some $\mu$ for which $\RV{A} \CI_\mu \RV{C} | \RV{B}$ holds approximately. That is, for some $\epsilon>0$
\begin{align}
    \left|\sum_c P^\mu(\RV{B}|\RV{A}=x,\RV{C}=c)P^\mu(\RV{C}=c)-P^\mu(B|A=x)\right| &< \epsilon \label{eq:app_ci}
\end{align}

Suppose that we have some loss such that $L(\rho)= \mathbb{E}_\rho[\RV{B}] + k$. Noting that $\mathscr{T}^\circ_\mathcal{G}$ and $\mathscr{T}^\square_\mathcal{G}$ agree on $\kappa^\circ$, we can bound the disagreement between the two theories with
\begin{align}
    |R(J,\kappa^\square,\mu) - R(J,\kappa^\circ,\mu)| &=  \left|\mathbb{E}_{\mu J \kappa^\square} [\RV{B}] - \mathbb{E}_{\mu J \kappa^\circ} [\RV{B}]\right|\\
        &\leq \max_x \left|\sum_c P^\mu(\RV{B}|\RV{A}=x,\RV{C}=c)P^\mu(\RV{C}=c)-P^\mu(B|A=x) \right|\\
        &< \epsilon
\end{align}

The stipulation that the prior $\xi$ was such that the marginal distribution over $\Delta(\mathcal{E})$ admitted a density may be controversial. It is consistent with the notion that ``there are no true parametric zeros'' endorsed by many statisticians (for example  \cite{gelman_bayesian_2010,meehl_theory-testing_1967,berkson_difficulties_1938}). Furthermore, if conditional independences rarely hold precisely, then learners based on the theory $\mathscr{T}_{\mathcal{G}}'$ may usually converge to a state of skepticism even given a prior that assigns nonzero weight to the set of compatible probability distributions because the data are usually drawn from a distribution from which this independence does not hold.

\textbf{TODO (maybe)} A useful property to consider of causal theories is whether determining the data generating distribution $\mu$ is ``close'' to $\mu_0$ implies that the risk is ``close'' to $R(J,\mu_0,\kappa_0)$ for all $(\mu_0,\kappa_0)$ in $\mathscr{T}$. One has to choose a reasonable notion of closeness. There are possible results in the spirit of the example above for Bayesian networks.

\section{Potential Outcomes}

\textbf{Todo: } This story could be made stronger starting from the proposition that using PO or anything else, you still need to rate the desirability of available decisisons somehow.

Potential outcomes provide an alternative means to discuss causal effects. The standard setup posits a joint distribution between observed data $\RV{X}$, a treatment $\RV{Z}$ taking values in $[N]$ and several ``potential outcomes'' $\RV{X}_i$, $i\in [N]\setminus\{0\}$. At a minimum, the consistency condition is usually asserted (\cite{richardson2013single}): $\RV{Z}=i$ implies $\RV{X}_i=\RV{X}$. 

We modify this setup somewhat in order to analyse it in terms of a causal theory. We believe these choices are reasonable, but there is an element of interpretation involved here. For clarity every variable gets a subscript and $\RV{X}_{ob}$, $\RV{Z}_{ob}$ are random variables representing outcomes and treatments in the observed data. $\RV{X}_i, \RV{Z}_i$, $i\geq 0$ are random variables representing outcomes and treatments in consequence of choosing a decision $\RV{D}=i$ deterministically. Note that we do not necessarily have a ``passive decision'' as we did with CBNs. Finally, we work with a slightly weaker ``almost certain consistency'':

\begin{align}
    P(\RV{X}_i,\RV{X}_{ob}|\RV{Z}_{ob}=i,\RV{Z}_i=i)=\mathds{1}_{\RV{X}_{ob}=\RV{X}_i} \qquad\text{ with probabiliy 1}\label{eq:consistency}
\end{align}

Conditioning on $\RV{Z}_i=i$ is redundant under the usual assumption that $P(\RV{Z}_i) = \delta_i(\RV{Z}_i)$.

While there appears to be a natural identification of ``potential outcomes'' with consequences, observed data with observed state and treatments with decisions in a causal theory, it is usually not possible to represent a joint distribution obeying Condition \ref{eq:consistency} with a causal theory. Take the spaces $D,X,Z=\{0,1\}$ and suppose we have a causal theory $\mathscr{T}$ consisting of pairs $(\kappa,\mu)$ where $\mu\in\Delta(\mathcal{X}\otimes\mathcal{Z})$ and $\kappa$ is a Markov kernel from $D\to \Delta(\mathcal{X}\otimes\mathcal{Z})$. To construct a joint distribution between $\RV{X}_{ob}$ and $\RV{X}_i$ for $i\in \{0,1\}$ we take some deterministic decision function $J_i:X\times Z\to \Delta(\mathcal{D})$ where $J_i:(x,z;d)\mapsto \delta_i(d)$. For $A,C\in \Delta(\mathcal{X}\otimes\mathcal{Z})$, $B\in \Delta(\mathcal{D})$ we compose the objects as 
\begin{align}
    \xi(A\times B\times C) =  \int_B \int_A  \kappa(y; C) \delta_i(dy) \mu(dx\times dz)
\end{align}

For $\alpha\in\{ob,0,1\}$ take random variables $\RV{X}_\alpha:(X\times Z)^2\times D\to X$, $\RV{Z}_\alpha:(X\times Z)^2\times D\to X$ and $\RV{D}:(X\times Z)^2\times D\to D$ defined by projections $\RV{X}_\alpha:((x_{ob},z_{ob}),(x_i,z_i),d)\mapsto x_\alpha$, $\RV{Z}_\alpha$ similarly and $\RV{D}:((x_{ob},z_{ob}),(x_i,z_i),d)\mapsto d$. It is then straightforward to show that $(x,z,d))\mapsto \kappa(d; C)$ is a version of the conditional probability $P^\xi(\RV{X}_i|\RV{D},\RV{X}_{ob},\RV{Z}_{ob})$, which implies 
\begin{align}
    \RV{X}_i&\CI_\xi \RV{X}_{ob}|\RV{D}, \RV{Z}_{ob}
\end{align}
For any choice of $J_i,\mu,\kappa$. Noting that $J_i$ is deterministic, we also have
\begin{align}
    \RV{X}_i&\CI_\xi \RV{X}_{ob}|\RV{Z}_{ob} \label{eq:decision_d_sep}
\end{align}
Conditions \ref{eq:consistency} and \ref{eq:decision_d_sep} can hold simultaneously only if $\RV{X}_i$ and $\RV{X}_{ob}$ are deterministic conditional on $\RV{Z}_{ob}$. This is usually not the case.

In order to facilitate nontrival joint distributions between obsevations and potential outcomes, we introduce a \emph{generalised consequence}:

\begin{definition}[Generalised consequence]
Given a measurable consequence space $(F,\mathcal{F})$, a sample space $(E,\mathcal{E})$ and a measurable decision set $(D,\mathcal{D})$, a Markov kernel $\kappa:D\times E \to \Delta(\mathcal{F})$ is a generalised consequence.
\end{definition}

\begin{definition}[Generalised causal theory]
A generalised causal theory is the analogue of a causal theory with the consequence replaced by a generalised consequence.
\end{definition}

Given $D,X,Z$ as before, we provide an explicit construction respecting \ref{eq:consistency}. Here, for convenience, we identify $E=F=X\times Z$. For $x\in X$, $z\in Z$, $d\in D$ and $G\in \mathcal{X}$, $H\in \mathcal{Z}$ consider the kernel

\begin{align}
    \iota: (d,x,z;G\times H) \mapsto \delta_d(H)(\delta_z(H) \delta_x(G) + (1-\delta_z(H)) \iota'(d,x,z;G))
\end{align}

Where $\iota'$ is an arbitrary Markov kernel $D\times X\times Z\to \Delta(\mathcal{X}\otimes\mathcal{Z})$. It is straightforward to check that $\iota$ is a Markov kernel. Take the Consider the distribution given by
\begin{align}
    \zeta (A\times B\times C) =  \int_B \int_A  \iota(y,x,z; C) \delta_i(dy) \mu(dx\times dz)
\end{align}
And random variables $\RV{X}_i$, $\RV{Z}_i$ and $\RV{D}$ as before. Then
\begin{align}
    P^\zeta(\RV{X}_i=j,\RV{X}_{ob}=k|\RV{Z}_{ob}=i)P^\zeta(\RV{Z}_{ob}=i) &= \sum_{m,n} \iota(n,k,i;\{j,m\}) \delta_i(\{n\}) \mu(k,i)\\
     &= \sum_{m,n} \delta_n(m)[\delta_i(m) \delta_k(j) + (1-\delta_i(m))\iota'(n,k,i;\{j,m\})]\delta_i(\{n\}) \mu(k,i)\\
     &= \delta_k(j) \mu(k,i)
\end{align}

Which implies \ref{eq:consistency}.

\subsection{Causal Theories and Generalised Causal Theories}


A generalised causal decision problem is a causal decision problem featuring a generalised causal theory and a loss $L:\Delta(\mathcal{E}\otimes\mathcal{D}\otimes\mathcal{F})\to[0,\infty]$. There is a straightforward identification of causal theories with generalised causal theories, befitting the name. We might also ask when the extra structure of a generalised causal decision problem is needed.

Given an ordinary consequence $\kappa:D\to \Delta(\mathcal{F})$, we can trivially construct a generalised consequence $\iota:(d,e;A)\mapsto \kappa(d;A)$. In addition, given a loss $L:\Delta(\mathcal{D}\otimes\mathcal{F})\to[0,\infty]$ we can construct $L':\Delta(\mathcal{E}\otimes \mathcal{D}\otimes\mathcal{F})\to[0,\infty]$ by $L':\mu\mapsto L(\mu(E\times \cdot \times \cdot \cdot))$.

Given a generalised consequence $\iota:D\times E\to \Delta(\mathcal{F})$ and a hypothesis class $\mathscr{H}\subset\Delta(\mathcal{F})$, we can construct a causal theory $\mathscr{T}_{\iota,\mathscr{H}} = \{(d\mapsto (\mu\otimes \delta_d)\iota,\mu)|\mu\in \mathscr{H}\}$. This causal theory ``forgets'' the joint structure induced by $\iota$. For many practical problems, this extra structure is unnecessary.

Suppose $E=F=\{0,1\}^\mathbb{N}$ and $\RV{X}_{<N}=\otimes_{i\in [N-1]} \underline{\RV{X}_i}$ represents the ``past'' data while $\RV{X}_{\geq N}=\otimes_{i\geq N} \underline{\RV{X}_i}$ represents ``future'' data. Then, given some loss $L':\Delta(\mathcal{E}\otimes \mathcal{D}\otimes\mathcal{F})\to[0,\infty]$ that depends only on the distribution of the future data $\RV{X}_{\geq N}$ and $\RV{D}$, and if 

If a loss function over $\Delta(\mathcal{D}\otimes\mathcal{F})$ is sufficient to describe our preferences then any counterfactual decision problem can be posed as a regular causal decision problem.

\subsubsection{Acyclic Structural Equation Models}

An acyclic structural equation model can be understood as a special case of a generalised consequence. Recall that an acyclic structural equation model is a set of equations $M=\{X^i = f(X^{<i},\epsilon^i)|i\in[N]\}$ along with an intervention operation that replaces the right hand side of an arbitrary subset of equations with an arbitrary set of (allowable) chosen values. Identify the sample space $E=\mathbb{R}^N$ as the space from which the noises $\epsilon=(\epsilon^0,..,\epsilon^N)$ are drawn the decision set $D$ with the set of allowable interventions (including non-interventions) and $F$ as the space in which $X=(X^0,...,X^N)$ lives. Then $M$ is a function from $D\times E\to F$. We can associate the function $M$ with the kernel $\kappa_M: D\times E\to \Delta(\mathcal{F})$ by $\iota_M:(d,e;A)\mapsto \delta_{M(d,e)}(A)$.

An acyclic SEM $M$ with independent noises can be associated with a causal theory. Take a hypothesis class $\mathscr{H}\subset\Delta(\mathcal{E})$ such that for every $\mu\in\mathscr{H}$ the noises are jointly independent. Then we can associate such an SEM with the causal theory
\begin{align}
    \mathscr{T} = \{(\iota_M,(\mu\otimes \delta_*)\iota_M )|\mu\in\mathscr{H}\}
\end{align}
Where $\delta_*$ is the distribution over $D$ that assigns weight 1 to the non-intervention $*$.