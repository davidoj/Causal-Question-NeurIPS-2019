To fully define the respective CDPs, suppose in both cases the loss is $L:\xi\mapsto 0.6\mathbb{E}_\xi[g(\RV{D}_A)] - \mathbb{E}_{\xi}[\RV{B}] - l^*$ where $g:\{0,1,*\}\to \{0,1\}$ is given by $g:x\mapsto x$ for $x\in \{0,1\}$ and $*\mapsto 0$. That is, $\RV{B}=1$ is desirable and setting $\RV{D}_A=1$ is a costly action. $l^*$ is some constant that ensures the minimal loss is 0.

Finally, suppose the given data is are IID samples from some distribution $\pi\in \Delta(\sigma(\{0,1\}^3))$ such that $P^\pi(\RV{B}|\RV{A}=a)=\delta_a(\RV{B})$. A naive application of $\mathcal{G}$ would then suggest that the consequence $\kappa$ were such that for any stochastic decision $\eta\in \Delta(\mathcal{D})$, $P^{\eta {(I_D\otimes \kappa)}}(\RV{B}|\RV{D}_A = x) =\delta_x(\RV{B})$ for $x\in\{0,1\}$. If $P^\pi(A=1)<0.4$ we then have $\delta_1(\RV{D}_A)$ as the optimal decision.

Consider the Bayes risk for such a problem (a similar problem can be constructed, but is more complicated, using Bayes risk), and suppose we have a learning rule that  This requires assigning a prior to causal states in $\mathscr{T}_{\mathcal{G}}'$ and $\mathscr{T}_{\mathcal{G}}^\square$- we will suppose that this prior that admits a density on the 8-simplex $\Delta(\sigma(\{0,1\}^3))$. In particular, the prior assigns 0 weight to any set $\mathscr{P}\subset\Delta(\sigma(\{0,1\}^3))$ with 0 volume. This is not an uncontroversial choice, but it is compatible with the view that ``there are no true parametric zeros'' endorsed by many statisticians (for example  \cite{gelman_bayesian_2010,meehl_theory-testing_1967,berkson_difficulties_1938}). Where a theory contains more than one state with a given distribution, we give these states equal weight. 

Note that the conditional independence $A\perp_\mathcal{G} C | B$ is associated with a lower dimensional subspace of $\Delta(\sigma(\{0,1\}^3))$ defined by 
\begin{align}
    \mu_{000}\mu_{101}-\mu_{100}\mu_{001}&=0\label{eq:ci0}\\
    \mu_{010}\mu_{111}-\mu_{110}\mu_{011}&=0 \label{eq:ci}
\end{align}
Hence any distribution compatible with $\mathcal{G}$ is in fact assigned 0 weight in our prior. Furthermore, for every graph with an arrow $A\to B$ there is a graph with an arrow $B\to A$; therefore the prior assigns at least a weight of 0.5 to the possibility that $\RV{B}$ is independent of $\RV{D}_A$ in the decision-consequence joint distribution. The gain from the decision $\RV{D}_B=1$ is therefore ``capped'' at 0.5, which is less than the direct cost of the decision. As such, any decision function $J$ that assigns nonzero weight to $\RV{D}_B = 1$ given \emph{any data} is dominated by any function that always assigns zero weight to this decision. This is despite the fact that, as noted above, the optimal stochastic decision should naively be $\delta_1(\RV{D}_B)$.

Consider instead the theory $\mathscr{T}^\square_{\mathcal{G}}$. As before, 0 weight is assigned to the causal states associated with $\mathscr{T}_{\mathcal{G}}$. On the other hand, given some incompatible $\mu$, $\mathscr{T}^\square_{\mathcal{G}}$ yields the following pair of states (for simplicity, marginalising over $\RV{A}$ and $\RV{C}$ that are irrelevant to the loss and ignoring the passive action):
\begin{align}
    &(\mu,x\mapsto P^\mu(\RV{B}|\RV{A}=x) )\label{eq:cbn_s1}\\
    &(p,x \mapsto \sum_c P^\mu(\RV{B}|\RV{A}=x,\RV{C}=c)P^\mu(\RV{C}=c)) \label{eq:cbn_s2}
\end{align}

Suppose Eq's \ref{eq:ci0} and \ref{eq:ci} hold approximately for some $\mu$. That is, the absolute value of the expression on the left hand side is less than some $\epsilon>0$ in each case. Then we have
\begin{align}
    \left|P^\mu(\RV{B}|\RV{A}=x,\RV{C}=0) - P^\mu(\RV{B}|\RV{A}=x,\RV{C}=1) \right| &< \frac{\epsilon}{P^\mu(\RV{A}=x,\RV{C}=0) P^\mu(\RV{A}=x,\RV{C}=1)}\\
    \left|\sum_c P^\mu(\RV{B}|\RV{A}=x,\RV{C}=c)P^\mu(\RV{C}=c)-P^\mu(B|A=x)\right| &< \frac{\epsilon}{P^\mu(\RV{A}=x,\RV{C}=0) P^\mu(\RV{A}=x,\RV{C}=1)} 
\end{align}

The set of distributions for which this independence holds are those that satisfy the following equalities:

\begin{align}
    \nu(0,0,0)\nu(1,0,1)-\nu(1,0,0)\nu(0,0,1)&=0\label{eq:ci0}\\
    \nu(0,1,0)\nu(1,1,1)-\nu(1,1,0)\nu(0,1,1)&=0 \label{eq:ci}
\end{align}

Suppose, then, that 

\begin{align}
    \mu(0,0,0)\mu(1,0,1)-\mu(1,0,0)\mu(0,0,1)&<\epsilon\label{eq:eci0}\\
    \mu(0,1,0)\mu(1,1,1)-\mu(1,1,0)\mu(0,1,1)&<\epsilon \label{eq:eci1}
\end{align}


% Sequential approach to CBN

A CBN is a non-trivial setup, so we need to define a number of moving parts to make the connection. Given a measurable space $(E,\mathcal{E})$ and a decision space $(D,\mathcal{D})$, a CBN is a causal theory $\Delta(\mathcal{E})\to (D\to \Delta(\mathcal{E}))$.

Suppose we have a graph $\mathcal{G}=(V,\mathscr{E})$ where $V=\{V_i|i\in [N]\}$.

Take some sequence of variables $\RV{X}:(E,\mathcal{E})\to (E,\mathcal{E})$ where $\RV{X} = \otimes\underline{[\RV{X}_j]}$, $j\in \mathbb{N}$, and suppose that they are jointly IID with respect to both $\mathscr{H}$ and $\mathscr{T}$ (that is, they are IID for all $\mu\in\mathscr{H}$ and all  $\tau(\mu)(d;\cdot)$ for $\tau \in \mathscr{T}$). Pick some $j\in \mathbb{N}$ and omit the subscript henceforth: $\RV{X}_j:=\RV{X}$. Suppose $\RV{X} = \otimes_{i\in[N]}\underline[\RV{X}^i]$. Take $\RV{X}^i:(E,\mathcal{E})\to \mathbb{R}$. The $\RV{X}^i$ represent the variables in a regular CBN.

For each $i\in [N]$ define a random variable $\RV{D}^i:D\to \mathbb{R}\cup\{*\}$. The variable $\RV{D}^i$ represents a do-intervention on $\RV{X}^i$.

A causal theory $\tau$ must satisfy three conditions in order to be a CBN with respect to $\mathcal{G}$.

\begin{itemize}
    \item For $x\in \mathbb{R}$, $\mu\in \mathscr{H}$, $\xi\in \Delta(\mathcal{D})$,  $P^{\xi \tau^\mu}(\RV{X}^i|\RV{D}^i=x)=\delta_x(\RV{X}^i)$ ($\RV{D}^i=x\in \mathbb{R}$ represents an active intervention on $\RV{X}^i$)
    \item $P^{\xi \tau^\mu}(\RV{X}^i|\RV{D}_i=*,\PA{\mathcal{G}}{\RV{X}^i}) = P^\mu(\RV{X}^i|\PA{\mathcal{G}}{\RV{X}^i})$ ($\RV{D}^i=*$ represents a passive intervention on $\RV{X}^i$)
    \item For all $\mu\in \mathscr{H}$, $d\in D$, $P^{\delta_d \tau^\mu}(\RV{X})$ is Markov with respect to $\mathcal{G}$
\end{itemize}

Given any distribution $\mu$ that is Markov with respect to $\mathcal{G}$, these conditions induce a map $\tau^\mu:D\to \Delta(\mathcal{E})$ given by\cite{pearl_causality:_2009}
\begin{align}
    \tau^\mu(d;B) = \prod_{i:\RV{D}^i(d)=*} \delta_{\RV{D}^i(d)} (\RV{X}^i(B)) \prod_{i:\RV{D}^i(d)\neq *} P^{\mu}_{\RV{X}^i|\PA{\mathcal{G}}{\RV{X}^i}} \left(\RV{X}^i(B)|\PA{\mathcal{G}}{\RV{X}^i(B)}\right)
\end{align}
Theorem \ref{th:cbn_MK} shows that provided $\mathcal{G}$ has a finite number of nodes, $\tau$ is a Markov kernel.

\begin{theorem}\label{th:cbn_MK}
The map $\tau^\mu:D\times \mathcal{E}\to [0,1]$ given by  is a Markov kernel.
\end{theorem}

\begin{proof}
Given $d\in D$, the map $B\mapsto \tau^\mu(d;B)$ is clearly a probability measure on $(E,\mathcal{E})$.

 
\end{proof}