To fully define the respective CDPs, suppose in both cases the loss is $L:\xi\mapsto 0.6\mathbb{E}_\xi[g(\RV{D}_A)] - \mathbb{E}_{\xi}[\RV{B}] - l^*$ where $g:\{0,1,*\}\to \{0,1\}$ is given by $g:x\mapsto x$ for $x\in \{0,1\}$ and $*\mapsto 0$. That is, $\RV{B}=1$ is desirable and setting $\RV{D}_A=1$ is a costly action. $l^*$ is some constant that ensures the minimal loss is 0.

Finally, suppose the given data is are IID samples from some distribution $\pi\in \Delta(\sigma(\{0,1\}^3))$ such that $P^\pi(\RV{B}|\RV{A}=a)=\delta_a(\RV{B})$. A naive application of $\mathcal{G}$ would then suggest that the consequence $\kappa$ were such that for any stochastic decision $\eta\in \Delta(\mathcal{D})$, $P^{\eta {(I_D\otimes \kappa)}}(\RV{B}|\RV{D}_A = x) =\delta_x(\RV{B})$ for $x\in\{0,1\}$. If $P^\pi(A=1)<0.4$ we then have $\delta_1(\RV{D}_A)$ as the optimal decision.

Consider the Bayes risk for such a problem (a similar problem can be constructed, but is more complicated, using Bayes risk), and suppose we have a learning rule that  This requires assigning a prior to causal states in $\mathscr{T}_{\mathcal{G}}'$ and $\mathscr{T}_{\mathcal{G}}^\square$- we will suppose that this prior that admits a density on the 8-simplex $\Delta(\sigma(\{0,1\}^3))$. In particular, the prior assigns 0 weight to any set $\mathscr{P}\subset\Delta(\sigma(\{0,1\}^3))$ with 0 volume. This is not an uncontroversial choice, but it is compatible with the view that ``there are no true parametric zeros'' endorsed by many statisticians (for example  \cite{gelman_bayesian_2010,meehl_theory-testing_1967,berkson_difficulties_1938}). Where a theory contains more than one state with a given distribution, we give these states equal weight. 

Note that the conditional independence $A\perp_\mathcal{G} C | B$ is associated with a lower dimensional subspace of $\Delta(\sigma(\{0,1\}^3))$ defined by 
\begin{align}
    \mu_{000}\mu_{101}-\mu_{100}\mu_{001}&=0\label{eq:ci0}\\
    \mu_{010}\mu_{111}-\mu_{110}\mu_{011}&=0 \label{eq:ci}
\end{align}
Hence any distribution compatible with $\mathcal{G}$ is in fact assigned 0 weight in our prior. Furthermore, for every graph with an arrow $A\to B$ there is a graph with an arrow $B\to A$; therefore the prior assigns at least a weight of 0.5 to the possibility that $\RV{B}$ is independent of $\RV{D}_A$ in the decision-consequence joint distribution. The gain from the decision $\RV{D}_B=1$ is therefore ``capped'' at 0.5, which is less than the direct cost of the decision. As such, any decision function $J$ that assigns nonzero weight to $\RV{D}_B = 1$ given \emph{any data} is dominated by any function that always assigns zero weight to this decision. This is despite the fact that, as noted above, the optimal stochastic decision should naively be $\delta_1(\RV{D}_B)$.

Consider instead the theory $\mathscr{T}^\square_{\mathcal{G}}$. As before, 0 weight is assigned to the causal states associated with $\mathscr{T}_{\mathcal{G}}$. On the other hand, given some incompatible $\mu$, $\mathscr{T}^\square_{\mathcal{G}}$ yields the following pair of states (for simplicity, marginalising over $\RV{A}$ and $\RV{C}$ that are irrelevant to the loss and ignoring the passive action):
\begin{align}
    &(\mu,x\mapsto P^\mu(\RV{B}|\RV{A}=x) )\label{eq:cbn_s1}\\
    &(p,x \mapsto \sum_c P^\mu(\RV{B}|\RV{A}=x,\RV{C}=c)P^\mu(\RV{C}=c)) \label{eq:cbn_s2}
\end{align}

Suppose Eq's \ref{eq:ci0} and \ref{eq:ci} hold approximately for some $\mu$. That is, the absolute value of the expression on the left hand side is less than some $\epsilon>0$ in each case. Then we have
\begin{align}
    \left|P^\mu(\RV{B}|\RV{A}=x,\RV{C}=0) - P^\mu(\RV{B}|\RV{A}=x,\RV{C}=1) \right| &< \frac{\epsilon}{P^\mu(\RV{A}=x,\RV{C}=0) P^\mu(\RV{A}=x,\RV{C}=1)}\\
    \left|\sum_c P^\mu(\RV{B}|\RV{A}=x,\RV{C}=c)P^\mu(\RV{C}=c)-P^\mu(B|A=x)\right| &< \frac{\epsilon}{P^\mu(\RV{A}=x,\RV{C}=0) P^\mu(\RV{A}=x,\RV{C}=1)} 
\end{align}

The set of distributions for which this independence holds are those that satisfy the following equalities:

\begin{align}
    \nu(0,0,0)\nu(1,0,1)-\nu(1,0,0)\nu(0,0,1)&=0\label{eq:ci0}\\
    \nu(0,1,0)\nu(1,1,1)-\nu(1,1,0)\nu(0,1,1)&=0 \label{eq:ci}
\end{align}

Suppose, then, that 

\begin{align}
    \mu(0,0,0)\mu(1,0,1)-\mu(1,0,0)\mu(0,0,1)&<\epsilon\label{eq:eci0}\\
    \mu(0,1,0)\mu(1,1,1)-\mu(1,1,0)\mu(0,1,1)&<\epsilon \label{eq:eci1}
\end{align}


% Sequential approach to CBN

A CBN is a non-trivial setup, so we need to define a number of moving parts to make the connection. Given a measurable space $(E,\mathcal{E})$ and a decision space $(D,\mathcal{D})$, a CBN is a causal theory $\Delta(\mathcal{E})\to (D\to \Delta(\mathcal{E}))$.

Suppose we have a graph $\mathcal{G}=(V,\mathscr{E})$ where $V=\{V_i|i\in [N]\}$.

Take some sequence of variables $\RV{X}:(E,\mathcal{E})\to (E,\mathcal{E})$ where $\RV{X} = \otimes\underline{[\RV{X}_j]}$, $j\in \mathbb{N}$, and suppose that they are jointly IID with respect to both $\mathscr{H}$ and $\mathscr{T}$ (that is, they are IID for all $\mu\in\mathscr{H}$ and all  $\tau(\mu)(d;\cdot)$ for $\tau \in \mathscr{T}$). Pick some $j\in \mathbb{N}$ and omit the subscript henceforth: $\RV{X}_j:=\RV{X}$. Suppose $\RV{X} = \otimes_{i\in[N]}\underline[\RV{X}^i]$. Take $\RV{X}^i:(E,\mathcal{E})\to \mathbb{R}$. The $\RV{X}^i$ represent the variables in a regular CBN.

For each $i\in [N]$ define a random variable $\RV{D}^i:D\to \mathbb{R}\cup\{*\}$. The variable $\RV{D}^i$ represents a do-intervention on $\RV{X}^i$.

A causal theory $\tau$ must satisfy three conditions in order to be a CBN with respect to $\mathcal{G}$.

\begin{itemize}
    \item For $x\in \mathbb{R}$, $\mu\in \mathscr{H}$, $\xi\in \Delta(\mathcal{D})$,  $P^{\xi \tau^\mu}(\RV{X}^i|\RV{D}^i=x)=\delta_x(\RV{X}^i)$ ($\RV{D}^i=x\in \mathbb{R}$ represents an active intervention on $\RV{X}^i$)
    \item $P^{\xi \tau^\mu}(\RV{X}^i|\RV{D}_i=*,\PA{\mathcal{G}}{\RV{X}^i}) = P^\mu(\RV{X}^i|\PA{\mathcal{G}}{\RV{X}^i})$ ($\RV{D}^i=*$ represents a passive intervention on $\RV{X}^i$)
    \item For all $\mu\in \mathscr{H}$, $d\in D$, $P^{\delta_d \tau^\mu}(\RV{X})$ is Markov with respect to $\mathcal{G}$
\end{itemize}

Given any distribution $\mu$ that is Markov with respect to $\mathcal{G}$, these conditions induce a map $\tau^\mu:D\to \Delta(\mathcal{E})$ given by\cite{pearl_causality:_2009}
\begin{align}
    \tau^\mu(d;B) = \prod_{i:\RV{D}^i(d)=*} \delta_{\RV{D}^i(d)} (\RV{X}^i(B)) \prod_{i:\RV{D}^i(d)\neq *} P^{\mu}_{\RV{X}^i|\PA{\mathcal{G}}{\RV{X}^i}} \left(\RV{X}^i(B)|\PA{\mathcal{G}}{\RV{X}^i(B)}\right)
\end{align}
Theorem \ref{th:cbn_MK} shows that provided $\mathcal{G}$ has a finite number of nodes, $\tau$ is a Markov kernel.

\begin{theorem}\label{th:cbn_MK}
The map $\tau^\mu:D\times \mathcal{E}\to [0,1]$ given by  is a Markov kernel.
\end{theorem}

\begin{proof}
Given $d\in D$, the map $B\mapsto \tau^\mu(d;B)$ is clearly a probability measure on $(E,\mathcal{E})$.

 
\end{proof}




We modify this setup somewhat in order to analyse it in terms of a causal theory. We believe these choices are reasonable, but there is an element of interpretation involved here. For clarity every variable gets a subscript and $\RV{X}_{ob}$, $\RV{Z}_{ob}$ are random variables representing outcomes and treatments in the observed data. $\RV{X}_i, \RV{Z}_i$, $i\geq 0$ are random variables representing outcomes and treatments in consequence of choosing a decision $\RV{D}=i$ deterministically; that is, $P(\RV{Z}_i) = \delta_i(\RV{Z}_i)$. Note that we do not necessarily have a ``passive decision'' as we did with CBNs. Finally, we work with a slightly weaker ``almost certain consistency'':

\begin{align}
    P(\RV{X}_i,\RV{X}_{ob}|\RV{Z}_{ob}=i,\RV{Z}_i=i)&=\mathds{1}_{\RV{X}_{ob}=\RV{X}_i} \label{eq:consistency}\\
    \implies P(\RV{X}_i,\RV{X}_{ob}|\RV{Z}_{ob}=i)&=\mathds{1}_{\RV{X}_{ob}=\RV{X}_i}
\end{align}

It is usually not possible to represent a joint distribution obeying condition \ref{eq:consistency} with a causal theory. For example, take the spaces $D,X,Z=\{0,1\}$ and suppose we have a causal theory $\mathscr{T}$ consisting of pairs $(\kappa,\mu)$ where $\mu\in\Delta(\mathcal{X}\otimes\mathcal{Z})$ and $\kappa$ is a Markov kernel from $D\to \Delta(\mathcal{X}\otimes\mathcal{Z})$. To construct a joint distribution between $\RV{X}_{ob}$ and $\RV{X}_i$ for $i\in \{0,1\}$ we take some deterministic decision function $J_i:X\times Z\to \Delta(\mathcal{D})$ where $J_i:(x,z;d)\mapsto \delta_i(d)$. For $A,C\in \Delta(\mathcal{X}\otimes\mathcal{Z})$, $B\in \Delta(\mathcal{D})$ we compose the objects as 
\begin{align}
    \xi(A\times B\times C) =  \int_B \int_A  \kappa(y; C) \delta_i(dy) \mu(dx\times dz)
\end{align}

For $\alpha\in\{ob,0,1\}$ take random variables $\RV{X}_\alpha:(X\times Z)^2\times D\to X$, $\RV{Z}_\alpha:(X\times Z)^2\times D\to X$ and $\RV{D}:(X\times Z)^2\times D\to D$ defined by projections $\RV{X}_\alpha:((x_{ob},z_{ob}),(x_i,z_i),d)\mapsto x_\alpha$, $\RV{Z}_\alpha$ similarly and $\RV{D}:((x_{ob},z_{ob}),(x_i,z_i),d)\mapsto d$. It is then straightforward to show that $(x,z,d))\mapsto \kappa(d; C)$ is a version of the conditional probability $P^\xi(\RV{X}_i|\RV{D},\RV{X}_{ob},\RV{Z}_{ob})$, which implies 
\begin{align}
    \RV{X}_i&\CI_\xi \RV{X}_{ob}|\RV{D}, \RV{Z}_{ob}
\end{align}
For any choice of $J_i,\mu,\kappa$. Noting that $J_i$ is deterministic, we also have
\begin{align}
    \RV{X}_i&\CI_\xi \RV{X}_{ob}|\RV{Z}_{ob} \label{eq:decision_d_sep}
\end{align}
Conditions \ref{eq:consistency} and \ref{eq:decision_d_sep} can hold simultaneously only if $\RV{X}_{ob}$ is deterministic conditional on $\RV{Z}_{ob}$. This is usually not the case.



In order to facilitate nontrival joint distributions between obsevations and potential outcomes, we introduce a \emph{generalised consequence}:

\begin{definition}[Generalised consequence]
Given a measurable consequence space $(F,\mathcal{F})$, a sample space $(E,\mathcal{E})$ and a measurable decision set $(D,\mathcal{D})$, a Markov kernel $\kappa:D\times E \to \Delta(\mathcal{F})$ is a generalised consequence.
\end{definition}

\begin{definition}[Generalised causal theory]
A generalised causal theory is the analogue of a causal theory with the consequence replaced by a generalised consequence.
\end{definition}

Given $D,X,Z$ as before, we provide an explicit construction respecting \ref{eq:consistency}. Here, for convenience, we identify $E=F=X\times Z$. For $x\in X$, $z\in Z$, $d\in D$ and $G\in \mathcal{X}$, $H\in \mathcal{Z}$ consider the kernel

\begin{align}
    \iota: (d,x,z;G\times H) \mapsto \delta_d(H)(\delta_z(H) \delta_x(G) + (1-\delta_z(H)) \iota'(d,x,z;G))
\end{align}

Where $\iota'$ is an arbitrary Markov kernel $D\times X\times Z\to \Delta(\mathcal{X}\otimes\mathcal{Z})$. It is straightforward to check that $\iota$ is a Markov kernel. Take the Consider the distribution given by
\begin{align}
    \zeta (A\times B\times C) =  \int_B \int_A  \iota(y,x,z; C) \delta_i(dy) \mu(dx\times dz)
\end{align}
And random variables $\RV{X}_i$, $\RV{Z}_i$ and $\RV{D}$ as before. Then
\begin{align}
    P^\zeta(\RV{X}_i=j,\RV{X}_{ob}=k|\RV{Z}_{ob}=i)P^\zeta(\RV{Z}_{ob}=i) &= \sum_{m,n} \iota(n,k,i;\{j,m\}) \delta_i(\{n\}) \mu(k,i)\\
     &= \sum_{m,n} \delta_n(m)[\delta_i(m) \delta_k(j) + (1-\delta_i(m))\iota'(n,k,i;\{j,m\})]\delta_i(\{n\}) \mu(k,i)\\
     &= \delta_k(j) \mu(k,i)
\end{align}

Which implies \ref{eq:consistency}.

\subsection{Causal Theories and Generalised Causal Theories}


A generalised causal decision problem is a causal decision problem featuring a generalised causal theory and a loss $L:\Delta(\mathcal{E}\otimes\mathcal{D}\otimes\mathcal{F})\to[0,\infty]$. There is a straightforward identification of causal theories with generalised causal theories, befitting the name. We might also ask when the extra structure of a generalised causal decision problem is needed.

Given an ordinary consequence $\kappa:D\to \Delta(\mathcal{F})$, we can trivially construct a generalised consequence $\iota:(d,e;A)\mapsto \kappa(d;A)$. In addition, given a loss $L:\Delta(\mathcal{D}\otimes\mathcal{F})\to[0,\infty]$ we can construct $L':\Delta(\mathcal{E}\otimes \mathcal{D}\otimes\mathcal{F})\to[0,\infty]$ by $L':\mu\mapsto L(\mu(E\times \cdot \times \cdot \cdot))$.

Given a generalised consequence $\iota:D\times E\to \Delta(\mathcal{F})$ and a hypothesis class $\mathscr{H}\subset\Delta(\mathcal{F})$, we can construct a causal theory $\mathscr{T}_{\iota,\mathscr{H}} = \{(d\mapsto (\mu\otimes \delta_d)\iota,\mu)|\mu\in \mathscr{H}\}$. This causal theory ``forgets'' the joint structure induced by $\iota$. For many practical problems, this extra structure is unnecessary.

Suppose $E=F=\{0,1\}^\mathbb{N}$ and $\RV{X}_{<N}=\otimes_{i\in [N-1]} \underline{\RV{X}_i}$ represents the ``past'' data while $\RV{X}_{\geq N}=\otimes_{i\geq N} \underline{\RV{X}_i}$ represents ``future'' data. Then, given some loss $L':\Delta(\mathcal{E}\otimes \mathcal{D}\otimes\mathcal{F})\to[0,\infty]$ that depends only on the distribution of the future data $\RV{X}_{\geq N}$ and $\RV{D}$, and if 

If a loss function over $\Delta(\mathcal{D}\otimes\mathcal{F})$ is sufficient to describe our preferences then any counterfactual decision problem can be posed as a regular causal decision problem.

\subsubsection{Acyclic Structural Equation Models}

An acyclic structural equation model can be understood as a special case of a generalised consequence. Recall that an acyclic structural equation model is a set of equations $M=\{X^i = f(X^{<i},\epsilon^i)|i\in[N]\}$ along with an intervention operation that replaces the right hand side of an arbitrary subset of equations with an arbitrary set of (allowable) chosen values. Identify the sample space $E=\mathbb{R}^N$ as the space from which the noises $\epsilon=(\epsilon^0,..,\epsilon^N)$ are drawn the decision set $D$ with the set of allowable interventions (including non-interventions) and $F$ as the space in which $X=(X^0,...,X^N)$ lives. Then $M$ is a function from $D\times E\to F$. We can associate the function $M$ with the kernel $\kappa_M: D\times E\to \Delta(\mathcal{F})$ by $\iota_M:(d,e;A)\mapsto \delta_{M(d,e)}(A)$.

An acyclic SEM $M$ with independent noises can be associated with a causal theory. Take a hypothesis class $\mathscr{H}\subset\Delta(\mathcal{E})$ such that for every $\mu\in\mathscr{H}$ the noises are jointly independent. Then we can associate such an SEM with the causal theory
\begin{align}
    \mathscr{T} = \{(\iota_M,(\mu\otimes \delta_*)\iota_M )|\mu\in\mathscr{H}\}
\end{align}
Where $\delta_*$ is the distribution over $D$ that assigns weight 1 to the non-intervention $*$.


\begin{align}
    L((\kappa,\mu),\gamma) = \sup_{\gamma'\in\Delta(\mathcal{D})} \mathbb{E}_{\gamma'\underline{(I_D\otimes \kappa)}}[u] - \mathbb{E}_{\gamma\underline{(I_D\otimes \kappa)}}[u]
\end{align}
For $(\kappa,\mu)\in \mathscr{T}$ and $\gamma\in \Delta(\mathcal{D})$. This is well defined wherever $U$ is bounded above. Note that $L$ does not depend on the data generating distribution $\mu$; henceforth we will suppress this argument and write $L(\kappa,\gamma):= L((\kappa,\mu),\gamma)$.


For an example of a pseudo utility that is not ordinary, consider $U(\xi) = \text{Var}_{\xi}(\RV{E})$ for $\xi\in\Delta(\mathcal{D}\otimes\mathcal{E})$ with $D=E=\{0,1\}$ and $\RV{E}:D\times E\to E$ is the projection $(d,e)\mapsto e$.


\begin{example}
\begin{align}
    \mathscr{T}_{\mathscr{M}}^{\mathrm{marg}} = \{(d\mapsto \mu F_{M(d,\cdot)},\mu F_{M(*,\cdot)})|\mu\in \mathscr{H}\} 
\end{align}

and the full-blown theory

\begin{align}
        \mathscr{T}_{\mathscr{M}}^{\mathrm{fb}} = \{(d\mapsto \mu \underline{(I_E\otimes F_{M(d,\cdot)})},\mu \underline{(I_E\otimes F_{M(*,\cdot)})})|\mu\in \mathscr{H}\}
\end{align}

We can define counterfactual random variables $\RV{X}^i_k:E\times D\to X^i$ for $k\in D$ by $\RV{X}^i_k=\RV{X}^i(\cdot,k)$; this is consistent with the approach in, for example, \cite{balke_counterfactual_1994}. Defining observational variables $\RV{X}^i:E\times X\to X^i$ by the projection, it is straightforward to see that $\mathscr{T}^{\mathrm{fb}}_{\mathscr{M}}$ satisfies consequence consistency with respect to these definitions (Equation \ref{eq:oc_consist}).



These two examples do not exhaust the set of causal theories that can be constructed from $\mathscr{M}$. For example, some philosophers believe that it is sometimes appropriate to allow a decision to provide evidence about the state of the world; we could model this with a kernel $\theta:D\to \Delta(\mathcal{E})$ and generate the ``evidential'' theory

\begin{align}
        \mathscr{T}_{\mathscr{M}}^{\mathrm{ev}} = \{(\theta  F_{M},\delta_{*}\theta F_{M})|\mu\in \mathscr{H}\}
\end{align}

\end{example}



\begin{definition}[Universal conditional independence]\label{def:univ_indep}
Given a measurable space $(E,\mathcal{E})$, a hypothesis class $\mathscr{H}\subset\Delta(\mathcal{E})$ and random variables $\RV{X}:E\to X$, $\RV{Y}:E\to Y$ and $\RV{W}:E\to W$, we say $\RV{X}$ is universally independent of $\RV{Y}$ conditional on $\RV{W}$ if for all $\mu\in\mathscr{H}$ we have $\RV{X}\CI_\mu \RV{Y} | \RV{W}$. We write this $\RV{X} \CII_\mathscr{H} \RV{Y} | \RV{W}$.
\end{definition}

Suppose $(E,\mathcal{E}) = (F\times G, \mathcal{F}\otimes \mathcal{G})$ and we have a kernel $\kappa:F\to \Delta(\mathcal{G})$ and a hypothesis class $\mathscr{J}\subset\Delta(\mathcal{F})$. Then define $\mathscr{H}\underline{\kappa}=\{\mu\underline{(I_F\otimes \kappa)}|\mu\in \mathscr{H}\}$. Universal conditional independence with respect to $\kappa$ and $\mathscr{J}$ is written $\RV{X}\CII_{\mathscr{J}\underline{\kappa}} \RV{Y} | \RV{W}$.


A more straightforward reduction can be made if the causal decision problem is \emph{identifiable}. A causal decision problem is identifiable if the risk of a given decision function is unique given a distribution over the observed data.

\begin{definition}[Identifiability]
A causal decision problem $\langle (\mathscr{T}, E), D, \RV{X}, L \rangle$ is risk-identifiable iff for each $J\in \mathscr{D}$ and $\mu\in \Delta(\mathcal{E})$, $|\{R(J,\kappa,\mu)|(\kappa,\mu)\in \mathscr{T}\}|=1$.

A causal theory $\mathscr{T}$ is identifiable iff for each $\mu\in \Delta(\mathcal{E})$, $|\{(\kappa,\mu)|(\kappa,\mu)\in\mathscr{T}\}|=1$.
\end{definition}

\begin{theorem}[Reduction of identifiable problems]
A risk-identifiable causal decision problem $\langle (\mathscr{T}, E), D, \RV{X}, L \rangle$ where the loss is an ordinary utility can be reduced to a statistical decision problem.
\end{theorem}

\begin{proof}


Choose an arbitrary $(\kappa,\mu)\in\mathscr{T}$ and define $L':\mathscr{H}\times D\to [0,\infty)$ by
\begin{align}
    L'(\nu,y) &= L(\delta_y\underline{[I_D\otimes \kappa]})\\
              &= \int_F \ell(z,y) \kappa(y;dz)
\end{align}

Then the risk $R'$ associated with the statistical decision problem $\langle (\mathscr{H},E),D,\RV{X},L'\rangle$ is given by 
\begin{align}
    R'(J,\mu) &= \int_E \int_F \ell(z,y)  \kappa (y;dz) \mu K_{\RV{X}} J(dy)\\
              &= R(J,\mu,\kappa')
\end{align}
For any $\kappa'\in\mathscr{K}$. The map $g:\mathscr{T}\to\mathscr{H}$ given by $(\mu,\kappa)\mapsto \mu$ is the required surjection.
\end{proof}


\begin{lemma}
The set $\Delta(B(\mathbb{R}))$ (where $B(\mathbb{R})$ is the Borel $\sigma$-algebra) has the cardinality $2^{\aleph_0}$.
\end{lemma}

\begin{proof}
Probability measures on the Borel $\sigma$-algebra are determined by their values on $\{(-\infty,r)|r\in \mathbb{Q}\}$. Therefore the cardinality of $\Delta(B(\mathbb{R}))$ is $(2^{\aleph_0})^{\aleph_0}=2^{\aleph_0}$.
\end{proof}

\begin{lemma}
The set of Markov kernels $\mathbb{R}\to \Delta(B(\mathbb{R})$ has the cardinality $2^{\aleph_0}$.
\end{lemma}

\begin{proof}
Consider some $\kappa:\mathbb{R}\to \Delta(B(\mathbb{R})$.

Because $\kappa(x;\cdot)$ is a probability measure for every $x\in \mathbb{R}$, $\kappa(x;\cdot)$ is determined by the values of $\kappa(x;A)$ for $A\in \{(-\infty,r)|r\in \mathbb{Q}\}$.

Fix $x'\in \mathbb{R}$ and consider the set $[\kappa(x;\cdot)]^{-1} = \{x|\forall A\in \{(-\infty,r)|r\in \mathbb{Q}\}:\kappa(x;A) = \kappa(x';A)\}$. By the above, this is equal to $\{x|\forall A\in B(\mathbb{R}):\kappa(x;A) = \kappa(x';A)\}$, so if, for all $x\in \mathbb{R}$, $[\kappa(x;\cdot)]^{-1}=[\iota(x;\cdot)]^{-1}$ then $\kappa=\iota$. 

$[\kappa(x;\cdot)]^{-1}$ is also a countable intersection of open sets, so it is itself in $B(\mathbb{R})$.

\end{proof}

\section{Appendix: Counterfactuals and one-shot inference}

Recall that we have proposed making the connection between data, decisions and outcomes in two steps: firstly a causal theory relates data to possible consequences (the ``inference'' step), and secondly a consequence then relates decisions to outcomes (the ``control'' step). We could consider a generalised consequence $D\times E\to \mathscr{P}(\Delta(\mathcal{X}))$ that jointly performs the inference and control steps. We speculate that this generalisation provides an alternative connection between SCDPs and counterfactual reasoning; in particular, Nonparametric Structural Equation Models (NPSEMs) which are often considered appropriate tools for modelling counterfactual distributions (\cite{pearl_causality:_2009,richardson2013single}) can be seen as a special case of generalised consequences.

\begin{definition}[NPSEM]\label{def:NPSEM}
A non-parametric structural equation model (NPSEM) is a tuple $\langle \{\RV{X}^i, \RV{U}^i, f^i\}_{i\in[N]}, (D,\mathcal{D}), (E,\mathcal{E})\rangle$ where, for all $i\in N$, $\RV{X}^i:E\times D \to X^i$, $\RV{U}^i:E\to U^i$, $\mathscr{H}\subset\Delta(\mathcal{E}$ and $D=\times_{i\in[N]} X^i\cup\{*\}$ and $f^i:\times_{j<i} X^i\times U^i\to X^i$ are functions measurable with respect to the implied product sigma algebras. The $\RV{X}^i$ are given by

\begin{align}
    \RV{X}^i(e,d) = \begin{cases} f^i(\RV{X}^{<i}(e,d),\RV{U}^i(e)) &\RV{D}^i(d)=*\\ 
    \RV{D}^i(d)  &\RV{D}^i(d)\neq * \end{cases}
\end{align}

Where $\RV{X}^{<i}(e,d)=[\RV{X}^0(e,d),...\RV{X}^{i-1}(e,d)]$.
\end{definition}

Given an NPSEM $\mathscr{M}:\langle \{\RV{X}_i, \RV{U}_i, f_i\}_{i\in[N]}, (D,\mathcal{D}), (E,\mathcal{E})\rangle$ we can let $\RV{X}$ be the joint space of all the $\RV{X}_i$ and an NPSEM induces a measurable function $M:D\times E\to X$. In general there are many NPSEMs that induce the same measurable function in this manner. For example $f_0:e\mapsto e$ and $f_1:(x_0,e)\mapsto x_0$ induces the same function $E\to X_0\times X_1$ as $f_0:e\mapsto e$ and $f_1:(x_0,e)\mapsto e$. If consider all NPSEMs inducing the same function $M$ to be equivalent, then we can, abusing terminology somewhat, consider an NPSEM to be a measurable function $D\times E\to X$. A straightforward generalisation of this is a stochastic NPSEM $D\times E\to \Delta(\mathscr{X})$, and a set of stochastic NSPEMs induces a set valued stochastic map $D\times E\to \mathscr{P}(\Delta(\mathcal{X}))$.



\subsection{Extending the theory induced by a CBN}

The causal theory $T_{\mathcal{G}}$ defined above associates a consequence with every probability distribution compatible with $\mathcal{G}$ but not every probability distribution in $\Delta(\mathcal{X})$ (this follows from condition 1 of Definition \ref{def:CBN}). It may be the case that it is not considered reasonable to assume \emph{a priori} that the conditional independences implied by $\mathcal{G}$ hold in the observed data - indeed, such an assumption is usually considered unreasonable.

We therefore need to extend the theory $\mathscr{T}_{\mathcal{G}}$ to account for the possibility of incompatible distributions. There are many choices for how this may be done, none are obviously correct and different extensions will generally induce very different risk sets, as shown by Example \ref{ex:extn_cbn}.

\begin{example}[Extension of a CBN]\label{ex:extn_cbn}

A graph $\mathcal{G}$ is given in figure \ref{fig:simple_cbn}. With this, we will associate the simplified sample space $(E,\mathcal{E})=(\{0,1\}^3,\mathscr{P}(\{0,1\}^3)$ (where $\mathscr{P}$ denotes the power set) and the random variables $\RV{A},\RV{B}$ and $\RV{C}$ taking values in $\{0,1\}$ defined by projections from $E$. The set of distributions $\Delta(\mathcal{E})$ is the categorical distribution with 8 outcomes.

\begin{figure}
    \centering
     \begin{tikzpicture}[-latex,auto ,node distance =1 cm and 2cm ,on grid ,
    semithick ,
    vb/.style ={ circle ,top color =white , 
    draw , text=blue , minimum width =0.6 cm},
    kernel/.style={rectangle,draw}
    ]

    \node[vb] (A) {$A$};
    \node[vb] (B) [right = of A] {$B$};
    \node[vb] (C) [right = of B] {$C$};
    \draw (A) -- (B);
    \draw (B) -- (C);
    \end{tikzpicture}
    \caption{Simple causal Bayesian network $\mathcal{G}$}
    \label{fig:simple_cbn}
\end{figure}

We will define a causal theory $\mathscr{T}_{\mathcal{G}}$ from $\mathcal{G}$ where, for simplicity, we suppose that only $A$ can be intervened on. The decision space $D=A\cup\{*\}$ with the decision $\RV{D}_A=x$ for $x\in A$ having the usual interpretation as a hard intervention on $A$. Suppose also that the utility $U(\zeta)=\mathbb{E}_{\zeta}[\RV{B}]$ for $\zeta\in\Delta(\mathcal{E}\otimes\mathcal{D})$.

$\mathcal{G}$ implies a single conditional independence: $\RV{A}\CI \RV{C} | \RV{B}$. As in the construction above, $\mathscr{T}_{\mathcal{G}}$ is the set of pairs

\begin{align}
    (\mu,x\mapsto \mu_{\mathcal{G}}^x ) \qquad \mu\in\Delta(\mathcal{E}):\RV{A}\CI_{\mu}\RV{B}|\RV{C} \label{eq:ocbn}
\end{align}

Consider three options for extending this to distributions $\nu$ incompatible with $\mathcal{G}$, noting that one could imagine many additional possibilities:
\begin{itemize}
    \item $\mathscr{T}_{\mathcal{G}}^\circ$ assigns the causal states given by the union over all DAGs on the set of nodes $\{A, B, C\}$
    \item $\mathscr{T}_{\mathcal{G}}^\subset$ assigns the causal states given by the union over all graphs $\mathcal{G}'$ on $\{A, B, C\}$ such that of $\mathcal{G}\subset \mathcal{G}'$ (that is, every edge in $\mathcal{G}$ is also in $\mathcal{G}'$)
    \item $\mathscr{T}_{\mathcal{G}}^\mathrm{stubborn}$ assigns the causal states given by $\mathcal{G}$ to all distributions in $\Delta(\mathcal{E})$
\end{itemize}

Finally, we will suppose some prior $\xi$ on $\Delta(\mathcal{E})$ that is absolutely continuous with respect to the Lebesgue measure on the probability simplex $\{[p_1,..p_8]|\sum_i p_i=1,0\leq p_i \leq 1\}\subset\mathbb{R}^8$ that parametrises $\Delta(\mathcal{E})$ and, whenever a theory admits multiple consequences for a given distribution, assigns these consequences equal weight. Note that the set of distributions $\mathscr{H}_{\mathcal{G}}$ for which $\RV{A}\CI \RV{C} | \RV{B}$ holds therefore has measure 0 with respect to $xi$\cite{meek_strong_1995}. The Bayes risk of any decision function $J\in \mathscr{J}$, therefore, will depend entirely on the chosen theory's behaviour on $\mathscr{H}_{\mathcal{G}}^c$.

Noe that the theory $\mathscr{T}_{\mathcal{G}}^\circ$ admits consequences on $\mathscr{H}_{\mathcal{G}}^c$ associated with:
\begin{enumerate}
    \item DAGs featuring $A\to B$
    \item DAGs featuring $B\to A$ (in equal number to the first set of DAGs)
    \item DAGs featuring no arrow between $B$ and $A$ (featuring one additional DAG to the first two types)
\end{enumerate} 
Therefore the calculation for the Bayes risk given by $\mathscr{T}_{\mathcal{G}}^\circ$ will always feature a weight of more than $\tfrac{2}{3}$ on the possibility that the marginal distribution of $\RV{B}$ is independent of whatever decision $\RV{D}_A$ is chosen. For many priors this will be very different to $\mathscr{T}_{\mathcal{G}}^\mathrm{stubborn}$.

The theory $\mathscr{T}_{\mathcal{G}}^\subset$, on the other hand, yields a set consequences that are ``close'' to the consequence admitted by the original theory $\mathscr{T}_{\mathcal{G}}$ if the distribution $\nu$ is sufficiently ``close'' to a distribution $\mu$ for which $\RV{A} \CI_\mu \RV{C} | \RV{B}$. Marginalising over $\RV{A}$ and $\RV{C}$ and ignoring the passive action, the theory $\mathscr{T}^\subset_{\mathcal{G}}$ associates exactly two consequences with every incompatible $\nu$:
\begin{align}
    &(\nu,x\mapsto \nu(\RV{B}|\RV{A}=x) )\label{eq:cbn_s1}\\
    &(\nu,x \mapsto \sum_c \nu(\RV{B}|\RV{A}=x,\RV{C}=c)\nu(\RV{C}=c)) \label{eq:cbn_s2}
\end{align}

Note that \ref{eq:cbn_s1} is the same pattern as the states given by $\mathscr{T}_{\mathcal{G}}$ - see Eq. \ref{eq:ocbn}. Define the consequences $\kappa^\mathcal{G}_\nu := x\mapsto \nu(\RV{B}|\RV{A}=x)$ and $\kappa^\subset_\nu:= x \mapsto \sum_c \nu(\RV{B}|\RV{A}=x,\RV{C}=c)\nu(\RV{C}=c))$.

Consider some $\nu$ for which $\RV{A} \CI_\nu \RV{C} | \RV{B}$ holds approximately. That is, for some $\epsilon>0$ and all $x\in\{0,1\}$
\begin{align}
    \left|\sum_{c\in\{0,1\}} \nu(\RV{B}|\RV{A}=x,\RV{C}=c)\nu(\RV{C}=c)-\nu(B|A=x)\right| &< \epsilon \label{eq:app_ci}
\end{align}

Recalling the utility $U(\zeta)=\mathbb{E}_\zeta[\RV{B}]$, and that $\mathscr{T}^\subset_\mathcal{G}$ and $\mathscr{T}^\mathrm{stubborn}_\mathcal{G}$ agree on $\kappa^\mathcal{G}$, we can bound the disagreement between the two theories with
\begin{align}
    |R(J,\kappa^\subset,\nu) - R(J,\kappa^\mathcal{G},\nu)| &=  \left|\mathbb{E}_{\nu J \kappa^\subset} [\RV{B}] - \mathbb{E}_{\nu J \kappa^\mathcal{G}} [\RV{B}]\right|\\
        &\leq \max_x \left|\sum_c P^\nu(\RV{B}|\RV{A}=x,\RV{C}=c)P^\nu(\RV{C}=c)-P^\nu(B|A=x) \right|\\
        &< \epsilon
\end{align}

Given the assumption of a prior $\xi$ that is uniformly continuous with respect to the Lebesgue measure, $\mathscr{T}_{\mathcal{G}}^\subset$ but not $\mathscr{T}_{\mathcal{G}}^\circ$ gives us the property that for distributions where $\RV{A} \CI_\nu \RV{C} | \RV{B}$ almost holds, the theory $\mathscr{T}_{\mathscr{G}}^{\mathrm{stubborn}}$ can yield ``almost'' correct results. Note that $\mathscr{T}_{\mathscr{G}}^{\mathrm{stubborn}}$ is precisely the theory that actually uses the graph $\mathcal{G}$ to calculate consequences.
\end{example}

This example is somewhat contrived. The stipulation that the prior $\xi$ is absolutely continuous with respect to the Lebesgue measure may be considered strong, as may the assumption of equal weight given to different consequences where multiple consequences were allowed. Bayesian methods of graph learning, for example, may use priors that are not absolutely continuous with respect to the Lebesgue measure \cite{chickering_optimal_2003}. At the same time, it is not obviously unreasonable; it is consistent with the notion that ``there are no true parametric zeros'' endorsed by many statisticians (for example  \cite{gelman_bayesian_2010,meehl_theory-testing_1967,berkson_difficulties_1938}) and a similar assumption is invoked in support of the faithfulness hypothesis in causal graph learning \cite{meek_strong_1995}. A prior that assigns nonzero weight to the set of distributions for which $\RV{A} \CI_\nu \RV{C} | \RV{B}$ will also not resolve the question of whether or not it is reasonable to calculate consequences according to $\mathcal{G}$ if $\RV{A} \CI_\nu \RV{C} | \RV{B}$ is in fact violated by a very small amount.

Even in the apparently simple case of a known causal graph $\mathcal{G}$, determining the associated causal theory is not a simple matter. The standard practice of computing consequences according to $\mathcal{G}$ if we do not reject the hypothesis that the observed data are compatible with $\mathcal{G}$ appears to rely on a prior with particular properties, a particular extension of the associated theory $\mathscr{T}_{\mathcal{G}}$, or both.


One of the possibly controversial choices in this scheme is the separation of the decision set $D$ from the sample space $E$ of the observed data. Almost universally, the causal inference literature identifies actions with some known impact on some observed variable (for example, deterministically setting some variable to a given value). If a problem is to be non-trivial we must accept some means of relating observed data to consequences.

This choice was made because there are many ways to specify prior knowledge about the relationship between decisions and outcomes, and different options are frequently chosen in practice. Within the graphical models literature one can find a wide variety of intervention types such as hard interventions, soft interventions, activity interventions and policy interventions. Given this, the requirement to specify prior knowledge about the outcomes of decisions \emph{somehow} is at least not an extra requirement.

Avoiding prescription here is also consistent with the project of describing the minimal set of elements necessary to describe a statistical causal decision problem. While we do not have a clean set of axioms that compel the construction given in this work, an informal case can be made for the necessity of the choices here. Taking the starting point that we are given some preferences over outcomes described by a utility function, a set of available decisions and a dataset and we want to determine preferences over possible decision functions, it appears necessary that we have some means of relating decisions to outcomes (given here by \emph{consequence mappings}) and some means of relating the given data to such consequence mappings (given here by \emph{causal theories}). It is not necessary, however, to suppose any particular canonical relationship between decisions, the given data and the outcomes. No preferences among possible decisions may be a trivial result, but it is not invalid.
