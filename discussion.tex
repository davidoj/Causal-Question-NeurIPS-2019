%!TEX root = main.tex

\section{Discussion}

We have introduced an original approach to formulating questions of causal inference and analysing approaches to causal modelling. We take cues from statistical decision theory in the realm of problem definition and make heavy use of the theory of Markov kernels for reasoning about causal theories, the central object of our approach. Our approach makes crystal clear the distinction between ``statistical'' and ``causal'' knowledge -- the former is represented by a statistical experiment and the latter by a causal theory. We can also plausibly interpret the two major existing approaches of Causal Bayesian Networks and Potenial Outcomes as tools to generate causal theories, though there are arbitrary decisions that must be made in order to do this.

Though we develop this theory in the context of ``small world decision problems'' \citep{joyce_foundations_1999}, we also make progress on the question of what causal theories are doing apart from facilitating reasoning about small world decision problems. We show that if a potentially unrealistic theory can be related to a more realistic theory by coarsening, then knowledge of consequences under the former may be informative about consequences under the latter. 

While we do not address the unique questions that can be raised with counterfactual models \citep{pearl_causality:_2009}, our approach suggests an alternative view for the relationship between counterfactual and interventional causal models. Rather than occupying different levels of a hierarchy, each yields causal theories with different kinds of rich decisions sets. It is plausible that the different sets of decisions each approach provides may be amenable to coarsening in different domains. Indeed, we see extensive discussion of counterfactual treatment effects in the econometrics literature, where decisions usually involve changing incentives which can plausibly be understood as altering the assignment function $\mathbf{W}$ in unpredictable ways \citep{angrist_mastering_2014,carneiro_evaluating_2010,imbens_identification_1994}. Causal Bayesian Networks, on the other hand, have found applications in the study of biological systems which typically feature large numbers of variables which permit a wide variety of targetted interventions \citep{sachs_causal_2005,maathuis_estimating_2009}.

While Theorem \ref{th:mod_extn} suggests that coarsening can be useful for ``reusing knowledge'' between compatible causal theories, this is only likely to be helpful if it is possible to determine that a theory $\mathbf{T}'$ is a coarsening of $\mathbf{T}$ under $\mathbf{M}$ without having to perform inference on both $\mathbf{T}$ and $\mathbf{T}'$ to satisfy ourselves that the consequences do indeed match in detail for both theories. Understanding when we can consider $\mathbf{T}'$ to be a coarsening of $\mathbf{T}$ and when it is useful to do so is an important development of the ideas presented here. Informally, we want to understand the question ``if I know my decision definitely results in $\RV{X}=x$, when do I also know it corresponds to $do(\RV{X}=x)$?''

A number of the results here are predicated on discrete spaces, a step that allows us to disregard questions of measurability. A second important direction of development is extending this theory to continuous spaces and understanding what limitations this introduces. Relatedly, the notions of conditional probability, conditioning, independence and Bayesian inversion are well understood in the context of probability measures, including in their string diagrammatic treatment \citep{cho_disintegration_2019}, but we are not aware of analogues of these notions for general Markov kernels, if they exist. They would be invaluable tools in the analysis of causal theories, which, owing to the dependence on $D$, are not naturally dealt with as probability measures.

The string diagram notation we use has a strong connection with the DAGs \citep{fong_causal_2013} used in causal graphical models as well as to influence diagrams\citep{dawid_influence_2002}, as do Markov kernels themselves. It would not be surprising if there were a deep connection between the two. 

