@incollection{dawid_decision-theoretic_2012,
	title = {The {Decision}-{Theoretic} {Approach} to {Causal} {Inference}},
	copyright = {Copyright © 2012 John Wiley \& Sons, Ltd},
	isbn = {978-1-119-94571-0},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119945710.ch4},
	abstract = {This chapter contains sections titled: Introduction Decision theory and causality No confounding Confounding Propensity analysis Instrumental variable Effect of treatment of the treated Connections and contrasts Postscript Acknowledgements References},
	language = {en},
	urldate = {2019-05-16},
	booktitle = {Causality},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Dawid, Philip},
	year = {2012},
	doi = {10.1002/9781119945710.ch4},
	keywords = {‘propensity analysis’ and decision-theoretic version, algebraic theory of conditional independence, and potential response modelling and causal graphs, and the DT approach, causal and associational concepts and quantities, causal assertions as ECI relations, causal inference, causal inference problems, DT, DT explication of concept of ACE, DT specialisation, ECI with DAG-related, Fisherian/decision-theoretic approach, information transfer from one ‘regime’ to another, Pearlian, propensity, structure, variables and treatment effect},
	pages = {25--42}
}

@inproceedings{balke_counterfactual_1994,
	address = {San Francisco, CA, USA},
	series = {{UAI}'94},
	title = {Counterfactual {Probabilities}: {Computational} {Methods}, {Bounds} and {Applications}},
	isbn = {978-1-55860-332-5},
	shorttitle = {Counterfactual {Probabilities}},
	url = {http://dl.acm.org/citation.cfm?id=2074394.2074401},
	abstract = {Evaluation of counterfactual queries (e.g., "If A were true, would C have been true?") is important to fault diagnosis, planning, and determination of liability. In this paper we present methods for computing the probabilities of such queries using the formulation proposed in [Balke and Pearl, 1994], where the antecedent of the query is interpreted as an external action that forces the proposition A to be true. When a prior probability is available on the causal mechanisms governing the domain, counterfactual probabilities can be evaluated precisely. However, when causal knowledge is specified as conditional probabilities on the observables, only bounds can computed. This paper develops techniques for evaluating these bounds, and demonstrates their use in two applications: (1) the determination of treatment efficacy from studies in which subjects may choose their own treatment, and (2) the determination of liability in product-safety litigation.},
	urldate = {2019-05-15},
	booktitle = {Proceedings of the {Tenth} {International} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Balke, Alexander and Pearl, Judea},
	year = {1994},
	note = {event-place: Seattle, WA},
	pages = {46--54},
	file = {ACM Full Text PDF:/home/users/u4533535/Zotero/storage/G9MKC43K/Balke and Pearl - 1994 - Counterfactual Probabilities Computational Method.pdf:application/pdf}
}

@book{geneletti2007defining,
  title={Defining and identifying the effect of treatment on the treated},
  author={Geneletti, Sara and Dawid, A Philip},
  year={2007},
  publisher={Citeseer}
}


@article{rubin_estimating_1974,
	title = {Estimating causal effects of treatments in randomized and nonrandomized studies},
	volume = {66},
	issn = {1939-2176(Electronic),0022-0663(Print)},
	doi = {10.1037/h0037350},
	abstract = {Presents a discussion of matching, randomization, random sampling, and other methods of controlling extraneous variation. The objective was to specify the benefits of randomization in estimating causal effects of treatments. It is concluded that randomization should be employed whenever possible but that the use of carefully controlled nonrandomized data to estimate causal effects is a reasonable and necessary procedure in many cases. (15 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {5},
	journal = {Journal of Educational Psychology},
	author = {Rubin, Donald B.},
	year = {1974},
	keywords = {Experimental Design, Random Sampling},
	pages = {688--701},
	file = {Snapshot:/home/users/u4533535/Zotero/storage/SIQJIHE5/1975-06502-001.html:text/html}
}

@article{robins2010alternative,
  title={Alternative graphical causal models and the identification of direct effects},
  author={Robins, James M and Richardson, Thomas S},
  journal={Causality and psychopathology: Finding the determinants of disorders and their cures},
  pages={103--158},
  year={2010},
  publisher={Oxford University Press New York, NY}
}


@book{toutenburg_ferguson_1970,
	title = {Mathematical {Statistics}: {A} {Decision} {Theoretic} {Approach}},
	isbn = {978-1-4832-2123-6},
	shorttitle = {Mathematical {Statistics}},
	abstract = {Mathematical Statistics: A Decision Theoretic Approach presents an investigation of the extent to which problems of mathematical statistics may be treated by decision theory approach. This book deals with statistical theory that could be justified from a decision-theoretic viewpoint.Organized into seven chapters, this book begins with an overview of the elements of decision theory that are similar to those of the theory of games. This text then examines the main theorems of decision theory that involve two more notions, namely the admissibility of a decision rule and the completeness of a class of decision rules. Other chapters consider the development of theorems in decision theory that are valid in general situations. This book discusses as well the invariance principle that involves groups of transformations over the three spaces around which decision theory is built. The final chapter deals with sequential decision problems.This book is a valuable resource for first-year graduate students in mathematics.},
	language = {en},
	publisher = {Academic Press},
	author = {Ferguson, Thomas S.},
	month = jul,
	year = {2014},
	note = {Google-Books-ID: qZLiBQAAQBAJ},
	keywords = {Mathematics / Applied, Mathematics / Probability \& Statistics / General}
}

@article{hajek_what_2003,
	title = {What {Conditional} {Probability} {Could} {Not} {Be}},
	volume = {137},
	issn = {1573-0964},
	url = {https://doi.org/10.1023/B:SYNT.0000004904.91112.16},
	doi = {10.1023/B:SYNT.0000004904.91112.16},
	language = {en},
	number = {3},
	urldate = {2019-05-08},
	journal = {Synthese},
	author = {Hájek, Alan},
	month = dec,
	year = {2003},
	keywords = {Conditional Probability, Probability Assignment, Ratio Analysis, Trouble Spot, Unconditional Probability},
	pages = {273--323},
	file = {Springer Full Text PDF:/home/users/u4533535/Zotero/storage/E75VCTXL/Hájek - 2003 - What Conditional Probability Could Not Be.pdf:application/pdf}
}

@article{peters_identifiability_2012,
	title = {Identifiability of {Causal} {Graphs} using {Functional} {Models}},
	url = {https://arxiv.org/abs/1202.3757v1},
	abstract = {This work addresses the following question: Under what assumptions on the
data generating process can one infer the causal graph from the joint
distribution? The approach taken by conditional independence-based causal
discovery methods is based on two assumptions: the Markov condition and
faithfulness. It has been shown that under these assumptions the causal graph
can be identified up to Markov equivalence (some arrows remain undirected)
using methods like the PC algorithm. In this work we propose an alternative by
defining Identifiable Functional Model Classes (IFMOCs). As our main theorem we
prove that if the data generating process belongs to an IFMOC, one can identify
the complete causal graph. To the best of our knowledge this is the first
identifiability result of this kind that is not limited to linear functional
relationships. We discuss how the IFMOC assumption and the Markov and
faithfulness assumptions relate to each other and explain why we believe that
the IFMOC assumption can be tested more easily on given data. We further
provide a practical algorithm that recovers the causal graph from finitely many
data; experiments on simulated data support the theoretical findings.},
	language = {en},
	urldate = {2019-05-07},
	author = {Peters, Jonas and Mooij, Joris and Janzing, Dominik and Schoelkopf, Bernhard},
	month = feb,
	year = {2012}
}

@inproceedings{tian2002general,
  title={A general identification condition for causal effects},
  author={Tian, Jin and Pearl, Judea},
  year={2002}
}

@article{bongers_theoretical_2016,
	title = {Theoretical {Aspects} of {Cyclic} {Structural} {Causal} {Models}},
	url = {http://arxiv.org/abs/1611.06221},
	abstract = {Structural causal models (SCMs), also known as (non-parametric) structural equation models (SEMs), are widely used for causal modeling purposes. A large body of theoretical results is available for the special case in which cycles are absent (i.e., acyclic SCMs, also known as recursive SEMs). However, in many application domains cycles are abundantly present, for example in the form of feedback loops. In this paper, we provide a general and rigorous theory of cyclic SCMs. The paper consists of two parts: the first part gives a rigorous treatment of structural causal models, dealing with measure-theoretic and other complications that arise in the presence of cycles. In contrast with the acyclic case, in cyclic SCMs solutions may no longer exist, or if they exist, they may no longer be unique, or even measurable in general. We give several sufficient and necessary conditions for the existence of (unique) measurable solutions. We show how causal reasoning proceeds in these models and how this differs from the acyclic case. Moreover, we give an overview of the Markov properties that hold for cyclic SCMs. In the second part, we address the question of how one can marginalize an SCM (possibly with cycles) to a subset of the endogenous variables. We show that under a certain condition, one can effectively remove a subset of the endogenous variables from the model, leading to a more parsimonious marginal SCM that preserves the causal and counterfactual semantics of the original SCM on the remaining variables. Moreover, we show how the marginalization relates to the latent projection and to latent confounders, i.e. latent common causes.},
	urldate = {2019-02-06},
	journal = {arXiv:1611.06221 [cs, stat]},
	author = {Bongers, Stephan and Peters, Jonas and Schölkopf, Bernhard and Mooij, Joris M.},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.06221},
	keywords = {Computer Science - Artificial Intelligence, Statistics - Methodology, Computer Science - Machine Learning},
	annote = {Comment: Will probably be submitted to The Annals of Statistics},
	file = {arXiv\:1611.06221 PDF:/home/users/u4533535/Zotero/storage/BIBWS6N9/Bongers et al. - 2016 - Theoretical Aspects of Cyclic Structural Causal Mo.pdf:application/pdf;arXiv.org Snapshot:/home/users/u4533535/Zotero/storage/F36XBBPJ/1611.html:text/html}
}

@inproceedings{dawid_beware_2010,
	title = {Beware of the {DAG}!},
	url = {http://proceedings.mlr.press/v6/dawid10a.html},
	abstract = {Directed acyclic graph (DAG) models are popular tools for describing causal relationships and for guiding attempts to learn them from data.  They appear to supply a means of extracting causal concl...},
	language = {en},
	urldate = {2018-03-09},
	booktitle = {Causality: {Objectives} and {Assessment}},
	author = {Dawid, A. Philip},
	month = feb,
	year = {2010},
	pages = {59--86},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/K2FLIM3E/Dawid - 2010 - Beware of the DAG!.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/3BBKAGH9/dawid10a.html:text/html}
}

@article{peters_structural_2015,
	title = {Structural {Intervention} {Distance} for {Evaluating} {Causal} {Graphs}},
	volume = {27},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/NECO_a_00708},
	doi = {10.1162/NECO_a_00708},
	abstract = {Causal inference relies on the structure of a graph, often a directed acyclic graph (DAG). Different graphs may result in different causal inference statements and different intervention distributions. To quantify such differences, we propose a (pre-)metric between DAGs, the structural intervention distance (SID). The SID is based on a graphical criterion only and quantifies the closeness between two DAGs in terms of their corresponding causal inference statements. It is therefore well suited for evaluating graphs that are used for computing interventions. Instead of DAGs, it is also possible to compare CPDAGs, completed partially DAGs that represent Markov equivalence classes. The SID differs significantly from the widely used structural Hamming distance and therefore constitutes a valuable additional measure. We discuss properties of this distance and provide a (reasonably) efficient implementation with software code available on the first author’s home page.},
	number = {3},
	urldate = {2019-03-19},
	journal = {Neural Computation},
	author = {Peters, Jonas and Bühlmann, Peter},
	month = jan,
	year = {2015},
	pages = {771--799}
}

@book{vapnik_nature_2013,
	title = {The {Nature} of {Statistical} {Learning} {Theory}},
	isbn = {978-1-4757-3264-1},
	abstract = {The aim of this book is to discuss the fundamental ideas which lie behind the statistical theory of learning and generalization. It considers learning as a general problem of function estimation based on empirical data. Omitting proofs and technical details, the author concentrates on discussing the main results of learning theory and their connections to fundamental problems in statistics. These include: * the setting of learning problems based on the model of minimizing the risk functional from empirical data * a comprehensive analysis of the empirical risk minimization principle including necessary and sufficient conditions for its consistency * non-asymptotic bounds for the risk achieved using the empirical risk minimization principle * principles for controlling the generalization ability of learning machines using small sample sizes based on these bounds * the Support Vector methods that control the generalization ability when estimating function using small sample size. The second edition of the book contains three new chapters devoted to further development of the learning theory and SVM techniques. These include: * the theory of direct method of learning based on solving multidimensional integral equations for density, conditional probability, and conditional density estimation * a new inductive principle of learning. Written in a readable and concise style, the book is intended for statisticians, mathematicians, physicists, and computer scientists. Vladimir N. Vapnik is Technology Leader AT\&T Labs-Research and Professor of London University. He is one of the founders of statistical learning theory, and the author of seven books published in English, Russian, German, and Chinese.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Vapnik, Vladimir},
	month = jun,
	year = {2013},
	note = {Google-Books-ID: EqgACAAAQBAJ},
	keywords = {Computers / Intelligence (AI) \& Semantics, Mathematics / Probability \& Statistics / General, Science / General}
}


@techreport{gordon_comparison_2018,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {A {Comparison} of {Approaches} to {Advertising} {Measurement}: {Evidence} from {Big} {Field} {Experiments} at {Facebook}},
	shorttitle = {A {Comparison} of {Approaches} to {Advertising} {Measurement}},
	url = {https://papers.ssrn.com/abstract=3033144},
	abstract = {Measuring the causal effects of digital advertising remains challenging despite the availability of granular data. Unobservable factors make exposure endogenous, and advertising’s effect on outcomes tends to be small. In principle, these concerns could be addressed using randomized controlled trials (RCTs). In practice, few online ad campaigns rely on RCTs, and instead use observational methods to estimate ad effects. We assess empirically whether the variation in data typically available in the advertising industry enables observational methods to recover the causal effects of online advertising. Using data from 15 US advertising experiments at Facebook comprising 500 million user-experiment observations and 1.6 billion ad impressions, we contrast the experimental results to those obtained from multiple observational models. The observational methods often fail to produce the same effects as the randomized experiments, even after conditioning on extensive demographic and behavioral variables. In our setting, advances in causal inference methods do not allow us to isolate the exogenous variation needed to estimate the treatment effects. We also characterize the incremental explanatory power our data would require to enable observational methods to successfully measure advertising effects. Our findings suggest that commonly used observational approaches based on the data usually available in the industry often fail to accurately measure the true effect of advertising.},
	language = {en},
	number = {ID 3033144},
	urldate = {2019-02-07},
	institution = {Social Science Research Network},
	author = {Gordon, Brett R. and Zettelmeyer, Florian and Bhargava, Neha and Chapsky, Dan},
	month = sep,
	year = {2018},
	keywords = {causal inference, advertising effects, digital advertising, field experiments, observational methods},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/BKFEMWA8/Gordon et al. - 2018 - A Comparison of Approaches to Advertising Measurem.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/NK2L98R6/papers.html:text/html}
}

@techreport{heckman_randomization_1991,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Randomization and {Social} {Policy} {Evaluation}},
	url = {https://papers.ssrn.com/abstract=995151},
	abstract = {This paper considers the recent case for randomized social experimentation and contrasts it with older cases for social experimentation. The recent case eschews behavioral models, assumes that certain mean differences in outcomes are the parameters of interest to evaluators and assumes that randomization does not disrupt the social program being analyzed. Conditions under which program disruption effects are of no consequence are presented. Even in the absence of randomization bias, ideal experimental data cannot estimate median (other quantile) differences between treated and untreated persons without invoking supplementary statistical assumptions. The recent case for randomized experimentation does not address the choice of the appropriate stage in a multistage program at which randomization should be conducted. Evidence on randomization bias is presented.},
	language = {en},
	number = {ID 995151},
	urldate = {2019-02-04},
	institution = {Social Science Research Network},
	author = {Heckman, James J.},
	month = jul,
	year = {1991},
	keywords = {James J. Heckman, Randomization and Social Policy Evaluation, SSRN},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/2J6VCTJD/Heckman - 1991 - Randomization and Social Policy Evaluation.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/NPXF69CD/papers.html:text/html}
}

@article{lemeire_replacing_2013,
	title = {Replacing {Causal} {Faithfulness} with {Algorithmic} {Independence} of {Conditionals}},
	volume = {23},
	issn = {0924-6495, 1572-8641},
	url = {https://link.springer.com/article/10.1007/s11023-012-9283-1},
	doi = {10.1007/s11023-012-9283-1},
	abstract = {Independence of Conditionals (IC) has recently been proposed as a basic rule for causal structure learning. If a Bayesian network represents the causal structure, its Conditional Probability Distributions (CPDs) should be algorithmically independent. In this paper we compare IC with causal faithfulness (FF), stating that only those conditional independences that are implied by the causal Markov condition hold true. The latter is a basic postulate in common approaches to causal structure learning. The common spirit of FF and IC is to reject causal graphs for which the joint distribution looks ‘non-generic’. The difference lies in the notion of genericity: FF sometimes rejects models just because one of the CPDs is simple, for instance if the CPD describes a deterministic relation. IC does not behave in this undesirable way. It only rejects a model when there is a non-generic relation between different CPDs although each CPD looks generic when considered separately. Moreover, it detects relations between CPDs that cannot be captured by conditional independences. IC therefore helps in distinguishing causal graphs that induce the same conditional independences (i.e., they belong to the same Markov equivalence class). The usual justification for FF implicitly assumes a prior that is a probability density on the parameter space. IC can be justified by Solomonoff’s universal prior, assigning non-zero probability to those points in parameter space that have a finite description. In this way, it favours simple CPDs, and therefore respects Occam’s razor. Since Kolmogorov complexity is uncomputable, IC is not directly applicable in practice. We argue that it is nevertheless helpful, since it has already served as inspiration and justification for novel causal inference algorithms.},
	language = {en},
	number = {2},
	urldate = {2018-05-24},
	journal = {Minds and Machines},
	author = {Lemeire, Jan and Janzing, Dominik},
	month = may,
	year = {2013},
	pages = {227--249},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/VSRYINKU/Lemeire and Janzing - 2013 - Replacing Causal Faithfulness with Algorithmic Ind.pdf:application/pdf;Snapshot:/home/users/u4533535/Zotero/storage/DCRU8TNB/s11023-012-9283-1.html:text/html}
}

@book{spirtes_causation_1993,
	title = {Causation, {Prediction}, and {Search}},
	volume = {81},
	abstract = {What assumptions and methods allow us to turn observations into causal knowledge, and how can even incomplete causal knowledge be used in planning and prediction to influence and control our environment? In this book Peter Spirtes, Clark Glymour, and Richard Scheines address these questions using the formalism of Bayes networks, with results that have been applied in diverse areas of research in the social, behavioral, and physical sciences. The authors show that although experimental and observational study designs may not always permit the same inferences, they are subject to uniform principles. They axiomatize the connection between causal structure and probabilistic independence, explore several varieties of causal indistinguishability, formulate a theory of manipulation, and develop asymptotically reliable procedures for searching over equivalence classes of causal models, including models of categorical data and structural equation models with and without latent variables. The authors show that the relationship between causality and probability can also help to clarify such diverse topics in statistics as the comparative power of experimentation versus observation, Simpson's paradox, errors in regression models, retrospective versus prospective sampling, and variable selection. The second edition contains a new introduction and an extensive survey of advances and applications that have appeared since the first edition was published in 1993.},
	author = {Spirtes, Peter and Glymour, Clark and Scheines, Richard},
	month = jan,
	year = {1993},
	doi = {10.1007/978-1-4612-2748-9},
	file = {Full Text PDF:/home/users/u4533535/Zotero/storage/Q5VT529X/Spirtes et al. - 1993 - Causation, Prediction, and Search.pdf:application/pdf}
}

@book{wald_statistical_1950,
	address = {Oxford, England},
	series = {Statistical decision functions},
	title = {Statistical decision functions},
	abstract = {In 5 chapters the general theory of statistical decision functions is presented. The decision problem is shown to be interpretable as a zero sum two-person game in von Neumann's theory. A generalization of this game type is basic to the development of the general theory. Chapter 4 considers the "case of a sequence of identically and independently distributed chance variables." Special illustrative problems are discussed in Chapter 5. 76-item bibliography. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {Wiley},
	author = {Wald, Abraham},
	year = {1950},
	file = {Snapshot:/home/users/u4533535/Zotero/storage/DAIIQKBL/1951-01400-000.html:text/html}
}

@article{richardson2013single,
  title={Single world intervention graphs (SWIGs): A unification of the counterfactual and graphical approaches to causality},
  author={Richardson, Thomas S and Robins, James M},
  journal={Center for the Statistics and the Social Sciences, University of Washington Series. Working Paper},
  volume={128},
  number={30},
  pages={2013},
  year={2013},
  publisher={Citeseer}
}

@article{ramsey_adjacency-faithfulness_2012,
	title = {Adjacency-{Faithfulness} and {Conservative} {Causal} {Inference}},
	url = {http://arxiv.org/abs/1206.6843},
	abstract = {Most causal inference algorithms in the literature (e.g., Pearl (2000), Spirtes et al. (2000), Heckerman et al. (1999)) exploit an assumption usually referred to as the causal Faithfulness or Stability condition. In this paper, we highlight two components of the condition used in constraint-based algorithms, which we call "Adjacency-Faithfulness" and "Orientation-Faithfulness". We point out that assuming Adjacency-Faithfulness is true, it is in principle possible to test the validity of Orientation-Faithfulness. Based on this observation, we explore the consequence of making only the Adjacency-Faithfulness assumption. We show that the familiar PC algorithm has to be modified to be (asymptotically) correct under the weaker, Adjacency-Faithfulness assumption. Roughly the modified algorithm, called Conservative PC (CPC), checks whether Orientation-Faithfulness holds in the orientation phase, and if not, avoids drawing certain causal conclusions the PC algorithm would draw. However, if the stronger, standard causal Faithfulness condition actually obtains, the CPC algorithm is shown to output the same pattern as the PC algorithm does in the large sample limit. We also present a simulation study showing that the CPC algorithm runs almost as fast as the PC algorithm, and outputs significantly fewer false causal arrowheads than the PC algorithm does on realistic sample sizes. We end our paper by discussing how score-based algorithms such as GES perform when the Adjacency-Faithfulness but not the standard causal Faithfulness condition holds, and how to extend our work to the FCI algorithm, which allows for the possibility of latent variables.},
	urldate = {2018-02-26},
	journal = {arXiv:1206.6843 [cs, stat]},
	author = {Ramsey, Joseph and Zhang, Jiji and Spirtes, Peter L.},
	month = jun,
	year = {2012},
	note = {arXiv: 1206.6843},
	keywords = {Computer Science - Artificial Intelligence, Statistics - Methodology},
	annote = {Adaptation of PC algorithm that distinguishes between orientation-faithfulness and adjacency-faithfulness. Orientation faithfulness can be tested, as given an unshielded collider X-{\textgreater}Y{\textless}-Z, any set containing Y should render X indep Z, and any set not containing Y should render X dep Z.
 
Derives "conservative" PC algorithm that assumes only adjacency-faithfulness.},
	annote = {Comment: Appears in Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence (UAI2006)},
	file = {arXiv\:1206.6843 PDF:/home/users/u4533535/Zotero/storage/5J3TGVYR/Ramsey et al. - 2012 - Adjacency-Faithfulness and Conservative Causal Inf.pdf:application/pdf;arXiv.org Snapshot:/home/users/u4533535/Zotero/storage/8VWWK4MQ/1206.html:text/html}
}

@article{chickering_optimal_2003,
	title = {Optimal {Structure} {Identification} with {Greedy} {Search}},
	volume = {3},
	issn = {1532-4435},
	url = {https://doi.org/10.1162/153244303321897717},
	doi = {10.1162/153244303321897717},
	abstract = {In this paper we prove the so-called "Meek Conjecture". In particular, we show that if a DAG H is an independence map of another DAG G, then there exists a finite sequence of edge additions and covered edge reversals in G such that (1) after each edge modification H remains an independence map of G and (2) after all modifications G =H. As shown by Meek (1997), this result has an important consequence for Bayesian approaches to learning Bayesian networks from data: in the limit of large sample size, there exists a two-phase greedy search algorithm that---when applied to a particular sparsely-connected search space---provably identifies a perfect map of the generative distribution if that perfect map is a DAG. We provide a new implementation of the search space, using equivalence classes as states, for which all operators used in the greedy search can be scored efficiently using local functions of the nodes in the domain. Finally, using both synthetic and real-world datasets, we demonstrate that the two-phase greedy approach leads to good solutions when learning with finite sample sizes.},
	urldate = {2018-02-27},
	journal = {J. Mach. Learn. Res.},
	author = {Chickering, David Maxwell},
	month = mar,
	year = {2003},
	pages = {507--554},
	annote = {It's possible to identify the "true" data-generating DAG in the infinite sample limit using a two-phase local search algorithm. This follows from the fact that it's possible to},
	file = {ACM Full Text PDF:/home/users/u4533535/Zotero/storage/FIK5RCSU/Chickering - 2003 - Optimal Structure Identification with Greedy Searc.pdf:application/pdf}
}

@inproceedings{meek_strong_1995,
	address = {San Francisco, CA, USA},
	series = {{UAI}'95},
	title = {Strong {Completeness} and {Faithfulness} in {Bayesian} {Networks}},
	isbn = {978-1-55860-385-1},
	url = {http://dl.acm.org/citation.cfm?id=2074158.2074205},
	abstract = {A completeness result for d-separation applied to discrete Bayesian networks is presented and it is shown that in a strong measure-theoretic sense almost all discrete distributions for a given network structure are faithful; i.e. the independence facts true of the distribution are all and only those entailed by the network structure},
	urldate = {2019-03-19},
	booktitle = {Proceedings of the {Eleventh} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Meek, Christopher},
	year = {1995},
	note = {event-place: Montréal, Qué, Canada},
	pages = {411--418},
	file = {ACM Full Text PDF:/home/users/u4533535/Zotero/storage/Z7SLGEL6/Meek - 1995 - Strong Completeness and Faithfulness in Bayesian N.pdf:application/pdf}
}

@article{berkson_difficulties_1938,
	title = {Some {Difficulties} of {Interpretation} {Encountered} in the {Application} of the {Chi}-{Square} {Test}},
	volume = {33},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2279690},
	doi = {10.2307/2279690},
	number = {203},
	urldate = {2019-04-28},
	journal = {Journal of the American Statistical Association},
	author = {Berkson, Joseph},
	year = {1938},
	pages = {526--536}
}

@article{gelman_bayesian_2010,
	title = {Bayesian {Statistics} {Then} and {Now}},
	volume = {25},
	issn = {0883-4237, 2168-8745},
	url = {https://projecteuclid.org/euclid.ss/1290175837},
	doi = {10.1214/10-STS308B},
	abstract = {Project Euclid - mathematics and statistics online},
	language = {EN},
	number = {2},
	urldate = {2019-04-28},
	journal = {Statistical Science},
	author = {Gelman, Andrew},
	month = may,
	year = {2010},
	mrnumber = {MR2789985},
	zmnumber = {1328.62045},
	pages = {162--165},
	file = {Full Text PDF:C\:\\Users\\david\\Zotero\\storage\\838N6CI5\\Gelman - 2010 - Bayesian Statistics Then and Now.pdf:application/pdf;Snapshot:C\:\\Users\\david\\Zotero\\storage\\UAJBSM99\\1290175837.html:text/html}
}


@article{meehl_theory-testing_1967,
	title = {Theory-{Testing} in {Psychology} and {Physics}: {A} {Methodological} {Paradox}},
	volume = {34},
	issn = {0031-8248},
	shorttitle = {Theory-{Testing} in {Psychology} and {Physics}},
	url = {https://www.journals.uchicago.edu/doi/abs/10.1086/288135},
	doi = {10.1086/288135},
	abstract = {Because physical theories typically predict numerical values, an improvement in experimental precision reduces the tolerance range and hence increases corroborability. In most psychological research, improved power of a statistical design leads to a prior probability approaching 1/2 of finding a significant difference in the theoretically predicted direction. Hence the corroboration yielded by "success" is very weak, and becomes weaker with increased precision. "Statistical significance" plays a logical role in psychology precisely the reverse of its role in physics. This problem is worsened by certain unhealthy tendencies prevalent among psychologists, such as a premium placed on experimental "cuteness" and a free reliance upon ad hoc explanations to avoid refutation.},
	number = {2},
	urldate = {2019-04-28},
	journal = {Philosophy of Science},
	author = {Meehl, Paul E.},
	month = jun,
	year = {1967},
	pages = {103--115},
	file = {Snapshot:C\:\\Users\\david\\Zotero\\storage\\VX8BUWUP\\288135.html:text/html}
}




@article{zhang_intervention_2011,
	title = {Intervention, determinism, and the causal minimality condition},
	volume = {182},
	issn = {1573-0964},
	url = {https://doi.org/10.1007/s11229-010-9751-1},
	doi = {10.1007/s11229-010-9751-1},
	abstract = {We clarify the status of the so-called causal minimality condition in the theory of causal Bayesian networks, which has received much attention in the recent literature on the epistemology of causation. In doing so, we argue that the condition is well motivated in the interventionist (or manipulability) account of causation, assuming the causal Markov condition which is essential to the semantics of causal Bayesian networks. Our argument has two parts. First, we show that the causal minimality condition, rather than an add-on methodological assumption of simplicity, necessarily follows from the substantive interventionist theses, provided that the actual probability distribution is strictly positive. Second, we demonstrate that the causal minimality condition can fail when the actual probability distribution is not positive, as is the case in the presence of deterministic relationships. But we argue that the interventionist account still entails a pragmatic justification of the causal minimality condition. Our argument in the second part exemplifies a general perspective that we think commendable: when evaluating methods for inferring causal structures and their underlying assumptions, it is relevant to consider how the inferred causal structure will be subsequently used for counterfactual reasoning.},
	language = {en},
	number = {3},
	urldate = {2019-04-27},
	journal = {Synthese},
	author = {Zhang, Jiji and Spirtes, Peter},
	month = oct,
	year = {2011},
	keywords = {Causal Bayesian network, Causation, Determinism, Intervention, Markov condition, Probability},
	pages = {335--347},
	file = {Springer Full Text PDF:C\:\\Users\\david\\Zotero\\storage\\2UKEIU5U\\Zhang and Spirtes - 2011 - Intervention, determinism, and the causal minimali.pdf:application/pdf}
}


@Book{cinlar_probability_2011,
  author = {Erhan \c{C}inlar},
  title = {Probability and Stochastics},
  year = 2011,
  publisher = {Springer}
}



@book{pearl_causality:_2009,
	edition = {2},
	title = {Causality: {Models}, {Reasoning} and {Inference}},
	publisher = {Cambridge University Press},
	author = {Pearl, Judea},
	year = {2009}
}