\section{Causal Decision Problems}

The normal form representation of a two person game is a triple:

\begin{definition}[Two person game (normal form)]
A normal form game is a triple $\langle \mathscr{S}, A, L\rangle$ where $\mathscr{S}$ and $A$ are arbitrary sets and $L:\mathscr{S}\times A\to [0,\infty)$ is a loss function.

By way of interpretation, we will identify the set $\mathscr{S}$ with a set of possible states that the environment may occupy and $A$ with a set of actions some decision maker may take. The decision maker seeks an action in $A$ that minimises the loss $L$.
\end{definition}

The definition presented here does not generally admit a unique best action. A minimax solution chooses an action that minimises the worst case loss:
\begin{align}
    a^*_{mm} = \argmin_{a\in A} [\sup_{s\in \mathscr{S}} L(s,a)]\label{eq:mm_soln}
\end{align}

If the set $\mathscr{S}$ is equipped with a $\sigma$-algebra $\mathcal{S}$, then given a probability measure $\xi\in \Delta(\mathcal{S})$ which we will call a ``prior'', the Bayes solution minimizes the expected risk with respect to $\xi$:
\begin{align}
    a^*_{ba} = \argmin_{a\in A} \int_{\mathcal{S}} L(s,a) \xi(ds)
\end{align}

A statistical decision problem is an instance of a two person zero sum game.

\begin{definition}[Statistical Decision Problem]
A statistical decision problem (SDP) is defined by a tuple $\langle (\mathscr{H},E), D, \RV{X}, L\rangle$.
\begin{itemize}
    \item Given a $\sigma$-algebra $\mathcal{E}$ on $E$, $\mathscr{H}\subset\Delta(\mathcal{E})$ is a hypothesis class.
    \item The set $D$, which is equipped with a $\sigma$-algebra $\mathcal{D}$, is a set of decisions
    \item $\RV{X}:E\to X$ is a random variable representing the information available for the statistician to make a decision
    \item $L:\mathcal{H}\times D\to [0,\infty)$ is a loss function
\end{itemize}

Denote by $\mathscr{D}$ the set of decision kernels $X\to \Delta(\mathcal{D})$. For $J\in \mathscr{D}$ and $\mu\in \mathcal{H}$, the risk is defined as:
\begin{align}
    R(J,\mu) = \int_D L(\mu,y) \mu J(dy)
\end{align}

Here $\mu J$ is the measure-kernel product defined in \ref{def:kernel_product}.

Denoting by $\mathscr{D}$  the set of kernels $X\to \Delta(\mathcal{D})$, the triple $\langle \mathscr{H}, \mathscr{D}, R\rangle$ forms a two player normal form game. The concepts of the minimax and Bayes solutions (Eq. \ref{eq:mm_soln} and \ref{eq:bayes_soln}) apply to this game.
\end{definition}

The loss function $L$ expresses preferences over (state, decision) pairs. However, it may be the case that our preferences don't naturally apply directly to such pairs. For a doctor deciding whether to prescribe a treatment to a patient, it is clear that this patient being healthy in the future is preferable to them being sick. While it may be possible to build a state for which it makes sense to evaluate the desirability of a (state, treatment) pair (for example, such a state may describe both the patient's illness and their responsiveness to treatement), such a description appears to be derived from the more basic preferences over future states of the patient's health.

This motivates the definition of a causal decision problem, which proceeds from a loss defined over outcomes rather than (state, decision) pairs.

\begin{definition}[Consequences]
Given a measurable space $(F,\mathcal{F})$ and a measurable decision set $(D,\mathcal{D})$, a Markov kernel $\kappa:D \to \Delta(\mathcal{F})$ is a consequence mapping, or just a consequence for short.
\end{definition}

\begin{definition}[Causal Theory]\label{def:causal_theory}
Given measurable spaces $(E,\mathcal{E})$, $(F,\mathcal{F})$ and a measurable decision set $(D,\mathcal{D})$, a causal theory is a Markov kernel $\tau:E\times D \to \Delta(\mathcal{F})$. Fixing $x\in E$, $\tau(x,\cdot;\cdot\cdot)$ is a consequence.
\end{definition}

\begin{definition}[Causal Decision Problem]
A causal decision problem (CDP) is a tuple $\langle (\mathscr{H}, \mathscr{T}, E, F), D, \RV{X}, L \rangle$. The sets $E$, $F$ and $D$ are equipped with $\sigma$-algebras which we leave implicit.

\begin{itemize}
    \item $\mathscr{H}\subset \Delta(\mathcal{E})$ is a hypothesis class
    \item $\mathscr{T}$ is a set of causal theories $\tau:E\times D\to \Delta(\mathcal{F})$ which we term a \emph{causal prospect}
    \item $(D,\mathcal{D})$ is a measurable decision set
    \item $\RV{X}:E\to X$ is a random variable representing the given information
    \item $L:\Delta(\mathcal{F})\times D\to [0,\infty)$ is a loss function
\end{itemize}

Given a decision map $J\in\mathscr{D}$, $\mu\in \mathscr{H}$ and $\tau\in \mathscr{T}$ the risk $R(J,\mu,\tau)$ is
\begin{align}
    R(J,\mu,\tau) = \int_D\int_E L(\nu J\tau, y) J(x;dy) \nu(dx)
\end{align}

\textbf{Note for proofreading:} This is the definition of risk that makes the closest connection with standard statistical decision problems. More elegant definitions would work with losses $L:\Delta(\mathcal{D}\otimes\mathcal{F})\to [0,\infty)$ (which might be more general than expected utility maximisation) or $L:D\times F\to [0,\infty)$ (which is simply an ordinary utility function).

The triple $\langle \mathscr{H}\times\mathscr{T}, \mathscr{D}, R\rangle$ is a normal form two person game.
\end{definition}

\begin{definition}[SDP and CDP reduction]
Given a statistical decision problem $\alpha$ with an induced game $\langle \mathscr{H}, \mathscr{D}, R\rangle$ and a causal decision problem $\beta$ with induced game $\langle \mathscr{H}'\times \mathscr{T}', \mathscr{D}, R'\rangle$ where the set of actions $\mathscr{D}$ is shared, $\alpha$ is reducible to $\beta$ if there is a function $f:\mathscr{H}\to \mathscr{H}'\times\mathscr{T}'$ such that for all $\mu\in \mathscr{H}$ and $J\in \mathscr{D}$ we have $R(J,\mu)=R'(J,f(\mu))$ and $\beta$ is reducible to $\alpha$ if there is some function $g:\mathscr{H}'\times\mathscr{T}'\to \mathscr{H}$ such that for all $(\nu,\tau)\in \mathscr{H}'\times \mathscr{T}'$ we have $R(J,g(\nu,\tau))=R'(J,\nu,\tau)$.
\end{definition}

\begin{theorem}
Every statistical decision problem $\langle (\mathscr{H},E),D,\RV{X},L\rangle$ can be reduced to a causal decision problem.
\end{theorem}
\begin{proof}
Define the theory $\tau_0:(z,y;A)\mapsto I_z(A)$ and the causal prospect $\mathscr{T}_0=\{\tau_0\}$ and consider the causal decision problem $\langle (\mathscr{H},\mathscr{T},E,E),D,\RV{X},L\rangle$. 

For the bijective map, take $f:\mathscr{H}\to \mathscr{H}\times\mathscr{T}$ defined by $f(\mu)=(\mu,\tau_0)$ and $f^{-1}(\nu,\tau_0)=\nu$.

Denote by $R$ the risk associated with $\langle (\mathscr{H},E),D,\RV{X},L\rangle$ and by $R'$ the risk associated with $\langle (\mathscr{H},\mathscr{T},E,E),D,\RV{X},L\rangle$. Then
\begin{align}
    R'(J,\nu,\tau_0) &= \int_D\int_E L(\nu J\tau_0, y) J(x;dy) \nu(dx)\\
                   &= \int_D\int_E L(\nu,y) J(x;dy) \nu(dx)\\
                   &=R(J,f(\nu,\tau_0))
\end{align}
\end{proof}

\begin{theorem}
A causal decision problem $\langle (\mathscr{H},\mathscr{T},E,F),D,\RV{X},L\rangle$ where $D$ is a denumerable set can be reduced to a statistical decision problem.
\end{theorem}

\begin{proof}
Take some $\mu\in \Delta(\mathcal{D})$ such that $\mu(\{y\})>0$ for all $y\in D$. Such a $\mu$ exists by the denumerability of $\mathcal{D}$.

Define a function $f:\mathscr{H}\times\mathscr{T}\to \mathscr{H}'$ such that $f(\nu,\tau)=(\mu\otimes\nu)\tau$. 
\end{proof}
