%!TEX root = main.tex

\section{Causal Statistical Decision Problems}
\vspace{-3mm}
\begin{table}[ht]
    \centering
\begin{tabular}{ |c|c|c| } 
 \hline
  & SDPs & CSDPs \\ 
 \hline
 State of the world & $\mathscr{H}$, hypothesis class & $\mathscr{T}$, causal theory \\ 
 Observations & $\RV{X}$ & $\RV{X}$ \\ 
 Decisions & $D$ & $D$ \\
 Known preferences & $\ell$, loss & $U$, generalised utility \\
 Derived preferences & $\ell$, loss & $L$, causal loss\\
 \hline
\end{tabular}
    \caption{Comparison of SDPs and CSDPs}
    \label{tab:sdp_cdp_comparison}
\end{table}

We develop causal statistical decision problems (CSDPs) inspired by statistical decision problems (SDPs) of \citet{wald_statistical_1950}. CSDPs differ from SDPs in that our preferences (i.e. utility or loss) are known less directly in former case. We show that every SDP can be represented by a CSDP and that the converse is sometimes but not always possible. We show that an analogoue of the fundamental \emph{complete class theorem} of SDPs applies to the class of CSDPs that can be represented by SDPs, but whether such a theorem applies more generally is an open question.

Following \citep{toutenburg_ferguson_1967}, we consider SDPs and CSDPs to represent normal form two person games. At the most abstract level the games represent the options and possible payoffs available to the decision maker, and this representation allows us to compare the two types of problem. In their more detailed versions,  CSDPs and SDPs differ in their representation of the state of the world and in the type of function that represents preferences. These differences are summarised in Table \ref{tab:sdp_cdp_comparison}.

\begin{definition}[Normal form two person game]
A normal form game is a triple $\langle \mathscr{S}, A, L\rangle$ where $\mathscr{S}$ and $A$ are arbitrary sets and $L:\mathscr{S}\times A\to [0,\infty)$ is a loss function.

\end{definition}
The set $\mathscr{S}$ is a set of possible states that the environment may occupy and $A$ is a set of actions the decision maker may take. The decision maker seeks an action in $A$ that minimises the loss $L$. Generally there is no action that minimises the loss for all environment states. A minimax solution is an action that minimises the worst case loss: $a^*_{mm} = \argmin_{a\in A} [\sup_{s\in \mathscr{S}} L(s,a)]$.

If the set $\mathscr{S}$ is equipped with a $\sigma$-algebra $\mathcal{S}$ and a probability measure $\xi\in \Delta(\mathcal{S})$ which we will call a ``prior'', a Bayes solution minimizes the expected risk with respect to $\xi$: $a^*_{ba} = \argmin_{a\in A} \int_{\mathcal{S}} L(s,a) \xi(ds)$.

\begin{definition}[Admissible Action]
Given a normal form two person game $\langle \mathscr{S}, A, L\rangle$, an action $a\in A$ is \emph{strictly better} than $a'\in A$ iff $L(s,a)\leq L(s,a')$ for all $s\in\mathscr{S}$ and $L(s_0,a)<L(s_0,a')$ for some $s_0\in \mathscr{S}$. If only the first holds, then $a$ is as good as $a'$. An \emph{admissible action} is an action $a\in A$ such that there is no action strictly better than $A$.
\end{definition}

\begin{definition}[Complete Class]
A class $C$ of decisions is a \emph{complete class} if for every $a\not\in C$ there is some $a'\in C$ that is strictly better than $a$.

$C$ is an \emph{essentially complete} class if for every $a\not\in C$ there is some $a'\in C$ that is as good as $a$.
\end{definition}

\begin{definition}[Reduction]\label{def:red_sdp_CSDP}
A normal form two person game $\alpha = \langle \mathscr{S}^\alpha, A, L^\alpha\rangle$ can be reduced to a different game sharing the same action set $\beta = \langle \mathscr{S}^\beta, A, L^\beta \rangle$ if there is a surjective function $g:\mathscr{S}^\alpha\to \mathscr{S}^\beta$ such that for every $a\in A$, $s\in \mathscr{S}^\alpha$, $L^\alpha(s,a) = L^\beta(g(s),a)$.
\end{definition}

Because CSDPs and SDPs posit states of nature of different types, they cannot represent exactly the same game. Reduction is a notion that allows us to say tht the game represented by a CSDP and an SDP are ``essentially'' the same. Reduction preserves the important properties of admissibility and completeness as shown in Appendix \ref{app:csdps}.

A statistical decision problem represents a normal form two-person game where the available actions are \emph{decision functions} that output a decision given data, the states of the environment are associated with probability measures on some measurable space and we assume a loss expressing preferences over decisions and states is known.

\begin{definition}[Statistical Experiment]\label{def:stat_expt}
A \emph{statistical experiment} relative to a set $\Theta$ on a measurable space $(E,\mathcal{E})$ is a set $\mathscr{H}=\{\mu_\theta|\theta\in \Theta\}$ where $\mu_\theta\in \Delta(\mathcal{E})$. The set $\Theta$ indexes the ``state of nature''. Given an experiment $\mathscr{H}$ relative to $\Theta$ we assume a map $\theta\mapsto \mu_\theta$ exists, but we typically leave it implicit.
\end{definition}


\begin{definition}[Statistical Decision Problem]
A statistical decision problem (SDP) is a triple $\langle\Theta, \mathscr{H}, D, \ell\rangle$. $\mathscr{H}\subset\Delta(\mathcal{E})$ is a statistical experiment relative to states $\Theta$, $D$ is the set of available decisions and $\ell:\Theta\times D\to [0,\infty)$ is a loss function.

Denote by $\mathscr{J}$ the set of stochastic decision functions $E\to \Delta(\mathcal{D})$. For $J\in \mathscr{J}$ and $\mu_\theta\in \mathcal{H}$, the risk $R:\mathscr{J}\times\Theta\to [0,\infty)$ is defined as $R(J,\theta) = \int_D \ell(\theta,y) \mu_\theta J(dy)$. The triple $\langle \mathscr{H}, \mathscr{J}, R\rangle$ forms a two player normal form game.
\end{definition}

The loss function $\ell$ expresses preferences over general (state, decision) pairs. It may be the case that our preferences are most directly known over future states of the world - we know which results of our decisions are desirable and which are undesirable, which we represent with a \emph{utility function}. In this case, if we are to induce preferences over the possible decisions, that we have a model that is more informative than a statistical experiment. In particular, we require each state of nature to be associated with both a distribution over the given information and a map from decisions to distributions over results - we call this map a \emph{consequence}, and the object that pairs a distribution and a consequence with each state of the world a \emph{causal theory}.

\begin{definition}[Consequences]
Given a measurable result space $(F,\mathcal{F})$ and a measurable decision space $(D,\mathcal{D})$, a Markov kernel $\kappa:D \to \Delta(\mathcal{F})$ is a \emph{consequence mapping}, or just a \emph{consequence}.
\end{definition}

\begin{definition}[Causal state]
Given a consequence $\kappa:D\to \Delta(\mathcal{F})$, a measurable observation space $(E,\mathcal{E})$ and some distribution $\mu\in \Delta(\mathcal{E})$, the pair $(\kappa,\mu)$ is a \emph{causal state} on $E, D$ and $F$. We refer to $\kappa$ as the consequence and $\mu$ as the observed distribution.
\end{definition}

We allow the ``observation'' space $E$ and the ``outcome'' space $F$ to differ as it it may be desirable to avoid modelling consequences on variables that are observed but irrelevant to preferences (see Theorems \ref{th:CSDP_u_red} and \ref{th:CSDP_ob_red}). In practice these spaces often coincide.

\begin{definition}[Causal Theory]\label{def:causal_theory}
A causal theory $\mathscr{T}$ is a set of causal states sharing the same decision, observation and outcome spaces. We abuse notation to assign the ``type signature'' $\mathscr{T}:E\times D\rightarrowtriangle F$ for a causal theory with observed distributions in $\Delta(\mathcal{E})$ and consequences of type $D\to \Delta(\mathcal{F})$. The causal states of a theory $\mathscr{T}$ may be associated with a master set of states $\Theta$, but in contrast to a statistical experiment this is not necessary to define the basic associated decision problem.
\end{definition}

\begin{definition}[Causal Statistical Decision Problem]\label{def:CSDP}
A causal statistical decision problem (CSDP) is a triple $\langle \mathscr{T}, D, u) \rangle$. $\mathscr{T}$ is a causal theory on $D\times E\rightarrowtriangle F$, $D$ is the decision set with $\sigma$-algebra $\mathcal{D}$ and $u:F\to \mathbb{R}$ is a utility function expressing preference over the results of decisions.

Given arbitrary $f:\mathscr{T}\to\mathbb{R}$, define $l:\mathscr{T}\times D\to \mathbb{R}$ by $l:(\kappa,\mu,y)\mapsto a f(\kappa,\mu) + b \mathbb{E}_{\delta_y\kappa}[u]$. We can define a loss (relative to $f$) $L:\mathscr{T}\times\Delta(\mathcal{D})\to [0,\infty]$ by
\begin{align}
    L((\kappa,\mu),\gamma) &:= \mathbb{E}_\gamma[l(\kappa,\mu,\cdot)]
    					   &= a f(\kappa,\mu) + b \mathbb{E}_{\gamma\kappa}[u]\label{eq:canonical_loss}\\
\end{align}
For $(\kappa,\mu)\in \mathscr{T}$ and $\gamma\in \Delta(\mathcal{D})$. Define $l^\kappa$

Given a decision function $J\in\mathscr{J}$ and $(\kappa,\mu)\in \mathscr{T}$, we define the risk $R:\mathscr{J}\times \mathscr{T}\to [0,\infty)$ by $R(J,\kappa,\mu) := L((\kappa,\mu),\mu J)$. The triple $\langle \mathscr{T}, \mathscr{J}, R\rangle$ is a normal form two person game.
\end{definition}

There are obvious similarities between SDPs and CSDPs: both have the same high level representation as a two person game which is arrived at by taking the expectation of a loss with respect to a decision function. We use the notion of a \emph{reduction} to formalise the notion of a CSDP and an SDP representing the same underlying decision problem. Reduction from a CSDP to an ordinary SDP is sufficient to import results from statistical decision theory such as Theorem \ref{th:complete_class}. The complete class theorem along with Corollary \ref{cor:CSDP_to_sdp} show that, at least for CSDPs with countable decision sets, finite causal theories and ordinary utilities, any admissible decision rule is a Bayes rule given \emph{some} prior on $\mathscr{T}$. Stronger versions of Theorem \ref{th:complete_class} exist for SDPs, and stronger versions are likely to exist for CSDPs as well.

\begin{theorem}[Complete class theorem (CSDP)]\label{th:complete_class}
Given an CSDP $\alpha:=\langle (\mathscr{T},E),D,\RV{X},U\rangle$ with risk $R$, if there is a reduction to an SDP $\beta:=\langle (\mathscr{H},F),D,\RV{Y},\ell \rangle$ with risk $R'$ such that $|\mathscr{H}|<\infty$ and $\inf_{J\in\mathscr{J},\mu\in\mathscr{H}} R'(J,\mu)<-\infty$, then the set of all Bayes decision functions is a complete class for $\beta$ and the set of all admissible Bayes decision functions is a minimal complete class for $\beta$.
\end{theorem}

\begin{proof}
This follows from Lemmas \ref{cor:red_comp} and \ref{lem:IB_rule}. See appendix \ref{app:csdps}.
\end{proof}

Any statistical decision problem can be reduced to a CSDP featuring a causal theory where decisions have no effect.

\begin{theorem}\label{th:sdp_to_CSDP}
Every SDP $\langle (\mathscr{H},E,\RV{X}),D,\ell\rangle$ can be reduced to a CSDP.
\end{theorem}
\begin{proof}
Choose a theory that matches every probability measure $\mu\in\Delta(\mathcal{E})$ with a consequence map that itself always yields $\mu$. Then construct a generalised utility $U$ that induces an identical risk. See Appendix \ref{app:csdps}.
\end{proof}

% The generalised utility $U$ enables Theorem \ref{th:sdp_to_CSDP}. A reduction is sometimes possible to an CSDP featuring an ordinary utility with a nontrivial theory, but whether this is always possible remains an open question.

A CSDP cannot, in general, be reduced to a statistical decision problem - for example, if we choose the utililty to be the variance of some random variable we may be able to achieve higher utility through a randomised decision than any nonrandomised decision under conditions where a regular SDP cannot have this property (see Example \ref{ex:ired_csdp} in Appendix \ref{app:csdps}). It is an open question whether this reduction is generally possible if the problem features a ordinary utility.

Theorem \ref{th:red_CSDP} reduces a CSDP to a SDP by associating each pair $(\mu,\kappa)$ in the causal theory with a distribution over $E\times F\times D$. This may be possible by finding a distribution on the product space for which $\mu$ is a marginal probability and $\kappa$ is a conditional distribution, but this is not necessary.

\begin{theorem}\label{th:red_CSDP}
Given a CSDP $\beta=\langle (\mathscr{T},E,\RV{X}),D,(U,F)\rangle$ where $U$ is an ordinary generalised utility, let $\mathscr{K}=\{\kappa|(\kappa,\mu)\in \mathscr{T}\}$ be the set of consequences. $\beta$ is reducible to a statistical decision problem on the measurable space $(E\times F\times D,\mathcal{E}\otimes \mathcal{F}\otimes \mathcal{D})$ if there is some surjective map $m:\Delta(\mathcal{F}\otimes\mathcal{D})\to \mathscr{K}$.
\end{theorem}

\begin{proof}
We construct the map $h$ based on the map $m$ and show that, given an ordinary utility $U$, it is possible to construct a loss $\ell$ such that the resulting SDP features the same risk assignments as the original CSDP. See Appendix \ref{app:csdps}.
\end{proof}

\begin{corollary}\label{cor:card_reduc}
If the cardinality of $\Delta(\mathcal{F}\otimes\mathcal{D})$ is at least as large as the cardinality of the set of Markov kernels $D\to \Delta(\mathcal{F})$ then an CSDP with an ordinary utility can always be reduced to a SDP.
\end{corollary}

A major open question, then, is if $(E,\mathcal{E})$ and $(D,\mathcal{D})$ are standard measurable spaces, the conditions for Corollary \ref{cor:card_reduc} hold in general. Corollary \ref{cor:CSDP_to_sdp} shows that the reduction can be made in general if $D$ is a denumerable set.

\begin{corollary}\label{cor:CSDP_to_sdp}
A CSDP $\langle (\mathscr{T},(E,\mathcal{E}),\RV{X}),(D,\mathcal{D}),(U,(F,\mathcal{F}))\rangle$ where $D$ is a denumerable set and $U$ is an ordinary generalised utility can be reduced to a statistical decision problem.
\end{corollary}

\begin{proof}
Take some probability measure $\pi\in \Delta(\mathcal{D})$ such that $\pi(\{y\})>0$ for all $y\in D$. Such a $\pi$ exists by the denumerability of $\mathcal{D}$. The map $m:\Delta(\mathcal{F}\otimes\mathcal{D})\to \mathscr{K}$ given by $m(\xi)(y;A) := \frac{\xi(A\times\{y\})}{\pi(\{y\})}$ is surjective. The result follows from Theorem \ref{th:red_CSDP}.
\end{proof}