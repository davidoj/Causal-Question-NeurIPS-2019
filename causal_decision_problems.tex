%!TEX root = main.tex

\section{Statistical Decision Problems and Causal Statistical Decision Problems}

A statistical decision problem (SDP) poses the following scenario: suppose we have a set of ``states of nature'' $\Theta$, a set of decisions $D$ and a loss function $l:\Theta\times D\to \mathbb{R}$. For each state of nature $\theta\in \Theta$ there is an associated probability measure $\mu_\theta\in \Delta(\mathcal{E})$ where $(E,\mathcal{E})$ is some measurable space. Call the stochastic map $\mathbf{H}:\theta\mapsto \mu_\theta$ a \emph{statistical experiment}. Given a \emph{decision strategy} $\mathbf{J}:E\to \Delta(\mathcal{D})$, define the \emph{risk} of $\mathbf{J}$ given state $\theta$ to be the expected loss of $\mathbf{J}$ in state $\theta$. Specifically, $R:\Delta(\mathcal{D})^E\times \Theta\to \mathbb{R}$ given by $R:(\mathbf{J},\theta)\mapsto \mathbf{H}_\theta \mathrm{J} l_\theta$, where we make use of the product notation for brevity.

We would ideally find a strategy $\mathbf{J}$ that minimises the risk in the ``true state'' $\theta^*$. Unfortunately, we don't know the true state. If there were a decision strategy that minimised the loss in every state, such a strategy would clearly minimise the loss in the true state, but most statistical decision problems don't admit such a strategy.  Two alternative decision rules are available:

Given a measure $\xi\in \Delta(\Theta)$ called a prior, $\xi$-\emph{Bayes decision rule} is a decision rule $\mathbf{J}^*_{\mathrm{Ba}}$ such that the \emph{Bayes risk} $R_\xi:\mathbf{J}\mapsto \int_\Theta H_\theta \mathbf{J} l_\theta d\xi$ is minimised. A \emph{minimax} decision rule $\mathbf{J}^*_{\mathrm{MM}}$ minimises the worst-case risk: $\mathbf{J}^*_{\mathrm{Mm}}\in \argmin_{\mathbf{J}} \max_{\theta\in \Theta} R(\mathbf{J},\theta)$ Unlike a Bayes rule, a minimax rule does not invoke a prior. In general, a decision rule is some rule that selects a decision on the basis of the risk functional $R(\mathbf{J},\cdot)$.

Our representation of statistical experiment is slightly different to, for example, \citet{le_cam_comparison_1996}, who introduces statistical experiments as an ordered collection of probability measures. Both representations do the same job, and the representation as a map makes for a clearer connection with causal statistical decision problems. 

Formally, we define an SDP as the tuple $\langle \Theta, E, D, \mathbf{H}, l\rangle$ where $\Theta, E$ and $D$ are measurable sets, $\mathbf{H}$ is a stochastic map $\Theta\to \Delta(\mathcal{E})$ and $l$ a measurable function $E\to \mathbb{R}$. We leave implicit the set of decision strategies $E\to \Delta(\mathcal{D})$. This is a very bare bones exposition of the theory of SDPs, and for more details we refer readers to \cite{toutenburg_ferguson_1967}.

Observe that a statistical decision problem supplies a loss $l$ that tells us immediately how desirable a pair $(\theta,d)\in\Theta\times D$ is. It is more typical to talk about how desirable the \emph{consequences} of a decision are than how desirable a (state, decision) pair is. If the set of possible consequences of a decision is denoted by a set $F$, let the desirability of an element $f\in F$ be given by a utility function $u:F\to \mathbb{R}$. Given such a $u$, the tuple $\langle \Theta, E, D, \mathbf{H}, u\rangle$ is an ill-posed problem: we want to evaluate the desirability of decision strategies $\mathbf{J}$, but we have no means of connecting decisions with consequences $F$. We introduce for each state of nature $\theta$ a \emph{consequence map} $\mathbf{C}_\theta:D\to \Delta(\mathcal{F})$; let $\mathbf{C}$ be the Markov kernel $\theta\mapsto \kappa_\theta$. We can then define the \emph{causal risk} $S:\Delta(\mathcal{D})^E\times \Theta\to \mathbb{R}$ by $S:(\mathbf{J},\theta)\mapsto -H_\theta \mathbf{F} C_\theta u$, and Bayes and minimax risks are defined analogously.

For each state $\theta\in \Theta$, the Markov kernel
\begin{align}
    \mathbf{T}_\theta := 
\begin{tikzpicture}
\path (0,0) node[dist] (theta) {$\delta_\theta$}
      +(0,-0.5) coordinate (D)
      ++(0.5,0) coordinate (copy0)
      ++(0.5,0) node[kernel] (H) {$H$}
      +(0,-0.5) node[kernel] (C) {$C$}
      ++(0.7,0) node (E) {$E$}
      +(0,-0.5) node (F) {$F$};
\draw (theta) -- (copy0);
\draw (D) -- (C) -- (F);
\draw (copy0) to [bend right] (C);
\draw (copy0) to [bend left] (H);
\draw (H) -- (E);
\end{tikzpicture}\label{eq:ttheta_def}
\end{align}

Is sufficient to compute the causal risk. Thus we can replace $\mathbf{H}$ and $\mathbf{C}$ with the \emph{causal theory} $\mathbf{T}:\Theta\times D\to \Delta(\mathcal{E}\otimes\mathcal{F})$ given by $(\theta,d)\mapsto \mathbf{T}_\theta(d;\cdot)$. A causal statistical decision problem (CSDP) is therefore a tuple $\langle \Theta, E, F, D, \mathbf{T}, u\rangle$.

Given a CSDP $\alpha = \langle \Theta, E, F, D, T, u\rangle$ where $\mathbf{T}$ is a theory arising from some $\mathbf{H}$ and $\mathbf{C}$ as in Equation \ref{eq:ttheta_def}, we can recover the original kernels by marginalisation: $\mathbf{H}= T(mathbf{Id}\otimes *)$ and $\mathbf{C}=\mathbf{T}(*\otimes \mathbf{Id})$. Given $\alpha$ and letting $l:= \mathbf{C}u$ we induce the canonical SDP $\beta=\langle \Theta, E, D, \mathbf{H}', l\rangle$ such that for any $\theta\in \Theta$, $\mathbf{J}$, $R^{(\beta)}(\mathbf{J},\theta) = S^{(\alpha)}(\mathbf{J},\theta)$, and thus $\alpha$ and $\beta$ will always produce identical recommendations.

It is also possible to induce a CSDP from an arbitrary SDP $\beta:=\langle \Theta, E, D, \mathbf{H}, l\rangle$. First, define $F:=\Theta\times D$ and then let $u:=-l$. Define $\mathbf{C}:\Theta\to (D\to \Delta(\mathcal{F}))$ by $\mathbf{C}:\theta\mapsto (d\mapsto (\theta,d))$, and then construct $\mathbf{T}$ from $\Theta, \mathbf{H}$ and $\mathbf{C}$ as in \ref{eq:ttheta_def}. Then the CSDP $\alpha:=\langle \Theta, E, F, D, \mathbf{T}, u\rangle$ has the property $S^{(\alpha)}(\mathbf{J}, \theta) = R^{(\beta)}(\mathbf{J},\theta)$.

Causal theories are the central object of study here. They provide a bridge between the experiment $\mathbf{H}$ and the consequences $\mathbf{C}$ and allow us to use the former to make inferences about the latter. 