\section{Causal Decision Problems}

The normal form representation of a two person game is a triple:

\begin{definition}[Two person game (normal form)]
A normal form game is a triple $\langle \mathscr{S}, A, L\rangle$ where $\mathscr{S}$ and $A$ are arbitrary sets and $L:\mathscr{S}\times A\to [0,\infty)$ is a loss function.

By way of interpretation, we will identify the set $\mathscr{S}$ with a set of possible states that the environment may occupy and $A$ with a set of actions some decision maker may take. The decision maker seeks an action in $A$ that minimises the loss $L$.
\end{definition}

The definition presented here does not generally admit a unique best action. A minimax solution chooses an action that minimises the worst case loss:
\begin{align}
    a^*_{mm} = \argmin_{a\in A} [\sup_{s\in \mathscr{S}} L(s,a)]\label{eq:mm_soln}
\end{align}

If the set $\mathscr{S}$ is equipped with a $\sigma$-algebra $\mathcal{S}$, then given a probability measure $\xi\in \Delta(\mathcal{S})$ which we will call a ``prior'', the Bayes solution minimizes the expected risk with respect to $\xi$:
\begin{align}
    a^*_{ba} = \argmin_{a\in A} \int_{\mathcal{S}} L(s,a) \xi(ds)
\end{align}

A statistical decision problem is an instance of a two person zero sum game.

\begin{definition}[Statistical Decision Problem]
A statistical decision problem (SDP) is defined by a tuple $\langle (\mathscr{H},E), D, \RV{X}, L\rangle$.
\begin{itemize}
    \item Given a $\sigma$-algebra $\mathcal{E}$ on $E$, $\mathscr{H}\subset\Delta(\mathcal{E})$ is a hypothesis class.
    \item The set $D$, which is equipped with a $\sigma$-algebra $\mathcal{D}$, is a set of decisions
    \item $\RV{X}:E\to X$ is a random variable representing the information available for the statistician to make a decision
    \item $L:\mathcal{H}\times D\to [0,\infty)$ is a loss function
\end{itemize}

Denote by $\mathscr{D}$ the set of decision kernels $X\to \Delta(\mathcal{D})$. For $J\in \mathscr{D}$ and $\mu\in \mathcal{H}$, the risk is defined as:
\begin{align}
    R(J,\mu) = \int_D L(\mu,y) \mu J(dy)
\end{align}

Here $\mu J$ is the measure-kernel product defined in \ref{def:kernel_product}.

Denoting by $\mathscr{D}$  the set of kernels $X\to \Delta(\mathcal{D})$, the triple $\langle \mathscr{H}, \mathscr{D}, R\rangle$ forms a two player normal form game. The concepts of the minimax and Bayes solutions (Eq. \ref{eq:mm_soln} and \ref{eq:bayes_soln}) apply to this game.
\end{definition}

The loss function $L$ expresses preferences over (state, decision) pairs. However, it may be the case that our preferences don't naturally apply directly to such pairs. For a doctor deciding whether to prescribe a treatment to a patient, it is clear that this patient being healthy in the future is preferable to them being sick. While it may be possible to build a state for which it makes sense to evaluate the desirability of a (state, treatment) pair (for example, such a state may describe both the patient's illness and their responsiveness to treatement), such a description appears to be derived from the more basic preferences over future states of the patient's health.

This motivates the definition of a causal decision problem, which proceeds from a loss defined over outcomes rather than (state, decision) pairs.

\begin{definition}[Consequences]
Given a measurable space $(F,\mathcal{F})$ and a measurable decision set $(D,\mathcal{D})$, a Markov kernel $\kappa:D \to \Delta(\mathcal{F})$ is a consequence mapping, or just a consequence for short.
\end{definition}

\begin{definition}[Causal Theory]\label{def:causal_theory}
Given measurable spaces $(E,\mathcal{E})$, $(F,\mathcal{F})$ and a measurable decision set $(D,\mathcal{D})$, a causal theory is a Markov kernel $\tau:E\times D \to \Delta(\mathcal{F})$. Fixing $x\in E$, $\tau(x,\cdot;\cdot\cdot)$ is a consequence.
\end{definition}

\begin{definition}[Causal Decision Problem]
A causal decision problem (CDP) is a tuple $\langle (\mathscr{H}, \mathscr{T}, E, F), D, \RV{X}, L \rangle$. The sets $E$, $F$ and $D$ are equipped with $\sigma$-algebras which we leave implicit.

\begin{itemize}
    \item $\mathscr{H}\subset \Delta(\mathcal{E})$ is a hypothesis class
    \item $\mathscr{T}$ is a set of causal theories $\tau:E\times D\to \Delta(\mathcal{F})$ which we term a \emph{causal prospect}
    \item $(D,\mathcal{D})$ is a measurable decision set
    \item $\RV{X}:E\to X$ is a random variable representing the given information
    \item $L:\Delta(\mathcal{F})\times D\to [0,\infty)$ is a loss function
\end{itemize}

Given a decision map $J\in\mathscr{D}$, $\mu\in \mathscr{H}$ and $\tau\in \mathscr{T}$ the risk $R(J,\mu,\tau)$ is
\begin{align}
    R(J,\mu,\tau) = \int_D\int_E L(\tau(x,y; \cdot), y) J(x;dy) mu(dx)
\end{align}
\end{definition}




\begin{definition}[Generalised Causal Prospect]\label{def:gen_causal_prospect}
A generalised causal prospect is a set of generalised causal theories.
\end{definition}

\begin{definition}[Generalised Statistical Causal Decision Problem]\label{def:gen_scdp}
A generalised statistical causal decision problem (GSCDP) is a tuple $\langle (\Omega,\mathcal{F},\kappa^*,\mu), (D,\mathcal{D}), L, \RV{X}, \mathscr{T} \rangle$.

The elements $(\Omega, \mathcal{F},\kappa^*), (D,\mathcal{D}), L$ are in common with a causal decision problem. $\RV{X}:\Omega\to X$ is a random variable distributed according to $\RV{X}_*\mu$ where $\mu\in \mathscr{H}\subset \Delta(\mathcal{F})$. $\mathscr{T}$ is a generalised causal prospect containing theories $X\times D\to \Delta(\mathcal{F})$.

The objective of a GSCDP is to find a decision kernel $\phi:X\to \Delta(D)$ such that $L(\mu\phi\kappa^*)$ is minimal.

If a GSCDP is realisable, given arbitray $A\in \mathcal{X}$ such that $\mu(A)>0$, the true kernel $\kappa^*$ is assumed to belong to the set $\{\frac{1}{\mu(A)}\int_A \tau(\cdot;x,\cdot)\mu(dx)|\tau\in\mathscr{T}\}$. That is, we assume the causal prospect is sufficiently large to contain a theory mapping to the true kernel with probability 1.
\end{definition}

A GSCDP can be reduced to a regular CDP. The intuition is that a decision kernel for a statistical causal decision problem can be considered to be an ordinary decision for a regular causal decision problem. If the set of available decision kernels is convex and closed, each stochastic decision in the regular causal decision problem corresponds to a decision kernel in the GSCDP, so each problem presents exactly the same set of options.

\begin{theorem}[Reduction from GSCDP to CDP]\label{th:gscdp_to_cdp}
Given a GSCDP $Q=\langle (\Omega,\mathcal{F},\kappa^*,\mu), (D,\mathcal{D}), L, \RV{X}, \mathscr{T} \rangle$, suppose we further have a set of available decision functions $\Phi\subset \Delta(\mathcal{F})^D$ along with some $\sigma$-algebra $\mathcal{E}$ and a hypothesis class $\mathscr{H}\ni \mu$. Then $Q$ can be reduced to a regular causal decision problem $\langle (\Omega,\mathcal{F},\kappa^{*\prime}), (D',\mathcal{D}'), L, \mathbf{K}' \rangle$ with the identification $(D',\mathcal{D}') = (\Phi,\mathcal{E})$, $\kappa^{*\prime}:\phi\mapsto \mu\phi \kappa^*$, $\mathbf{K}' = \{\phi\mapsto \nu\phi\frac{1}{\nu(A)}\int_A\tau(\cdot;x,\cdot)\nu(dx)|\tau\in\mathscr{T},\nu\in \mathscr{H},\forall A:\nu(A)>0\}$.

If $\Phi$ is convex and closed, then each $\theta\in \Delta(\mathcal{E})$ can be identified with some $\phi\in \Phi$ such that $\theta\kappa^{*\prime} = \mu\phi\kappa^*$.
\end{theorem}

\begin{proof}
For the reduction, we must show that $\kappa^*\in \{\frac{1}{\nu(A)}\int_A \tau(\cdot;x,\cdot)\nu(dx)|\tau\in \mathscr{T},\nu\in\mathscr{H},\forall A:\nu(A)>0\}$ implies $\kappa^{*\prime}\in \mathbf{K}'$. This is trivial by the definition of $\mathscr{H}$, $\mathbf{K}'$ and $\kappa^{*\prime}$.

For the identification, we require for each $\theta\in \Delta(\mathcal{E})$ there is a corresponding $\phi\in \Phi$ such that $L(\mu\phi\kappa^*)=L(\theta\kappa^{*\prime})$. Observe that given any $\theta\in \Delta(\mathcal{E})$ by convexity and closure there exists $\phi_0\in \Phi$ such that $\phi_0 = \int_\Phi \phi \theta(d\phi)$. Therefore $\theta\kappa^{*\prime}=\int_\Phi \mu \phi \kappa^* \theta(d\phi) = \mu \int_\Phi \phi \theta(d\phi) \kappa^*=\mu\phi_0\kappa^*$.
\end{proof}