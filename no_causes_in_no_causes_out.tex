%!TEX root = main.tex

\section{Coarsening and Saved Inference}

The causal theories associated with both CBN and PO models are very profligate. They define many decisions that are unlikely to be considered in a pragmatic decision problem, and in practice it is usually only possible to determine the consequences of a small subset of these decisions if it is possible to determine any at all. In additon, proponents of both theories have advocated for the universality of the ``causal effects'' they represent:

\begin{quote}
The perspective that (1) the science exists independently of how we try to learn about it and that (2) if the model used for analysis of the resulting data is approximately correct, then the resulting posterior distribution will give a fair summary of the current state of knowledge of that science seems, at least to me, consistent with common views of the scientific enterprise
[...]
The potential outcomes, together with covariates, define the science in the sense that all causal estimands are functions of these values \citep{rubin_causal_2005}
\end{quote}

\begin{quote}
By representing the domain in the form of an assembly of stable mechanisms, we have in fact created an oracle capable of answering queries about the effects of a huge set of actions and action combinations \citep{pearl_causality:_2009}
\end{quote}

We present here a somewhat speculative account of what both of these approaches are trying to achieve based on the notions of \emph{coarsening} and \emph{saved inference}. With these, we can show that it is sometimes possible to reuse the results of inference performed with a dextrous theory $\mathbf{T}$ with a more pragmatic theory $\mathbf{T}'$.

\begin{definition}[Coarsening]
A theory $\mathbf{T}:\Theta\times D\to \Delta(\mathcal{E}\otimes\mathcal{F})$ can be coarsened to a theory $\mathbf{T}':\Theta\times D'\to \Delta(\mathcal{E}\otimes\mathcal{F})$ if there exists $M:D'\to \Delta(\mathcal{D})$ such that $(\xi \otimes \mathrm{Id}_D) \mathbf{T}'  = (\xi \otimes M) \mathbf{T}$. We say that $\mathbf{T}'$ is \emph{clumsier} than $\mathbf{T}$ or $\mathbf{T}$ is \emph{more dextrous} than $\mathbf{T}'$.
\end{definition}

Given $\mathbf{T}$, an event $A\in \mathcal{E}$ with $\xi H \mathds{1}_A >0$, write the theory conditioned on $A$ as $\mathbf{T}_\xi|A:D\to \Delta(\mathcal{F})$, defined as
\begin{align}
 \mathbf{T}_\xi|A:= (\xi H (A))^{-1}\begin{tikzpicture}
\path (0,0) node[dist] (theta) {$\xi$}
      +(0,-1) node (D) {}
      ++(0.5,0) coordinate (copy0)
      ++(0.5,0) node[kernel] (H) {$H$}
      +(0,-1) node[kernel] (C) {$C$}
      ++(0.7,0) node[expectation] (E) {$\mathds{1}_A$}
      +(0,-1) node (F) {};
\draw (theta) -- (copy0);
\draw (D) -- (C) -- (F);
\draw (copy0) to [bend right] (C);
\draw (copy0) to [bend left] (H);
\draw (H) -- (E);
\end{tikzpicture}
\end{align}

Note that $\mathbf{T}_\xi|A$ along with a strategy $\gamma\in \Delta(\mathcal{D})$ is the conditional probability of $\RV{F}$ by the elementary definition - for $B\in \mathcal{F}$, $\mathbf{T}_{\xi,\gamma}|A:B\mapsto \frac{(\xi\otimes\gamma) \mathbf{T} (A,B))}{\xi H (A)}$.

\begin{theorem}\label{th:mod_extn}
Given any prior $\xi$, a strategy $\gamma$ and $A\in \mathcal{E}$ such that $\mathbf{T}_\xi|A$ is defined, then there exists $\mathbf{M}$ such that $\mathbf{T}'_{\gamma,\xi} | A = \gamma M \mathbf{T}_\xi|A$ if and only if $\mathbf{T}'$ is a coarsening of $\mathbf{T}$.
\end{theorem}

\begin{proof}
Let the coarsening from $\mathbf{T}$ to $\mathbf{T}'$ be witnessed by $\mathbf{M}:D'\to \Delta(\mathcal{D})$. For arbitrary $\xi$, $A$ such that $\xi \mathbf{H} (A)>0$ and arbitrary $\gamma$:
\begin{align}
\gamma M \mathbf{T}_\xi|A &= (\xi \mathbf{H} (A))^{-1}\begin{tikzpicture}
\path (0,0) node[dist] (theta) {$\xi$}
      +(0,-1) node[dist] (D) {$\gamma$}
      +(0.5,-1) node[kernel] (M) {$\mathbf{M}$}
      ++(1,0) coordinate (copy0)
      ++(1,0) node[kernel] (H) {$\mathbf{H}$}
      +(0,-1) node[kernel] (C) {$\mathbf{C}$}
      ++(0.7,0) node[expectation] (E) {$\mathds{1}_A$}
      +(0,-1) node (F) {};
\draw (theta) -- (copy0);
\draw (D) -- (M)--(C) -- (F);
\draw (copy0) to [bend right] (C);
\draw (copy0) to [bend left] (H);
\draw (H) -- (E);
\end{tikzpicture}\\
&= (\xi \mathbf{H} (A))^{-1}\gamma (\xi\otimes \mathbf{M}) \mathbf{T} (\mathds{1}_A\otimes \mathrm{Id}_F)\\
&= (\xi \mathbf{H} (A))^{-1}\gamma (\xi\otimes \mathrm{Id}_D) \mathbf{T}' (\mathds{1}_A\otimes \mathrm{Id}_F)\\
&= \mathbf{T}'_{\gamma,\xi} | A
\end{align}



\end{proof}

In other words, if and only if $\mathbf{T}$ can be coarsened to $\mathbf{T}'$ then we can ``save'' the results of conditioning $\mathbf{T}_\xi$ on $A$ via $\mathbf{T}_\xi|A$ and later on we can determine the effects of some strategy $\gamma$ on $\mathbf{T}'$ via $\gamma \mathbf{M} \mathbf{T}_\xi|A$.

We will return to our discussion of the the ``effect of taking the treatment'' for an example. Suppose we have $\Theta=[0,1]^2:=\Theta_1\otimes \Theta_2$ where given $(\theta_1,\theta_2)\in\Theta$ we identify $\theta_1$ with ``treatment efficacy'' and $\theta_2$ with ``treatment susceptibility''. Let $Y,W=\{0,1\}$ where $Y$ is the set of outcomes and $W$ indicates whether or not a patient took the treatment. Define a potential outcomes model $H_{PO}:\Theta\to \Delta(\mathcal{Y}^2)$, $H_W:\Theta\to \Delta(\mathcal{W})$ and $H_Y:W\times Y^2\to \Delta(\mathcal{Y})$. Furthermore, suppose we have $D=[0,1]^2$ and $C_W:\Theta_2\times D\to \Delta(\mathcal{W})$ defined by $C_W(\theta_2,d_1,d_2;A):= \theta_2(d_1\delta_1(A) (1-d_1)\delta_0(A)) + (1-\theta_2)(d_2\delta_1(A)+(1-d_2)\delta_0(A))$; that is, $d_1$ and $d_2$ parametrise the set of Markov kernels $\Theta_2\to \Delta(\mathcal{W})$. Then $\langle H_{PO},H_W,H_Y,C_W\rangle$ defines a causal theory $T$. Suppose we observe $A\in \mathcal{E}$; then for $(d_1,d_2)\in D$, $B\in \mathcal{E}$:

\begin{align}
	T_\xi|A (d_1,d_2;B) = \frac{1}{\int_\Theta (H_{PO,\theta}\otimes H_{W,\theta})H_Y(A)}\int_\Theta (H_{PO,\theta}\otimes H_{W,\theta})H_Y(A) C_{W,\theta} (d_1,d_2;B) d\xi
\end{align}

$T_\xi|A$ describes a Markov kernel from $D\to \Delta(\mathcal{E})$. However, it is unlikely to be the case that $D$ describes the actual decisions we have available - we probably don't have the ability to choose the exact relationship between treatment susceptibility and treatment taking. In fact, all that may be actually available are some decisions $D'=\{0,1\}$ where 0 represents no prescription and 1 represents prescription; these may yield uncertain relationships between $\theta_2$ and $\RV{W}$. While we might not know which relationship a decision to prescribe or not induces, we might accept that influencing this relationship is the only important consequence of this decision. That is, we might accept that for \emph{some} $M:D'\to \Delta(\mathcal{D})$ a causal theory $T':\Theta\times D'\to \Delta(\mathcal{E}^2)$ of the form $T' = (\mathrm{Id}_\Theta\otimes M)T$ is appropriate. Then, because $T'$ is an extension of $T$, rather than having to rerun our inference we can simply compute $MT_\xi|A$.

% While there are numerous differences between the Potential Outcomes and Causal Bayesian Network approach to causality, it is interesting to reflect on their different approaches to handling Theorem \ref{th:ncinco}. The CBN approach fixes a number of conditional probabilities among variables unless they are directly intervened on and combines this with a standard ``hard-intervention'' operation. Potential outcomes, in the form we discuss here, represents by potential outcomes a fixed set of properties of outcomes (``the science'', as Rubin calls it) which are then partially revealed by an assignment function which may respond in problem specific ways to decisions. As we have discussed regarding ETT, the potential outcomes approach is capable of representing decisions that are known to have certain effects but we may be uncertain as to how exactly they achieve these effects, though this is not always enough to satisfactorily represent the problem of interest (see the discussion of ITT). The CBN approach features a hard transition between fixed flexible conditional probabilities - either an intervention is not on a node, in which case its probability conditional on its parents is fixed, or it is on that node in which case the conditional probability is vastly different. This doesn't appear to be ideal for representing uncertainty over how a decision might correspond to an intervention. In fact \emph{any} CBN with hard interventions can in fact represent any causal theory if we permit decisions to correspond to unknown, state-dependent mixtures of interventions (this reflects the fact that every joint probability distribution can be achieved with the right mixture of hard interventions on every node). The fact that we lose dependence on the graph suggests that a na\"ive approach to uncertainty over the decision bias may be too general. There are many versions of CBNs with generalised interventions that may address this issue.

% It is interesting to consider whether there might be principles of causal inference that eschew the two part approach of fixing some underlying notion of ``the science'' and separately adding in some kind of decision bias. One could imagine, for example, a causal theory that posits that consequences minimise some combination of causally appropriate dissimilarity measures from the observational distribution and from a decision-dependent target distribution without any clear commitments to invariant principles of science. It's not obvious how we should construct such measures without appealing to some notion of the underlying science, but we regard it as an interesting question nonetheless.

