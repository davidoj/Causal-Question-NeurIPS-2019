%!TEX root = main.tex

\section{Introduction}

\vspace{-3mm}

It is widely accepted that causal knowledge and statistical knowledge are distinct. Statistics is concerned with \emph{association} while causation is concerned with \emph{consequences}; a distinction of this type goes back at least to Hume \citep{morris_david_2019}. There are a number of modern approaches to representing causal knowledge, which broadly fall into two categories: those based on some means of representing counterfactual relationships such as \emph{potential outcomes} \citep{rubin_causal_2005} and those based on causal graphical models such as \emph{causal Bayesian networks} \citep{pearl_causality:_2009}. There have been a number of attempts to bring these two views together \cite{richardson2013single,shpitser_complete_2008}. 

Perhaps as a result of the requirements of representing causal knowledge, both approaches feature idiosyncratic elements, and it isn't fully transparent where they follow statistical theory and where they depart from it. For example, causal Bayesian networks feature $do$ operations that appear to have no statistical counterpart, while counterfactual problems can be formulated as missing data problems. However, \citet{pearl_causality:_2009} claims that the counterfactual approach subsumes the Bayesian network approach, suggesting that perhaps $do$ operations are statistical objects in disguise or, alternatively, that counterfactual random variables are somehow non-standard. 

We develop an approach to causal inference taking statistical decision theory \citep{wald_statistical_1950} as a starting point and, with conceptual cues from \citet{savage_foundations_1972}, introducing the notion of utilities and consequences. As a result our approach has very clear connections with statistical theory. We develop causal statistical decsion theory (CSDT) which features \emph{causal theories} as the central object of study. Causal theories play a role analogous to \emph{statistical experiments} in ordinary statistical decision theory. They differ in that, where a statistical experiment gives you a probability measure, a causal theory gives a stochastic map.

Causal Bayesian networks themselves have a natural representation as causal theories. Against Pearl's claim that counterfactual models subsume interventional ones, we find that some arbitrary choices must be made in order to represent potential outcomes models as causal theories. Nonetheless, we propose a plausible strategy for representing potential outcomes models as causal theories. We find that these two approaches yield very different causal theories from one another, though these differences may disappear when we move from ``idealised'' theories to more realistic theories that we might actually use to make decisions.

We then turn our attention to a notable feature of the idealised causal theories induced by both approaches: they each allow for unrealistically fine control over many of their consequences. We posit that these theories are intended to inform realistic theories used for making decisions. We show that this is possible if the realistic theories can be derived from the idealised theories via what we term \emph{coarsening}. To our knowledge, this is the first attempt to formalise the notion of ``stable knowledge'' that is often raised as a key potential advantage of causal understanding over purely statistical learning \citep{arjovsky_invariant_2019,pearl_causality:_2009,rubin_causal_2005}.

% Potential Outcomes (PO) posits a large joint distribution over observed variables $\RV{X}$, $\RV{Y}$ and partly unobserved ``potential outcome'' variables $\RV{X}_0$, $\RV{Y}_1$ and so forth. A potential outcome variable $\RV{Y}_i$ is interpreted as ``the value of $\RV{Y}$ that would be observed if the action identified by $i$ were taken''. Under some conditions, an investigator with access to a joint distribution over observed variables may be able to infer certain properties of the distribution over potential outcome variables such as $\mathbb{E}[\RV{X}_i]$.

% Queries in the CBN framework may be concerned with identification of causal effects given a graph and a probability distribution \citep{tian2002general}, or with the determination of the true causal graph given just a probability distribution \citep{spirtes_causation_1993}. Queries in the PO framework usually concern identification of properties of the distribution of potential outcome variables known as \emph{treatment effects} given a dataset and certain assumptions about this distribution \citep{rubin_causal_2005,robins2010alternative}. In both cases, these queries fit the paradigm of ``determining true properties of nature'' rather than ``learning to output a decision that minimises a loss''.

% The first contribution of this paper is the notion of a \emph{causal statistical decision problem} (CSDP) that proceeds from a natural extension of an ordinary statistical decision problem (SDP) introduced by \citep{wald_statistical_1950}. We suppose that, in contrast to an ordinary SDP where we have known preferences over (decision, state of nature) pairs, we know only our preferences over the \emph{outcomes} of decisions, which we represent with a utility function. Uncertainty over the consequences of decisions is represented by a \emph{causal theory} that connects observed data with \emph{consequence maps}. 

% We show by a reduction that results concerning standard SDPs are also true of (at least) a subset of CSDPs.  We also show that both Causal Bayesian Networks and joint distributions over potential outcomes have a natural representation as causal theories. Together these results show, for example, that the class of Bayes decision functions is a complete class for CSDPs based on Causal Bayesian Networks provided certain conditions on the utility and size of the available set of decisions are met.

% The notion of a causal theory presented here can naturally represent models cast in terms of CBNs or POs, but there are many causal theories that cannot easily be represented by either. We discuss a question motivated by this more general perspective: \emph{given a CBN with observable predictions, what should be assumed when the data doesn't match these predictions?} We show that different answers to this question yield widely divergent conclusions.

% A key strength of our perspective is the possibility of theoretical treatment of causal learning from a viewpoint that is agnostic about the nature of ``causal knowledge''. Causal knowledge is a tricky domain from philosophy to practice, and there are many proposals for causal assumptions that do not neatly fit in either the CBN or PO camps \citep{bongers_theoretical_2016,dawid_beware_2010,bengio_meta-transfer_2019}. The theory presented here is capable of posing questions such as ``does a proposed causal learning method work?'' without first requiring commitments on the nature of causal knowledge. Substantial progress in machine learning has been the result of developing generic principles and learning techniques that are relevant to many datasets from many domains and are less reliant on the judgement of domain experts. We believe this separation of concerns is crucial to the advancement of generic techniques of causal learning.

% Our approach is similar to that of \citet{dawid_decision-theoretic_2012}, but where he takes a ``bottom-up'' approach of developing a decision theoretic answer to particular causal questions, our approach is ``top-down'', proceeding from a general account of a causal problem to the particular objects needed to answer it. It also shares similarities with Causal Decision Theory developed by \citet{lewis_causal_1981}, though the connection with statistical decision theory is better understood at this point.

% There are two main assumptions used so far in pursuing generic causal inference: \emph{faithfulness} and the \emph{independence of cause and mechanism}. The assumption of faithfulness (together with the Causal Markov Condition) facilitates the exclusion of some graphical models on the basis of conditional independences found in the data \citep{spirtes_causation_1993} while the principle of independence of cause and mechanism enables the use of a number of special purpose techniques to assess the \emph{algorithmic independence} of marginal and conditional distributions which leads to preferment of some graphical models over others \citep{lemeire_replacing_2013, peters_identifiability_2012}.



% Both faithfulness and the independence of cause and mechanism are employed in learning causal Bayesian networks. While these are undoubtedly useful tools for causal reasoning, causal Bayesian networks are not ideal objects for the analysis of causal learning at a very general level:
% \begin{itemize}
%     \item There are causal models which cannot be captured by a DAG \citep{dawid_beware_2010,bongers_theoretical_2016}
%     \item There is controversy over how causal Bayesian networks should be adapted to answer counterfactual questions \citep{richardson2013single}
%     \item Under appropriate conditions, different graphs may induce the same set of interventional distributions \citep{peters_structural_2015}
%     \item A standard causal Bayesian network posits an intervention operation for every variable under consideration, while the actions to be evaluated may be much more limited. Learning such a graph appears to run afoul of Vapnik's precept: \emph{When solving a given problem, try to avoid solving a more general problem as an intermediate step} \citep{vapnik_nature_2013}
% \end{itemize}
