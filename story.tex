%!TEX root = main.tex

\section{Introduction: Consequences of Decisions}

This thesis is concerned with understanding a particular kind of decision problem: we are given a set of feasible decisions and a set of observed data, we know the potential consequences these decisions may have and we know how desirable these consequences are. We wish to develop strategies for selecting decisions that are likely to lead to favourable consequences. For example, the decisions may be a set of possible medical treatments, consequences are states of health and data are from published medical trials; we also assume that some states of health are known to be more desirable than others. 

This general kind of problem seems to me to be a reasonable description of a type of problem that people often face (allowing that it may be somewhat simplified). But I need not rely only on an appeal to intuition to argue that this is an important class of problem, as decision problems of this type have a long and extensive history of study: \citet{von_neumann_theory_1944} considers the problem of choosing between consequences directly with some means of evaluating their desirability, \citet{weirich_causal_2016} discusses decision problems featuring decisions, consequences and desirability but no explicit consideration of data. \citet{wald_statistical_1950} considers the problem of selecting a favourable decision given a set of data and a desirability function, though he eschews explicitly considering consequences, and \citet{savage_foundations_1972} develops Wald's theory to also include consequences of decisions, yielding a class of decision problems very similar to those discussed here. Many of the solutions presented by these authors have ``entered the water supply'' - in particular, the expected utility theory of \citet{von_neumann_theory_1944} underpins an enormous amount of the work on decision problems of any type, and the risk functionals of \citet{wald_statistical_1950} are fundamental to much of statistics and machine learning. Even theories that reject the particulars proposed by these authors build on the foundations laid by them - in short, the type of problem studied here is widely accepted to be a very important class of problem.

This type of problem has particular practical relevance to the field of \emph{causal inference}. A Google Scholar search for ``causal inference'' found, in the top five results: 
\begin{itemize}
	\item \citet{holland_statistics_1986} and \citet{frangakis_principal_2002} discuss causal inference as the project of relating \emph{treatments} to \emph{responses} via \emph{observations}. If we postulate an implicit desirability of responses, we have a decision problem of the type outlined
	\item \citet{morgan_counterfactuals_2014} provide in their opening paragraph three examples of causal problems. Two of them have clear interpretations as decision problems where decisions involve funding of charter schools and engaging in or encouraging college study, while the third is perhaps more concerned with \emph{responsibility} and \emph{remedy}:
	\begin{itemize}
		\item Do charter schools increase test scores?
		\item Does obtaining a college degree increase an individual's labor market earnings?
		\item Did the use of a butterfly ballot in some Florida counties in the 2000 presidential election cost Al Gore votes?
	\end{itemize}
	\item \citet{pearl_causal_2009} begins with four examples of causal questions. The first appears to be part of a decision problem, while the second to fourth are questions of responsibility and remedy:
	\begin{itemize}
		\item What is the efficacy of a given drug in a given population? 
		\item Whether data can prove an employer guilty of hiring discrimination? 
		\item What fraction of past crimes could have been avoided by a given policy? 
		\item What was the cause of death of a given individual, in a specific incident?
	\end{itemize}
	\item \citet{robins_marginal_2000} is again concerned with estimating responses to treatments via observations
\end{itemize} 
From this informal survey we have six out of ten example problems that correspond directly to the type of decision problem studied here. While decision problems are a substantial class of causal inference problems, we find that questions of responsibility also figure prominently. It is OK that there are other interesting causal questions; the focus on decision problems is justified by the fact that decision problems are an important class of problem in general, and also a large and important class of problems within causality in particular. We do not require that they are the \emph{only} class of problems that causal researchers may be interested in.

One key difference between CSDT and existing popular approaches to causal inference is that we stipulate that \emph{the set of decisions is a feature of the problem}, and does not depend in any way on how we choose to analyse the problem. Existing approaches provide ``standard'' objects (e.g. counterfactual random variables) or operations (e.g. intervening on the value of some random variable) which, if they are to be interpreted as decisions, impose some presuppositions on the nature of the decisions available. Even if these presuppositions correspond to very common regularities of decision problems, we take the view that such regularities should be included as assumptions rather than be part of the language used to express the problem.

This difference is illustrated by the question of \emph{external validity}. Given a randomised controlled trial (RCT), under ideal conditions existing causal inference approaches agree that certain causal effects can be consistently estimated. However, as reported by \citet{deaton_understanding_2018}:
\begin{quote}
	Trials, as is widely noted, often take place in artificial environments which raises well recognized problems for extrapolation. For instance, with respect to economic development, Drèze (J. Drèze, personal communications, November 8, 2017) notes, based on extensive experience in India, that “when a foreign agency comes in with its heavy boots and deep pockets to administer a ‘treatment,’ whether through a local NGO or government or whatever, there tends to be a lot going on other than the treatment.” There is also the suspicion that a treatment that works does so because of the presence of the ‘treators,’ often from abroad, and may not do so with the people who will work it in practice.
\end{quote}
Here, Drèze is describing the problem of determining the consequences of the ``treatment in practice'', and why these may differ from the ``causal effects of treatment in the trial'' - the question of external validity is, loosely, the question of how informative the latter are about the former. The usual approach of causal inference is to determine conditions under which the latter can be estimated and then, maybe, consider some additional assumptions that might allow for the latter estimate to inform the former. CSDT inverts the priority of these questions: the question of treatment in practice is primary and the question of causal effects in the trial may be a subproblem of interest under particular conditions. 

\citet{bareinboim_transportability_2012} have claimed to have a complete solution to the problem of ``[identifying] conditions under which causal information learned from experiments can be reused in a different environment where only passive observations can be collected'', a claim made with more force in \citet{pearl_challenging_2018}. A complete solution to the transportability of causal information is \emph{not} a claim of a complete solution to the problem of determining the effects of ``treatment in practice'' or the problem of making decisions with causal information. These latter problems ask when causal effects are informative about the consequences of decisions in the given problem, a question that doesn't even make sense without our insistence that decisions are a feature of the problem.

Key features (/aims - not all are realised yet) of CSDT are:

\begin{itemize}
	\item Conceptual clarity:
	\begin{itemize}
		\item CSDT separates of those aspects of a problem that are fixed by non-causal considerations (objectives, feasible decisions) and causal assumptions
	\end{itemize}
	\item Unification and extension of existing approaches to causal inference for decision problems
	\begin{itemize}
		\item Faithful translation from any existing approach to CSDT (including the derivation of key results)
		\item Exact and approximate comparison of arbitrary causal theories
		\item Quantification of the \emph{difficulty} of a causal problem
		\item Necessary conditions for key results
		\item Novel approaches/assumptions for causal inference
	\end{itemize}	
\end{itemize}



\todo[inline]{the following seems like a reasonable point, but not sure where to put it right now}

The core features of CSDT are that it is a new approach to causality that is strictly more capable of representing decision problems than existing approaches, and that it allows for novel and fundamental questions to be asked. However, a secondary feature of CSDT is that its statements can be clearly resolved to statements in the underlying theory of probability. This may also be true of some counterfactual approaches, but I don't think it is true of interventional graphical models. For example, Causal Bayesian Networks feature an elementary operation notated $P(\cdot|do(\RV{X}_k=a))$ where $\RV{X}_k$ is a random variable on some implicit sample space $E$. We can ask: what does $P(\cdot|do(\RV{X}_k=a))$ mean in more elementary terms? $do(\RV{X}_k=a)$ itself \emph{looks} like a function, and the conventional interpretation of $\RV{X}_k=a$ is the preimage of $a$ under $\RV{X}_k$. Thus, $do()$ appears to be a function typed like a measure on $\mathcal{E}$ with the domain being the sigma algebra generated by all statements $\RV{X}_i=a$ for all $\RV{X}_i$ associated with some graph $\mathcal{G}$, which we will denote $\sigma(\utimes_{i\in \mathcal{G}} \RV{X}_i)$. We might surmise that the ``conditional probability'' $P(\cdot|do(\RV{X}_k=\cdot))$ might then be the conditional probability on $\sigma(\utimes_{i\in \mathcal{G}} \RV{X}_i)$. However, CBNs in general support models where $P(\cdot|do(\RV{X}_k=\cdot))$ is not equal to $P(\cdot|\RV{A})$ for any $\RV{A}\in \sigma(\utimes_\mathcal{G} \RV{X}_i)$, so our attempt to parse this notation by ``conventional reading'' has failed.

In fact, the situation is even more dire: we may view $do(\RV{X}_k=a)$ as a relation between probability measures on $E$ which is not, in general, functional -- an interpretation compatible with the definitions in \citet{pearl_causality:_2009}. If $do()$ were functional, we could define $P(\cdot|\do(\RV{X}_k=a)$ to be the element of $\Delta(\mathcal{E})$ related to $P$ by $\do(\RV{X}_k=a)$. However, because $do(\RV{X}_k=a)$ is not functional, ``conditioning'' on $do(\RV{X}_k=\cdot)$ is ambiguous - does $P(\cdot|do(\RV{X}_k=a))$ refer to the set of probability measures related to $P$? A distinguished member of this set? In contrast to regular conditioning, where a similar ambiguity prevails but the ambient measure guarantees that disagreement can only happen on sets of measure zero, $P(\cdot|do(\RV{X}_k=a))$ can under different interpretations assign different measures to the same set. Causal Bayesian Network notational conventions suggest interpretations that do not make sense, and their meaning may be ambiguous even if we dig more deeply into the matter.

% It is widely accepted that causal knowledge and statistical knowledge are distinct. Statistics is concerned with \emph{association} while causation is concerned with \emph{consequences}; a distinction of this type goes back at least to Hume \citep{morris_david_2019}. Statistics nevertheless plays a vital role in causal inference and the languages of \emph{potential outcomes} \citep{rubin_causal_2005} and \emph{causal Bayesian networks} \citep{pearl_causality:_2009} are key tools that, in their somewhat different ways, allow us to bring statistical knowledge to bear on causal questions. Counterfactual random variables and ``do-interventions'' are unique elements of the potential outcomes and causal Bayesian network approach respectively, and there have been a number of attempts to bring these two views together \cite{richardson2013single,shpitser_complete_2008,pearl_causality:_2009}, but there doesn't appear to be a consensus about which (if any) of these unifications is successful. Our work takes a different approach: we begin with statistical decision theory and connect it with both.

% We develop \emph{causal statistical decision theory}, an approach to causal inference that takes statistical decision theory \citep{wald_statistical_1950} as a starting point and, with conceptual cues from \citet{savage_foundations_1972}, replaces losses with utilities and consequences. Causal statistical decsion theory features \emph{causal theories} as the central object of study, playing a role analogous to \emph{statistical experiments} in ordinary statistical decision theory. They differ in that, where a statistical experiment gives you a probability measure, a causal theory gives a stochastic map. A statistical experiment connects observations with an abstract ``state'', while a causal theory expresses a relationship between observations and consequences.

% Causal Bayesian networks themselves have a natural representation as causal theories. Against Pearl's claim that counterfactual models subsume interventional ones, we find that arbitrary choices must be made in order to represent potential outcomes models as causal theories. Nonetheless, we propose a plausible strategy for representing potential outcomes models as causal theories. We find that these two approaches yield very different causal theories from one another, though these differences may disappear when we move from ``idealised'' theories to more realistic theories that we might actually use to make decisions.

% We then turn our attention to a notable feature of the idealised causal theories induced by both approaches: they each allow for unrealistically fine control over many of their consequences. We posit that these theories are intended to inform realistic theories used for making decisions. We show that this is possible if the realistic theories can be derived from the idealised theories via what we term \emph{coarsening}. To our knowledge, this is the first attempt to formalise the notion of ``stable knowledge'' that is often raised as a key potential advantage of causal understanding over purely statistical learning \citep{arjovsky_invariant_2019,pearl_causality:_2009,rubin_causal_2005}.

% Potential Outcomes (PO) posits a large joint distribution over observed variables $\RV{X}$, $\RV{Y}$ and partly unobserved ``potential outcome'' variables $\RV{X}_0$, $\RV{Y}_1$ and so forth. A potential outcome variable $\RV{Y}_i$ is interpreted as ``the value of $\RV{Y}$ that would be observed if the action identified by $i$ were taken''. Under some conditions, an investigator with access to a joint distribution over observed variables may be able to infer certain properties of the distribution over potential outcome variables such as $\mathbb{E}[\RV{X}_i]$.

% Queries in the CBN framework may be concerned with identification of causal effects given a graph and a probability distribution \citep{tian2002general}, or with the determination of the true causal graph given just a probability distribution \citep{spirtes_causation_1993}. Queries in the PO framework usually concern identification of properties of the distribution of potential outcome variables known as \emph{treatment effects} given a dataset and certain assumptions about this distribution \citep{rubin_causal_2005,robins2010alternative}. In both cases, these queries fit the paradigm of ``determining true properties of nature'' rather than ``learning to output a decision that minimises a loss''.

% The first contribution of this paper is the notion of a \emph{causal statistical decision problem} (CSDP) that proceeds from a natural extension of an ordinary statistical decision problem (SDP) introduced by \citep{wald_statistical_1950}. We suppose that, in contrast to an ordinary SDP where we have known preferences over (decision, state of nature) pairs, we know only our preferences over the \emph{outcomes} of decisions, which we represent with a utility function. Uncertainty over the consequences of decisions is represented by a \emph{causal theory} that connects observed data with \emph{consequence maps}. 

% We show by a reduction that results concerning standard SDPs are also true of (at least) a subset of CSDPs.  We also show that both Causal Bayesian Networks and joint distributions over potential outcomes have a natural representation as causal theories. Together these results show, for example, that the class of Bayes decision functions is a complete class for CSDPs based on Causal Bayesian Networks provided certain conditions on the utility and size of the available set of decisions are met.

% The notion of a causal theory presented here can naturally represent models cast in terms of CBNs or POs, but there are many causal theories that cannot easily be represented by either. We discuss a question motivated by this more general perspective: \emph{given a CBN with observable predictions, what should be assumed when the data doesn't match these predictions?} We show that different answers to this question yield widely divergent conclusions.

% A key strength of our perspective is the possibility of theoretical treatment of causal learning from a viewpoint that is agnostic about the nature of ``causal knowledge''. Causal knowledge is a tricky domain from philosophy to practice, and there are many proposals for causal assumptions that do not neatly fit in either the CBN or PO camps \citep{bongers_theoretical_2016,dawid_beware_2010,bengio_meta-transfer_2019}. The theory presented here is capable of posing questions such as ``does a proposed causal learning method work?'' without first requiring commitments on the nature of causal knowledge. Substantial progress in machine learning has been the result of developing generic principles and learning techniques that are relevant to many datasets from many domains and are less reliant on the judgement of domain experts. We believe this separation of concerns is crucial to the advancement of generic techniques of causal learning.

% Our approach is similar to that of \citet{dawid_decision-theoretic_2012}, but where he takes a ``bottom-up'' approach of developing a decision theoretic answer to particular causal questions, our approach is ``top-down'', proceeding from a general account of a causal problem to the particular objects needed to answer it. It also shares similarities with Causal Decision Theory developed by \citet{lewis_causal_1981}, though the connection with statistical decision theory is better understood at this point.

% There are two main assumptions used so far in pursuing generic causal inference: \emph{faithfulness} and the \emph{independence of cause and mechanism}. The assumption of faithfulness (together with the Causal Markov Condition) facilitates the exclusion of some graphical models on the basis of conditional independences found in the data \citep{spirtes_causation_1993} while the principle of independence of cause and mechanism enables the use of a number of special purpose techniques to assess the \emph{algorithmic independence} of marginal and conditional distributions which leads to preferment of some graphical models over others \citep{lemeire_replacing_2013, peters_identifiability_2012}.



% Both faithfulness and the independence of cause and mechanism are employed in learning causal Bayesian networks. While these are undoubtedly useful tools for causal reasoning, causal Bayesian networks are not ideal objects for the analysis of causal learning at a very general level:
% \begin{itemize}
%     \item There are causal models which cannot be captured by a DAG \citep{dawid_beware_2010,bongers_theoretical_2016}
%     \item There is controversy over how causal Bayesian networks should be adapted to answer counterfactual questions \citep{richardson2013single}
%     \item Under appropriate conditions, different graphs may induce the same set of interventional distributions \citep{peters_structural_2015}
%     \item A standard causal Bayesian network posits an intervention operation for every variable under consideration, while the actions to be evaluated may be much more limited. Learning such a graph appears to run afoul of Vapnik's precept: \emph{When solving a given problem, try to avoid solving a more general problem as an intermediate step} \citep{vapnik_nature_2013}
% \end{itemize}
