%!TEX root = main.tex

\section{Introduction}

\vspace{-3mm}

It is widely accepted that causal knowledge and statistical knowledge are distinct. At least two levels are common: statistics is concerned with \emph{association} while causation is concerned with \emph{consequences}; a distinction of this nature goes back at least to Hume \citep{morris_david_2019}, who is also noted for his argument that knowledge of the latter cannot be reduced to the former. \citet{pearl_causality:_2009} has identified three level hierarchy of causal knowledge in contemporary work: first \emph{association}, then \emph{intervention} (analogous to Cartwright's \emph{strategy}) and finally \emph{counterfactuals}. Pearl argues that the types of things that can be known at higher levels subsumes what can be known at lower levels (e.g. all associational knowledge is a type of interventional knowledge), but lower levels do not subsume higher levels.

An apparently paradoxical feature of this three level hierarchy is that, though knowledge is claimed to flow only in one direction, we find that the first and third levels are both described by ordinary joint probability distributions. Counterfactual queries can be formulated as missing data problems, which are distinct from associational problems only due to the interpretations we assign to so-called \emph{counterfactual random variables} or \emph{potential outcomes}. Knowledge at the second level, on the other hand, is described by causal graphical models which are \emph{not} joint probability distributions (in one treatment, they are introduced as indexed sets of joint probability distributions \cite{pearl_causality:_2009}). Here is an apparently paradoxical feature of common approaches to causal inference: associational knowledge is distinguished from consequential knowledge in both interpretation and representation, while counterfactual knowledge -- considered to subsume both -- is distinguished from associational knowledge by interpretation only.

Statistical decision theory, introduced by \citet{wald_statistical_1950}, underpins much of modern machine learning. It introduced the fundamental notions of \emph{loss} and \emph{risk} to statistics and proided foundational theorems such as the \emph{complete class theorem} which shows that all admissible decision rules are Bayesian decision rules for some prior. Key elements of statistical learning theory inherits heavily from statistical decision theory\todo{Is this true? There are substantial similarities between SDT and SLT, but I haven't found direct evidence of lineage in e.g. a citation from Valiant}. While some descendants of statistical decision theory have grappled with the problem of causality \citep{lewis_causal_1981}, SDT itself is regarded as a theory of statistical decision making and not of causality.

We show a surprising relationship between SDT and causal graphical models. We proceed in two steps: We note that a causal graphical model represents a relationship between probability measures on a given space and the consequences of a given set of actions. We then consider a modification of a standard statistical decision problem: suppose that, rather than being given a loss function that directly evaluates decisions, we are instead provided with a preference function over consequences of decisions that (following convention) we call a \emph{utility}. The resulting problem is underspecified and provides no ordering over decisions. However, the type of relationship represented by a causal graphical model is then found to be precisely the type of object needed to fully specify the problem, and does so in a way that induces a regular statistical decision problem.

This motivates the definition of \emph{causal statistical decision problems} (CSDPs). These relate to regular statistical decision problems (SDPs) in loose analogy with the way that model based reinforcement learning relates to model free reinforcement learning; while the former keeps track of both consequences and rewards/utililties of decisions, the latter ``forgets about the consequences'' and only works with reward/utiltiy.

CSDPs introduce the notion of \emph{causal theories}. Causal theories represent relationships between probability measures and consequences and are a generalisation of causal graphical models. In Pearl's language, they represent the connection between associational knowledge and interventional knowledge; in Cartwright's, they connect associational knowledge with the consequences of strategies. 

Thanks to the clarity of our approach, we are able to shed light on the questions raised in the second paragraph: we require a causal theory to bring knowledge from levels 1 to 2 of Pearl's hierarchy and we \emph{also} require a causal theory to bring knowledge from level 3 to level 2. A joint distribution over counterfactuals can only answer interventional questions \emph{given interventional assumptions} (we speculate that such assumptions may have been taken for granted). Associational knowledge is represented with probability distributions, knowledge of consequences with stochastic maps and relationships between the two with causal theories.

Choosing appropriate causal theories is a hard problem. Whether we build a causal theory with graphical models or Potential Outcomes (with additional assumptions), it is often the case that a nontrivial result rests on assumptions that are not obvious, generic or testable. Generic principles such as the bias-variance tradeoff have proved to be immensely powerful in the world of statistics, and we regard the question of whether there are generic principles that govern causal inference and what they may be to be one of the most important questions in the field.

We are primarily concerned with setting out a clear framework for reasoning about causal theories, and do not propose principles for constructing a causal theory in this paper. We are able to show a general negative result - causal theories that are symmetric over permutations of decisions cannot yield nontrivial decision rule orderings. We term this result ``no causes in, no causes out'' as it demonstrates that some causal knowledge is required at the outset if we hope for any nontrivial decision rules. Such asymmetric causal assumptions must be problem specific, so from the outset we cannot build causal theories on ``problem neutral'' assumptions alone. 

\todo[inline]{There's another half baked angle here, which is ``what kinds of causal theories are represented by graphical models''? In particular, via the question of dominance we can consider causal theories to be related by three different types of randomisation. Also, if we examine marginal causal models, we note that they all represent causal theories that are related to a ``nice'' causal theory (in the sense that identification is straightforward) via two of these types of randomisation. It's half baked because I can't yet say a lot from there, save for the fact that the operation of randomisation seems more amenable to being generalised to a continuous version than DAGs do.}

\todo[inline]{I could also include the ``free'' results from statistical decision theory somewhere - complete class theorem, purification}

% Potential Outcomes (PO) posits a large joint distribution over observed variables $\RV{X}$, $\RV{Y}$ and partly unobserved ``potential outcome'' variables $\RV{X}_0$, $\RV{Y}_1$ and so forth. A potential outcome variable $\RV{Y}_i$ is interpreted as ``the value of $\RV{Y}$ that would be observed if the action identified by $i$ were taken''. Under some conditions, an investigator with access to a joint distribution over observed variables may be able to infer certain properties of the distribution over potential outcome variables such as $\mathbb{E}[\RV{X}_i]$.

% Queries in the CBN framework may be concerned with identification of causal effects given a graph and a probability distribution \citep{tian2002general}, or with the determination of the true causal graph given just a probability distribution \citep{spirtes_causation_1993}. Queries in the PO framework usually concern identification of properties of the distribution of potential outcome variables known as \emph{treatment effects} given a dataset and certain assumptions about this distribution \citep{rubin_causal_2005,robins2010alternative}. In both cases, these queries fit the paradigm of ``determining true properties of nature'' rather than ``learning to output a decision that minimises a loss''.

% The first contribution of this paper is the notion of a \emph{causal statistical decision problem} (CSDP) that proceeds from a natural extension of an ordinary statistical decision problem (SDP) introduced by \citep{wald_statistical_1950}. We suppose that, in contrast to an ordinary SDP where we have known preferences over (decision, state of nature) pairs, we know only our preferences over the \emph{outcomes} of decisions, which we represent with a utility function. Uncertainty over the consequences of decisions is represented by a \emph{causal theory} that connects observed data with \emph{consequence maps}. 

% We show by a reduction that results concerning standard SDPs are also true of (at least) a subset of CSDPs.  We also show that both Causal Bayesian Networks and joint distributions over potential outcomes have a natural representation as causal theories. Together these results show, for example, that the class of Bayes decision functions is a complete class for CSDPs based on Causal Bayesian Networks provided certain conditions on the utility and size of the available set of decisions are met.

% The notion of a causal theory presented here can naturally represent models cast in terms of CBNs or POs, but there are many causal theories that cannot easily be represented by either. We discuss a question motivated by this more general perspective: \emph{given a CBN with observable predictions, what should be assumed when the data doesn't match these predictions?} We show that different answers to this question yield widely divergent conclusions.

% A key strength of our perspective is the possibility of theoretical treatment of causal learning from a viewpoint that is agnostic about the nature of ``causal knowledge''. Causal knowledge is a tricky domain from philosophy to practice, and there are many proposals for causal assumptions that do not neatly fit in either the CBN or PO camps \citep{bongers_theoretical_2016,dawid_beware_2010,bengio_meta-transfer_2019}. The theory presented here is capable of posing questions such as ``does a proposed causal learning method work?'' without first requiring commitments on the nature of causal knowledge. Substantial progress in machine learning has been the result of developing generic principles and learning techniques that are relevant to many datasets from many domains and are less reliant on the judgement of domain experts. We believe this separation of concerns is crucial to the advancement of generic techniques of causal learning.

% Our approach is similar to that of \citet{dawid_decision-theoretic_2012}, but where he takes a ``bottom-up'' approach of developing a decision theoretic answer to particular causal questions, our approach is ``top-down'', proceeding from a general account of a causal problem to the particular objects needed to answer it. It also shares similarities with Causal Decision Theory developed by \citet{lewis_causal_1981}, though the connection with statistical decision theory is better understood at this point.

% There are two main assumptions used so far in pursuing generic causal inference: \emph{faithfulness} and the \emph{independence of cause and mechanism}. The assumption of faithfulness (together with the Causal Markov Condition) facilitates the exclusion of some graphical models on the basis of conditional independences found in the data \citep{spirtes_causation_1993} while the principle of independence of cause and mechanism enables the use of a number of special purpose techniques to assess the \emph{algorithmic independence} of marginal and conditional distributions which leads to preferment of some graphical models over others \citep{lemeire_replacing_2013, peters_identifiability_2012}.



% Both faithfulness and the independence of cause and mechanism are employed in learning causal Bayesian networks. While these are undoubtedly useful tools for causal reasoning, causal Bayesian networks are not ideal objects for the analysis of causal learning at a very general level:
% \begin{itemize}
%     \item There are causal models which cannot be captured by a DAG \citep{dawid_beware_2010,bongers_theoretical_2016}
%     \item There is controversy over how causal Bayesian networks should be adapted to answer counterfactual questions \citep{richardson2013single}
%     \item Under appropriate conditions, different graphs may induce the same set of interventional distributions \citep{peters_structural_2015}
%     \item A standard causal Bayesian network posits an intervention operation for every variable under consideration, while the actions to be evaluated may be much more limited. Learning such a graph appears to run afoul of Vapnik's precept: \emph{When solving a given problem, try to avoid solving a more general problem as an intermediate step} \citep{vapnik_nature_2013}
% \end{itemize}
