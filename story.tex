%!TEX root = main.tex

\section{Introduction}

\vspace{-3mm}

It is widely accepted that causal knowledge and statistical knowledge are distinct. Statistics is concerned with \emph{association} while causation is concerned with \emph{consequences}; a distinction of this type goes back at least to Hume \citep{morris_david_2019}. Statistics nevertheless plays a vital role in causal inference and the languages of \emph{potential outcomes} \citep{rubin_causal_2005} and \emph{causal Bayesian networks} \citep{pearl_causality:_2009} are key tools that, in their somewhat different ways, allow us to bring statistical knowledge to bear on causal questions. Counterfactual random variables and ``do-interventions'' are unique elements of the potential outcomes and causal Bayesian network approach respectively, and there have been a number of attempts to bring these two views together \cite{richardson2013single,shpitser_complete_2008,pearl_causality:_2009}, but there doesn't appear to be a consensus about which (if any) of these unifications is successful. Our work takes a different approach: we begin with statistical decision theory and connect it with both.

We develop \emph{causal statistical decision theory}, an approach to causal inference that takes statistical decision theory \citep{wald_statistical_1950} as a starting point and, with conceptual cues from \citet{savage_foundations_1972}, replaces losses with utilities and consequences. Causal statistical decsion theory features \emph{causal theories} as the central object of study, playing a role analogous to \emph{statistical experiments} in ordinary statistical decision theory. They differ in that, where a statistical experiment gives you a probability measure, a causal theory gives a stochastic map. A statistical experiment connects observations with an abstract ``state'', while a causal theory expresses a relationship between observations and consequences.

Causal Bayesian networks themselves have a natural representation as causal theories. Against Pearl's claim that counterfactual models subsume interventional ones, we find that arbitrary choices must be made in order to represent potential outcomes models as causal theories. Nonetheless, we propose a plausible strategy for representing potential outcomes models as causal theories. We find that these two approaches yield very different causal theories from one another, though these differences may disappear when we move from ``idealised'' theories to more realistic theories that we might actually use to make decisions.

We then turn our attention to a notable feature of the idealised causal theories induced by both approaches: they each allow for unrealistically fine control over many of their consequences. We posit that these theories are intended to inform realistic theories used for making decisions. We show that this is possible if the realistic theories can be derived from the idealised theories via what we term \emph{coarsening}. To our knowledge, this is the first attempt to formalise the notion of ``stable knowledge'' that is often raised as a key potential advantage of causal understanding over purely statistical learning \citep{arjovsky_invariant_2019,pearl_causality:_2009,rubin_causal_2005}.

% Potential Outcomes (PO) posits a large joint distribution over observed variables $\RV{X}$, $\RV{Y}$ and partly unobserved ``potential outcome'' variables $\RV{X}_0$, $\RV{Y}_1$ and so forth. A potential outcome variable $\RV{Y}_i$ is interpreted as ``the value of $\RV{Y}$ that would be observed if the action identified by $i$ were taken''. Under some conditions, an investigator with access to a joint distribution over observed variables may be able to infer certain properties of the distribution over potential outcome variables such as $\mathbb{E}[\RV{X}_i]$.

% Queries in the CBN framework may be concerned with identification of causal effects given a graph and a probability distribution \citep{tian2002general}, or with the determination of the true causal graph given just a probability distribution \citep{spirtes_causation_1993}. Queries in the PO framework usually concern identification of properties of the distribution of potential outcome variables known as \emph{treatment effects} given a dataset and certain assumptions about this distribution \citep{rubin_causal_2005,robins2010alternative}. In both cases, these queries fit the paradigm of ``determining true properties of nature'' rather than ``learning to output a decision that minimises a loss''.

% The first contribution of this paper is the notion of a \emph{causal statistical decision problem} (CSDP) that proceeds from a natural extension of an ordinary statistical decision problem (SDP) introduced by \citep{wald_statistical_1950}. We suppose that, in contrast to an ordinary SDP where we have known preferences over (decision, state of nature) pairs, we know only our preferences over the \emph{outcomes} of decisions, which we represent with a utility function. Uncertainty over the consequences of decisions is represented by a \emph{causal theory} that connects observed data with \emph{consequence maps}. 

% We show by a reduction that results concerning standard SDPs are also true of (at least) a subset of CSDPs.  We also show that both Causal Bayesian Networks and joint distributions over potential outcomes have a natural representation as causal theories. Together these results show, for example, that the class of Bayes decision functions is a complete class for CSDPs based on Causal Bayesian Networks provided certain conditions on the utility and size of the available set of decisions are met.

% The notion of a causal theory presented here can naturally represent models cast in terms of CBNs or POs, but there are many causal theories that cannot easily be represented by either. We discuss a question motivated by this more general perspective: \emph{given a CBN with observable predictions, what should be assumed when the data doesn't match these predictions?} We show that different answers to this question yield widely divergent conclusions.

% A key strength of our perspective is the possibility of theoretical treatment of causal learning from a viewpoint that is agnostic about the nature of ``causal knowledge''. Causal knowledge is a tricky domain from philosophy to practice, and there are many proposals for causal assumptions that do not neatly fit in either the CBN or PO camps \citep{bongers_theoretical_2016,dawid_beware_2010,bengio_meta-transfer_2019}. The theory presented here is capable of posing questions such as ``does a proposed causal learning method work?'' without first requiring commitments on the nature of causal knowledge. Substantial progress in machine learning has been the result of developing generic principles and learning techniques that are relevant to many datasets from many domains and are less reliant on the judgement of domain experts. We believe this separation of concerns is crucial to the advancement of generic techniques of causal learning.

% Our approach is similar to that of \citet{dawid_decision-theoretic_2012}, but where he takes a ``bottom-up'' approach of developing a decision theoretic answer to particular causal questions, our approach is ``top-down'', proceeding from a general account of a causal problem to the particular objects needed to answer it. It also shares similarities with Causal Decision Theory developed by \citet{lewis_causal_1981}, though the connection with statistical decision theory is better understood at this point.

% There are two main assumptions used so far in pursuing generic causal inference: \emph{faithfulness} and the \emph{independence of cause and mechanism}. The assumption of faithfulness (together with the Causal Markov Condition) facilitates the exclusion of some graphical models on the basis of conditional independences found in the data \citep{spirtes_causation_1993} while the principle of independence of cause and mechanism enables the use of a number of special purpose techniques to assess the \emph{algorithmic independence} of marginal and conditional distributions which leads to preferment of some graphical models over others \citep{lemeire_replacing_2013, peters_identifiability_2012}.



% Both faithfulness and the independence of cause and mechanism are employed in learning causal Bayesian networks. While these are undoubtedly useful tools for causal reasoning, causal Bayesian networks are not ideal objects for the analysis of causal learning at a very general level:
% \begin{itemize}
%     \item There are causal models which cannot be captured by a DAG \citep{dawid_beware_2010,bongers_theoretical_2016}
%     \item There is controversy over how causal Bayesian networks should be adapted to answer counterfactual questions \citep{richardson2013single}
%     \item Under appropriate conditions, different graphs may induce the same set of interventional distributions \citep{peters_structural_2015}
%     \item A standard causal Bayesian network posits an intervention operation for every variable under consideration, while the actions to be evaluated may be much more limited. Learning such a graph appears to run afoul of Vapnik's precept: \emph{When solving a given problem, try to avoid solving a more general problem as an intermediate step} \citep{vapnik_nature_2013}
% \end{itemize}
