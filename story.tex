\section{Introduction}

% \cheng{Add a Venn diagram at the top of page 2, with all the terms in it.}

% \cheng{Do not assume your reader knows what is Causal Bayesian Networks and Potential Outcomes. You need to describe them.}

The decision theoretic approach to statistics casts statistical problems in terms of learning to output decisions that minimise a loss rather than in terms of learning true properties of a data generating distribution. Statistical decision theory plays a role of fundamental importance in modern machine learning; loss functions underpin the development of algorithms, and the analysis of losses is critical to the theoretical treatment of learning algorithms.

It is widely accepted that problems of causal inference are different to statistical problems; causal problems are held to demand causal knowledge that is considered irrelevant to statistical problems \citep{pearl_causality:_2009,cartwright_no_1994}. There are two leading approaches to formalising ``causal knowledge'' and posing causal problems: one based on Causal Bayesian Networks and the other on Potential Outcomes.

Causal Bayesian Networks (CBNs) posit that there are causal relationships among a set of random variables that can be encoded by a directed acyclic graph (DAG). An investigator with access to the true graph and a joint probability distribution over all the variables present in that graph can calculate a number of causal effects with these two objects. A causal effect here is intuitively understood as ``the result of intervening to set particular variables to particular values''.

Potential Outcomes (PO) posits a large joint distribution over observed variables $\RV{X}$, $\RV{Y}$ and ``potential outcome'' variables $\RV{X}_0$, $\RV{Y}_1$ and so forth. A potential outcome variable $\RV{Y}_i$ is intuitively understood as ``the value of $\RV{Y}$ that would be observed if the action identified by $i$ is taken''. Under some conditions, an investigator with access to a joint distribution over observed variables may be able to infer certain properties of the distribution over potential outcome variables such as $\mathbb{E}[\RV{X}_i]$.

Queries in the CBN framework may be concerned with identification of causal effects given a graph and a probability distribution (see for example \citep{tian2002general}), or with the determination of the true causal graph given just a probability distribution (see \citep{spirtes_causation_1993}). Queries in the PO framework usually concern identification of properties of the distribution of potential outcome variables known as treatment effects given a dataset and certain assumptions about this distribution (see \citep{rubin_causal_2005,robins2010alternative}). In both cases, these queries fit the paradigm of ``determining true properties of nature'' rather than ``learning to output a decision that minimises a loss''.

The first contribution of this paper is the notion of a \emph{causal statistical decision problem} (CSDP) that proceeds from a natural extension of an ordinary statistical decision problem (SDP) introduced by \citep{wald_statistical_1950}. We suppose that, in contrast to an ordinary SDP where we have known preferences over (decision, state of nature) pairs, we know only our preferences over the \emph{outcomes} of decisions, which we represent with a utility function. Uncertainty over the consequences of decisions is represented by a \emph{causal theory} that connects observed data with \emph{consequence maps}. 

We show by a reduction that results concerning standard SDPs are also true of a subset of CSDPs.  We also show that both Causal Bayesian Networks and joint distributions over potential outcomes have a natural representation as causal theories. Together these results show, for example, that the class of Bayes decision functions is a complete class for CSDPs based on Causal Bayesian Networks provided certain conditions on the utility and size of the available set of decisions are met.

The notion of a causal theory presented here can naturally represent models cast in terms of CBNs or POs, but there are many causal theories that cannot easily be represented by either. We present two examples to demonstrate the usefulness of the more general notion. First, we address the question of \emph{what assumptions should be made for when the data doesn't match a given CBN} and show that, depending on the commitments we are willing to make, we might conclude that we should always ignore the given CBN no matter what data is observed. Secondly, we show that the issue of \emph{performance bias} can be naturally represented as a causal theory, while we find evidence in the existing literature of difficulty in representing this bias in one of the existing causal frameworks.

One of the key strengths of our perspective is the possibility of theoretical treatment of causal learning from a viewpoint that is fundamentally agnostic about the nature of ``true causal knowledge''. The questions of whether an approach to causal learning is true and whether it is effective ought to be independent, and the theory presented here is capable of addressing the second question without first making a commitment on the first. Substantial progress in machine learning has been the result of developing generic principles and learning techniques that are relevant to many datasets from many domains and are less reliant on the judgement of domain experts and we believe this separation of concerns is crucial to the advancement of generic techniques of causal learning.

Our approach is similar to that of \cite{dawid_decision-theoretic_2012}, but where he takes a ``bottom-up'' approach of developing a decision theoretic answer to particular causal questions, our approach is ``top-down'', proceeding from a general account of a causal problem to the particular objects needed to answer it. It also shares similarities with Causal Decision Theory developed by \cite{lewis_causal_1981}, though the connection with statistical decision theory is better understood at this point.

% There are two main assumptions used so far in pursuing generic causal inference: \emph{faithfulness} and the \emph{independence of cause and mechanism}. The assumption of faithfulness (together with the Causal Markov Condition) facilitates the exclusion of some graphical models on the basis of conditional independences found in the data \citep{spirtes_causation_1993} while the principle of independence of cause and mechanism enables the use of a number of special purpose techniques to assess the \emph{algorithmic independence} of marginal and conditional distributions which leads to preferment of some graphical models over others \citep{lemeire_replacing_2013, peters_identifiability_2012}.



% Both faithfulness and the independence of cause and mechanism are employed in learning causal Bayesian networks. While these are undoubtedly useful tools for causal reasoning, causal Bayesian networks are not ideal objects for the analysis of causal learning at a very general level:
% \begin{itemize}
%     \item There are causal models which cannot be captured by a DAG \citep{dawid_beware_2010,bongers_theoretical_2016}
%     \item There is controversy over how causal Bayesian networks should be adapted to answer counterfactual questions \citep{richardson2013single}
%     \item Under appropriate conditions, different graphs may induce the same set of interventional distributions \citep{peters_structural_2015}
%     \item A standard causal Bayesian network posits an intervention operation for every variable under consideration, while the actions to be evaluated may be much more limited. Learning such a graph appears to run afoul of Vapnik's precept: \emph{When solving a given problem, try to avoid solving a more general problem as an intermediate step} \citep{vapnik_nature_2013}
% \end{itemize}
